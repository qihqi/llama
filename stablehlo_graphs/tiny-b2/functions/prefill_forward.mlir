module @IrToHlo.842 attributes {mhlo.cross_program_prefetches = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32000x128xf32>, %arg1: tensor<128xf32>, %arg2: tensor<f32>, %arg3: tensor<128x352xf32>, %arg4: tensor<352x128xf32>, %arg5: tensor<128xf32>, %arg6: tensor<128x128xf32>, %arg7: tensor<2048xi64>, %arg8: tensor<128x128xf32>, %arg9: tensor<128xf32>, %arg10: tensor<128x352xf32>, %arg11: tensor<352x128xf32>, %arg12: tensor<128xf32>, %arg13: tensor<128x128xf32>, %arg14: tensor<128x128xf32>, %arg15: tensor<128xf32>, %arg16: tensor<128x352xf32>, %arg17: tensor<352x128xf32>, %arg18: tensor<128xf32>, %arg19: tensor<128x128xf32>, %arg20: tensor<128x128xf32>, %arg21: tensor<128xf32>, %arg22: tensor<2x2048xi64>, %arg23: tensor<i64>, %arg24: tensor<32000x128xf32>, %arg25: tensor<2048xi64>, %arg26: tensor<i64>, %arg27: tensor<2x2304x2x64xf32>, %arg28: tensor<f32>, %arg29: tensor<f32>, %arg30: tensor<4608x32xcomplex<f32>>, %arg31: tensor<128x128xf32>, %arg32: tensor<2x2304x2x64xf32>, %arg33: tensor<128x128xf32>, %arg34: tensor<352x128xf32>, %arg35: tensor<2x2304x2x64xf32>, %arg36: tensor<128x128xf32>, %arg37: tensor<2x2304x2x64xf32>, %arg38: tensor<128x128xf32>, %arg39: tensor<352x128xf32>, %arg40: tensor<2x2304x2x64xf32>, %arg41: tensor<128x128xf32>, %arg42: tensor<2x2304x2x64xf32>, %arg43: tensor<128x128xf32>, %arg44: tensor<352x128xf32>) -> (tensor<2x2048x32000xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>) {
    %0 = stablehlo.constant dense<7.812500e-03> : tensor<2x2048xf32>
    %1 = stablehlo.constant dense<2.000000e+00> : tensor<2x2048x128xf32>
    %2 = stablehlo.constant dense<0> : tensor<2048xi64>
    %3 = stablehlo.constant dense<0.000000e+00> : tensor<1x1x2048x2048xf32>
    %4 = stablehlo.constant dense<1> : tensor<2048x2048xi64>
    %5 = stablehlo.constant dense<"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tensor<2048xi64>
    %6 = stablehlo.constant dense<0> : tensor<2x2048xi64>
    %7 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %8 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %9 = stablehlo.compare  LT, %arg22, %6 : (tensor<2x2048xi64>, tensor<2x2048xi64>) -> tensor<2x2048xi1>
    %10 = stablehlo.broadcast_in_dim %arg23, dims = [] : (tensor<i64>) -> tensor<2x2048xi64>
    %11 = stablehlo.add %arg22, %10 : tensor<2x2048xi64>
    %12 = stablehlo.select %9, %11, %arg22 : tensor<2x2048xi1>, tensor<2x2048xi64>
    %13 = stablehlo.reshape %12 : (tensor<2x2048xi64>) -> tensor<2x2048x1xi64>
    %14 = "stablehlo.gather"(%arg24, %13) {dimension_numbers = #stablehlo.gather<offset_dims = [2], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 2>, indices_are_sorted = false, slice_sizes = dense<[1, 128]> : tensor<2xi64>} : (tensor<32000x128xf32>, tensor<2x2048x1xi64>) -> tensor<2x2048x128xf32>
    %15 = stablehlo.power %14, %1 : tensor<2x2048x128xf32>
    %16 = stablehlo.reduce(%15 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %17 = stablehlo.multiply %16, %0 : tensor<2x2048xf32>
    %18 = stablehlo.reshape %17 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %19 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %20 = stablehlo.add %18, %19 : tensor<2x2048x1xf32>
    %21 = stablehlo.rsqrt %20 : tensor<2x2048x1xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %24 = stablehlo.multiply %14, %23 : tensor<2x2048x128xf32>
    %25 = stablehlo.broadcast_in_dim %arg21, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %26 = stablehlo.multiply %24, %25 : tensor<2x2048x128xf32>
    %27 = stablehlo.reshape %26 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %28 = stablehlo.transpose %arg33, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %29 = stablehlo.dot %27, %28, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %30 = stablehlo.reshape %29 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %31 = stablehlo.slice %30 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %32 = stablehlo.reshape %31 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %33 = stablehlo.slice %30 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %34 = stablehlo.reshape %33 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %35 = stablehlo.complex %32, %34 : tensor<2x2048x2x32xcomplex<f32>>
    %36 = stablehlo.convert %arg25 : (tensor<2048xi64>) -> tensor<2048xui32>
    %37 = "stablehlo.gather"(%arg30, %36) {dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[1, 32]> : tensor<2xi64>} : (tensor<4608x32xcomplex<f32>>, tensor<2048xui32>) -> tensor<2048x32xcomplex<f32>>
    %38 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %39 = stablehlo.multiply %35, %38 : tensor<2x2048x2x32xcomplex<f32>>
    %40 = stablehlo.real %39 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %41 = stablehlo.reshape %40 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %42 = stablehlo.imag %39 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %43 = stablehlo.reshape %42 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %44 = stablehlo.concatenate %41, %43, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %45 = stablehlo.reshape %44 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %47 = stablehlo.reshape %46 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %48 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %49 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %50 = stablehlo.add %arg25, %49 : tensor<2048xi64>
    %51 = stablehlo.select %48, %50, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %52 = stablehlo.reshape %51 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %53 = stablehlo.reshape %26 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %54 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %55 = stablehlo.dot %53, %54, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %56 = stablehlo.reshape %55 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %57 = stablehlo.slice %56 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %58 = stablehlo.reshape %57 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %59 = stablehlo.slice %56 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %60 = stablehlo.reshape %59 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %61 = stablehlo.complex %58, %60 : tensor<2x2048x2x32xcomplex<f32>>
    %62 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %63 = stablehlo.multiply %61, %62 : tensor<2x2048x2x32xcomplex<f32>>
    %64 = stablehlo.real %63 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %65 = stablehlo.reshape %64 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %66 = stablehlo.imag %63 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %67 = stablehlo.reshape %66 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %68 = stablehlo.concatenate %65, %67, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %69 = stablehlo.reshape %68 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %70 = "stablehlo.scatter"(%arg32, %52, %69) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %71 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %72 = "stablehlo.gather"(%70, %71) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %73 = stablehlo.transpose %72, dims = [0, 2, 3, 1] : (tensor<2x2048x2x64xf32>) -> tensor<2x2x64x2048xf32>
    %74 = stablehlo.reshape %73 : (tensor<2x2x64x2048xf32>) -> tensor<4x64x2048xf32>
    %75 = stablehlo.dot_general %47, %74, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x64xf32>, tensor<4x64x2048xf32>) -> tensor<4x2048x2048xf32>
    %76 = stablehlo.reshape %75 : (tensor<4x2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %77 = stablehlo.broadcast_in_dim %arg29, dims = [] : (tensor<f32>) -> tensor<2x2x2048x2048xf32>
    %78 = stablehlo.divide %76, %77 : tensor<2x2x2048x2048xf32>
    %79 = stablehlo.broadcast_in_dim %5, dims = [1] : (tensor<2048xi64>) -> tensor<2048x2048xi64>
    %80 = stablehlo.broadcast_in_dim %5, dims = [0] : (tensor<2048xi64>) -> tensor<2048x2048xi64>
    %81 = stablehlo.subtract %79, %80 : tensor<2048x2048xi64>
    %82 = stablehlo.compare  GE, %81, %4 : (tensor<2048x2048xi64>, tensor<2048x2048xi64>) -> tensor<2048x2048xi1>
    %83 = stablehlo.reshape %82 : (tensor<2048x2048xi1>) -> tensor<1x1x2048x2048xi1>
    %84 = stablehlo.reshape %arg28 : (tensor<f32>) -> tensor<1x1xf32>
    %85 = stablehlo.broadcast_in_dim %84, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x2048x2048xf32>
    %86 = stablehlo.select %83, %85, %3 : tensor<1x1x2048x2048xi1>, tensor<1x1x2048x2048xf32>
    %87 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %89 = stablehlo.add %78, %88 : tensor<2x2x2048x2048xf32>
    %90 = stablehlo.reduce(%89 init: %7) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.maximum %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %91 = stablehlo.broadcast_in_dim %90, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %92 = stablehlo.subtract %89, %91 : tensor<2x2x2048x2048xf32>
    %93 = stablehlo.exponential %92 : tensor<2x2x2048x2048xf32>
    %94 = stablehlo.reduce(%93 init: %8) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %95 = stablehlo.broadcast_in_dim %94, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %96 = stablehlo.divide %93, %95 : tensor<2x2x2048x2048xf32>
    %97 = stablehlo.reshape %96 : (tensor<2x2x2048x2048xf32>) -> tensor<4x2048x2048xf32>
    %98 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %99 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %100 = stablehlo.add %arg25, %99 : tensor<2048xi64>
    %101 = stablehlo.select %98, %100, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %102 = stablehlo.reshape %101 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %103 = stablehlo.reshape %26 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %104 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %105 = stablehlo.dot %103, %104, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %106 = stablehlo.reshape %105 : (tensor<4096x128xf32>) -> tensor<2x2048x2x64xf32>
    %107 = "stablehlo.scatter"(%arg27, %102, %106) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %108 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %109 = "stablehlo.gather"(%107, %108) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %110 = stablehlo.transpose %109, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %111 = stablehlo.reshape %110 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %112 = stablehlo.dot_general %97, %111, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x2048xf32>, tensor<4x2048x64xf32>) -> tensor<4x2048x64xf32>
    %113 = stablehlo.reshape %112 : (tensor<4x2048x64xf32>) -> tensor<2x2x2048x64xf32>
    %114 = stablehlo.transpose %113, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,2,64]{3,1,2,0}"} : (tensor<2x2x2048x64xf32>) -> tensor<2x2048x2x64xf32>
    %115 = stablehlo.reshape %114 : (tensor<2x2048x2x64xf32>) -> tensor<4096x128xf32>
    %116 = stablehlo.transpose %arg19, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %117 = stablehlo.dot %115, %116, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %118 = stablehlo.reshape %117 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %119 = stablehlo.add %14, %118 : tensor<2x2048x128xf32>
    %120 = stablehlo.power %119, %1 : tensor<2x2048x128xf32>
    %121 = stablehlo.reduce(%120 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %122 = stablehlo.multiply %121, %0 : tensor<2x2048xf32>
    %123 = stablehlo.reshape %122 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %124 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %125 = stablehlo.add %123, %124 : tensor<2x2048x1xf32>
    %126 = stablehlo.rsqrt %125 : tensor<2x2048x1xf32>
    %127 = stablehlo.reshape %126 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %128 = stablehlo.broadcast_in_dim %127, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %129 = stablehlo.multiply %119, %128 : tensor<2x2048x128xf32>
    %130 = stablehlo.broadcast_in_dim %arg18, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %131 = stablehlo.multiply %129, %130 : tensor<2x2048x128xf32>
    %132 = stablehlo.reshape %131 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %133 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %134 = stablehlo.dot %132, %133, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %135 = stablehlo.reshape %134 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %136 = stablehlo.logistic %135 : tensor<2x2048x352xf32>
    %137 = stablehlo.multiply %135, %136 : tensor<2x2048x352xf32>
    %138 = stablehlo.reshape %131 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %139 = stablehlo.transpose %arg17, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %140 = stablehlo.dot %138, %139, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %141 = stablehlo.reshape %140 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %142 = stablehlo.multiply %137, %141 : tensor<2x2048x352xf32>
    %143 = stablehlo.reshape %142 : (tensor<2x2048x352xf32>) -> tensor<4096x352xf32>
    %144 = stablehlo.transpose %arg16, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[352,128]{0,1}"} : (tensor<128x352xf32>) -> tensor<352x128xf32>
    %145 = stablehlo.dot %143, %144, precision = [DEFAULT, DEFAULT] : (tensor<4096x352xf32>, tensor<352x128xf32>) -> tensor<4096x128xf32>
    %146 = stablehlo.reshape %145 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %147 = stablehlo.add %119, %146 : tensor<2x2048x128xf32>
    %148 = stablehlo.power %147, %1 : tensor<2x2048x128xf32>
    %149 = stablehlo.reduce(%148 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %150 = stablehlo.multiply %149, %0 : tensor<2x2048xf32>
    %151 = stablehlo.reshape %150 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %152 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %153 = stablehlo.add %151, %152 : tensor<2x2048x1xf32>
    %154 = stablehlo.rsqrt %153 : tensor<2x2048x1xf32>
    %155 = stablehlo.reshape %154 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %156 = stablehlo.broadcast_in_dim %155, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %157 = stablehlo.multiply %147, %156 : tensor<2x2048x128xf32>
    %158 = stablehlo.broadcast_in_dim %arg15, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %159 = stablehlo.multiply %157, %158 : tensor<2x2048x128xf32>
    %160 = stablehlo.reshape %159 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %161 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %162 = stablehlo.dot %160, %161, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %163 = stablehlo.reshape %162 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %164 = stablehlo.slice %163 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %166 = stablehlo.slice %163 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %167 = stablehlo.reshape %166 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %168 = stablehlo.complex %165, %167 : tensor<2x2048x2x32xcomplex<f32>>
    %169 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %170 = stablehlo.multiply %168, %169 : tensor<2x2048x2x32xcomplex<f32>>
    %171 = stablehlo.real %170 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %172 = stablehlo.reshape %171 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %173 = stablehlo.imag %170 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %174 = stablehlo.reshape %173 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %175 = stablehlo.concatenate %172, %174, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %176 = stablehlo.reshape %175 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %177 = stablehlo.transpose %176, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %178 = stablehlo.reshape %177 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %179 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %180 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %181 = stablehlo.add %arg25, %180 : tensor<2048xi64>
    %182 = stablehlo.select %179, %181, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %183 = stablehlo.reshape %182 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %184 = stablehlo.reshape %159 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %185 = stablehlo.transpose %arg36, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %186 = stablehlo.dot %184, %185, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %187 = stablehlo.reshape %186 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %188 = stablehlo.slice %187 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %189 = stablehlo.reshape %188 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %190 = stablehlo.slice %187 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %191 = stablehlo.reshape %190 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %192 = stablehlo.complex %189, %191 : tensor<2x2048x2x32xcomplex<f32>>
    %193 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %194 = stablehlo.multiply %192, %193 : tensor<2x2048x2x32xcomplex<f32>>
    %195 = stablehlo.real %194 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %196 = stablehlo.reshape %195 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %197 = stablehlo.imag %194 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %198 = stablehlo.reshape %197 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %199 = stablehlo.concatenate %196, %198, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %200 = stablehlo.reshape %199 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %201 = "stablehlo.scatter"(%arg37, %183, %200) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %202 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %203 = "stablehlo.gather"(%201, %202) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %204 = stablehlo.transpose %203, dims = [0, 2, 3, 1] : (tensor<2x2048x2x64xf32>) -> tensor<2x2x64x2048xf32>
    %205 = stablehlo.reshape %204 : (tensor<2x2x64x2048xf32>) -> tensor<4x64x2048xf32>
    %206 = stablehlo.dot_general %178, %205, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x64xf32>, tensor<4x64x2048xf32>) -> tensor<4x2048x2048xf32>
    %207 = stablehlo.reshape %206 : (tensor<4x2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %208 = stablehlo.broadcast_in_dim %arg29, dims = [] : (tensor<f32>) -> tensor<2x2x2048x2048xf32>
    %209 = stablehlo.divide %207, %208 : tensor<2x2x2048x2048xf32>
    %210 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %211 = stablehlo.broadcast_in_dim %210, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %212 = stablehlo.add %209, %211 : tensor<2x2x2048x2048xf32>
    %213 = stablehlo.reduce(%212 init: %7) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.maximum %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %214 = stablehlo.broadcast_in_dim %213, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %215 = stablehlo.subtract %212, %214 : tensor<2x2x2048x2048xf32>
    %216 = stablehlo.exponential %215 : tensor<2x2x2048x2048xf32>
    %217 = stablehlo.reduce(%216 init: %8) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %219 = stablehlo.divide %216, %218 : tensor<2x2x2048x2048xf32>
    %220 = stablehlo.reshape %219 : (tensor<2x2x2048x2048xf32>) -> tensor<4x2048x2048xf32>
    %221 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %222 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %223 = stablehlo.add %arg25, %222 : tensor<2048xi64>
    %224 = stablehlo.select %221, %223, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %225 = stablehlo.reshape %224 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %226 = stablehlo.reshape %159 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %227 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %228 = stablehlo.dot %226, %227, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %229 = stablehlo.reshape %228 : (tensor<4096x128xf32>) -> tensor<2x2048x2x64xf32>
    %230 = "stablehlo.scatter"(%arg35, %225, %229) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %231 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %232 = "stablehlo.gather"(%230, %231) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %233 = stablehlo.transpose %232, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %234 = stablehlo.reshape %233 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %235 = stablehlo.dot_general %220, %234, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x2048xf32>, tensor<4x2048x64xf32>) -> tensor<4x2048x64xf32>
    %236 = stablehlo.reshape %235 : (tensor<4x2048x64xf32>) -> tensor<2x2x2048x64xf32>
    %237 = stablehlo.transpose %236, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,2,64]{3,1,2,0}"} : (tensor<2x2x2048x64xf32>) -> tensor<2x2048x2x64xf32>
    %238 = stablehlo.reshape %237 : (tensor<2x2048x2x64xf32>) -> tensor<4096x128xf32>
    %239 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %240 = stablehlo.dot %238, %239, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %241 = stablehlo.reshape %240 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %242 = stablehlo.add %147, %241 : tensor<2x2048x128xf32>
    %243 = stablehlo.power %242, %1 : tensor<2x2048x128xf32>
    %244 = stablehlo.reduce(%243 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %245 = stablehlo.multiply %244, %0 : tensor<2x2048xf32>
    %246 = stablehlo.reshape %245 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %247 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %248 = stablehlo.add %246, %247 : tensor<2x2048x1xf32>
    %249 = stablehlo.rsqrt %248 : tensor<2x2048x1xf32>
    %250 = stablehlo.reshape %249 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %251 = stablehlo.broadcast_in_dim %250, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %252 = stablehlo.multiply %242, %251 : tensor<2x2048x128xf32>
    %253 = stablehlo.broadcast_in_dim %arg12, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %254 = stablehlo.multiply %252, %253 : tensor<2x2048x128xf32>
    %255 = stablehlo.reshape %254 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %256 = stablehlo.transpose %arg39, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %257 = stablehlo.dot %255, %256, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %258 = stablehlo.reshape %257 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %259 = stablehlo.logistic %258 : tensor<2x2048x352xf32>
    %260 = stablehlo.multiply %258, %259 : tensor<2x2048x352xf32>
    %261 = stablehlo.reshape %254 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %262 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %263 = stablehlo.dot %261, %262, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %264 = stablehlo.reshape %263 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %265 = stablehlo.multiply %260, %264 : tensor<2x2048x352xf32>
    %266 = stablehlo.reshape %265 : (tensor<2x2048x352xf32>) -> tensor<4096x352xf32>
    %267 = stablehlo.transpose %arg10, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[352,128]{0,1}"} : (tensor<128x352xf32>) -> tensor<352x128xf32>
    %268 = stablehlo.dot %266, %267, precision = [DEFAULT, DEFAULT] : (tensor<4096x352xf32>, tensor<352x128xf32>) -> tensor<4096x128xf32>
    %269 = stablehlo.reshape %268 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %270 = stablehlo.add %242, %269 : tensor<2x2048x128xf32>
    %271 = stablehlo.power %270, %1 : tensor<2x2048x128xf32>
    %272 = stablehlo.reduce(%271 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %273 = stablehlo.multiply %272, %0 : tensor<2x2048xf32>
    %274 = stablehlo.reshape %273 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %275 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %276 = stablehlo.add %274, %275 : tensor<2x2048x1xf32>
    %277 = stablehlo.rsqrt %276 : tensor<2x2048x1xf32>
    %278 = stablehlo.reshape %277 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %279 = stablehlo.broadcast_in_dim %278, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %280 = stablehlo.multiply %270, %279 : tensor<2x2048x128xf32>
    %281 = stablehlo.broadcast_in_dim %arg9, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %282 = stablehlo.multiply %280, %281 : tensor<2x2048x128xf32>
    %283 = stablehlo.reshape %282 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %284 = stablehlo.transpose %arg43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %285 = stablehlo.dot %283, %284, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %286 = stablehlo.reshape %285 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %287 = stablehlo.slice %286 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %288 = stablehlo.reshape %287 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %289 = stablehlo.slice %286 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %290 = stablehlo.reshape %289 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %291 = stablehlo.complex %288, %290 : tensor<2x2048x2x32xcomplex<f32>>
    %292 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %293 = stablehlo.multiply %291, %292 : tensor<2x2048x2x32xcomplex<f32>>
    %294 = stablehlo.real %293 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %295 = stablehlo.reshape %294 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %296 = stablehlo.imag %293 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %297 = stablehlo.reshape %296 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %298 = stablehlo.concatenate %295, %297, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %299 = stablehlo.reshape %298 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %300 = stablehlo.transpose %299, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %301 = stablehlo.reshape %300 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %302 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %303 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %304 = stablehlo.add %arg25, %303 : tensor<2048xi64>
    %305 = stablehlo.select %302, %304, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %306 = stablehlo.reshape %305 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %307 = stablehlo.reshape %282 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %308 = stablehlo.transpose %arg41, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %309 = stablehlo.dot %307, %308, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %310 = stablehlo.reshape %309 : (tensor<4096x128xf32>) -> tensor<2x2048x2x32x2xf32>
    %311 = stablehlo.slice %310 [0:2, 0:2048, 0:2, 0:32, 0:1] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %312 = stablehlo.reshape %311 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %313 = stablehlo.slice %310 [0:2, 0:2048, 0:2, 0:32, 1:2] : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x32x1xf32>
    %314 = stablehlo.reshape %313 : (tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32xf32>
    %315 = stablehlo.complex %312, %314 : tensor<2x2048x2x32xcomplex<f32>>
    %316 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x32xcomplex<f32>>) -> tensor<2x2048x2x32xcomplex<f32>>
    %317 = stablehlo.multiply %315, %316 : tensor<2x2048x2x32xcomplex<f32>>
    %318 = stablehlo.real %317 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %319 = stablehlo.reshape %318 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %320 = stablehlo.imag %317 : (tensor<2x2048x2x32xcomplex<f32>>) -> tensor<2x2048x2x32xf32>
    %321 = stablehlo.reshape %320 : (tensor<2x2048x2x32xf32>) -> tensor<2x2048x2x32x1xf32>
    %322 = stablehlo.concatenate %319, %321, dim = 4 : (tensor<2x2048x2x32x1xf32>, tensor<2x2048x2x32x1xf32>) -> tensor<2x2048x2x32x2xf32>
    %323 = stablehlo.reshape %322 : (tensor<2x2048x2x32x2xf32>) -> tensor<2x2048x2x64xf32>
    %324 = "stablehlo.scatter"(%arg42, %306, %323) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %325 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %326 = "stablehlo.gather"(%324, %325) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %327 = stablehlo.transpose %326, dims = [0, 2, 3, 1] : (tensor<2x2048x2x64xf32>) -> tensor<2x2x64x2048xf32>
    %328 = stablehlo.reshape %327 : (tensor<2x2x64x2048xf32>) -> tensor<4x64x2048xf32>
    %329 = stablehlo.dot_general %301, %328, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x64xf32>, tensor<4x64x2048xf32>) -> tensor<4x2048x2048xf32>
    %330 = stablehlo.reshape %329 : (tensor<4x2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %331 = stablehlo.broadcast_in_dim %arg29, dims = [] : (tensor<f32>) -> tensor<2x2x2048x2048xf32>
    %332 = stablehlo.divide %330, %331 : tensor<2x2x2048x2048xf32>
    %333 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %334 = stablehlo.broadcast_in_dim %333, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %335 = stablehlo.add %332, %334 : tensor<2x2x2048x2048xf32>
    %336 = stablehlo.reduce(%335 init: %7) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.maximum %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %337 = stablehlo.broadcast_in_dim %336, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %338 = stablehlo.subtract %335, %337 : tensor<2x2x2048x2048xf32>
    %339 = stablehlo.exponential %338 : tensor<2x2x2048x2048xf32>
    %340 = stablehlo.reduce(%339 init: %8) across dimensions = [3] : (tensor<2x2x2048x2048xf32>, tensor<f32>) -> tensor<2x2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %341 = stablehlo.broadcast_in_dim %340, dims = [0, 1, 2] : (tensor<2x2x2048xf32>) -> tensor<2x2x2048x2048xf32>
    %342 = stablehlo.divide %339, %341 : tensor<2x2x2048x2048xf32>
    %343 = stablehlo.reshape %342 : (tensor<2x2x2048x2048xf32>) -> tensor<4x2048x2048xf32>
    %344 = stablehlo.compare  LT, %arg25, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %345 = stablehlo.broadcast_in_dim %arg26, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %346 = stablehlo.add %arg25, %345 : tensor<2048xi64>
    %347 = stablehlo.select %344, %346, %arg25 : tensor<2048xi1>, tensor<2048xi64>
    %348 = stablehlo.reshape %347 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %349 = stablehlo.reshape %282 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %350 = stablehlo.transpose %arg8, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %351 = stablehlo.dot %349, %350, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %352 = stablehlo.reshape %351 : (tensor<4096x128xf32>) -> tensor<2x2048x2x64xf32>
    %353 = "stablehlo.scatter"(%arg40, %348, %352) ({
    ^bb0(%arg45: tensor<f32>, %arg46: tensor<f32>):
      stablehlo.return %arg46 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x2x64xf32>, tensor<2048x1xi64>, tensor<2x2048x2x64xf32>) -> tensor<2x2304x2x64xf32>
    %354 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %355 = "stablehlo.gather"(%353, %354) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 2, 64]> : tensor<4xi64>} : (tensor<2x2304x2x64xf32>, tensor<2048xui32>) -> tensor<2x2048x2x64xf32>
    %356 = stablehlo.transpose %355, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2,2048,64]{3,1,2,0}"} : (tensor<2x2048x2x64xf32>) -> tensor<2x2x2048x64xf32>
    %357 = stablehlo.reshape %356 : (tensor<2x2x2048x64xf32>) -> tensor<4x2048x64xf32>
    %358 = stablehlo.dot_general %343, %357, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<4x2048x2048xf32>, tensor<4x2048x64xf32>) -> tensor<4x2048x64xf32>
    %359 = stablehlo.reshape %358 : (tensor<4x2048x64xf32>) -> tensor<2x2x2048x64xf32>
    %360 = stablehlo.transpose %359, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,2,64]{3,1,2,0}"} : (tensor<2x2x2048x64xf32>) -> tensor<2x2048x2x64xf32>
    %361 = stablehlo.reshape %360 : (tensor<2x2048x2x64xf32>) -> tensor<4096x128xf32>
    %362 = stablehlo.transpose %arg6, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,128]{0,1}"} : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %363 = stablehlo.dot %361, %362, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x128xf32>) -> tensor<4096x128xf32>
    %364 = stablehlo.reshape %363 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %365 = stablehlo.add %270, %364 : tensor<2x2048x128xf32>
    %366 = stablehlo.power %365, %1 : tensor<2x2048x128xf32>
    %367 = stablehlo.reduce(%366 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %368 = stablehlo.multiply %367, %0 : tensor<2x2048xf32>
    %369 = stablehlo.reshape %368 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %370 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %371 = stablehlo.add %369, %370 : tensor<2x2048x1xf32>
    %372 = stablehlo.rsqrt %371 : tensor<2x2048x1xf32>
    %373 = stablehlo.reshape %372 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %374 = stablehlo.broadcast_in_dim %373, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %375 = stablehlo.multiply %365, %374 : tensor<2x2048x128xf32>
    %376 = stablehlo.broadcast_in_dim %arg5, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %377 = stablehlo.multiply %375, %376 : tensor<2x2048x128xf32>
    %378 = stablehlo.reshape %377 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %379 = stablehlo.transpose %arg44, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %380 = stablehlo.dot %378, %379, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %381 = stablehlo.reshape %380 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %382 = stablehlo.logistic %381 : tensor<2x2048x352xf32>
    %383 = stablehlo.multiply %381, %382 : tensor<2x2048x352xf32>
    %384 = stablehlo.reshape %377 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %385 = stablehlo.transpose %arg4, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,352]{0,1}"} : (tensor<352x128xf32>) -> tensor<128x352xf32>
    %386 = stablehlo.dot %384, %385, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x352xf32>) -> tensor<4096x352xf32>
    %387 = stablehlo.reshape %386 : (tensor<4096x352xf32>) -> tensor<2x2048x352xf32>
    %388 = stablehlo.multiply %383, %387 : tensor<2x2048x352xf32>
    %389 = stablehlo.reshape %388 : (tensor<2x2048x352xf32>) -> tensor<4096x352xf32>
    %390 = stablehlo.transpose %arg3, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[352,128]{0,1}"} : (tensor<128x352xf32>) -> tensor<352x128xf32>
    %391 = stablehlo.dot %389, %390, precision = [DEFAULT, DEFAULT] : (tensor<4096x352xf32>, tensor<352x128xf32>) -> tensor<4096x128xf32>
    %392 = stablehlo.reshape %391 : (tensor<4096x128xf32>) -> tensor<2x2048x128xf32>
    %393 = stablehlo.add %365, %392 : tensor<2x2048x128xf32>
    %394 = stablehlo.power %393, %1 : tensor<2x2048x128xf32>
    %395 = stablehlo.reduce(%394 init: %8) across dimensions = [2] : (tensor<2x2048x128xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg45: tensor<f32>, %arg46: tensor<f32>)  {
      %410 = stablehlo.add %arg45, %arg46 : tensor<f32>
      stablehlo.return %410 : tensor<f32>
    }
    %396 = stablehlo.multiply %395, %0 : tensor<2x2048xf32>
    %397 = stablehlo.reshape %396 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %398 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %399 = stablehlo.add %397, %398 : tensor<2x2048x1xf32>
    %400 = stablehlo.rsqrt %399 : tensor<2x2048x1xf32>
    %401 = stablehlo.reshape %400 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %402 = stablehlo.broadcast_in_dim %401, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x128xf32>
    %403 = stablehlo.multiply %393, %402 : tensor<2x2048x128xf32>
    %404 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<128xf32>) -> tensor<2x2048x128xf32>
    %405 = stablehlo.multiply %403, %404 : tensor<2x2048x128xf32>
    %406 = stablehlo.reshape %405 : (tensor<2x2048x128xf32>) -> tensor<4096x128xf32>
    %407 = stablehlo.transpose %arg0, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[128,32000]{0,1}"} : (tensor<32000x128xf32>) -> tensor<128x32000xf32>
    %408 = stablehlo.dot %406, %407, precision = [DEFAULT, DEFAULT] : (tensor<4096x128xf32>, tensor<128x32000xf32>) -> tensor<4096x32000xf32>
    %409 = stablehlo.reshape %408 : (tensor<4096x32000xf32>) -> tensor<2x2048x32000xf32>
    return %409, %70, %107, %201, %230, %324, %353 : tensor<2x2048x32000xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>, tensor<2x2304x2x64xf32>
  }
}
