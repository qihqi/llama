module @IrToHlo.8005 attributes {mhlo.cross_program_prefetches = [], mhlo.is_dynamic = false, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<32000x4096xf32>, %arg1: tensor<4096xf32>, %arg2: tensor<f32>, %arg3: tensor<4096x11008xf32>, %arg4: tensor<11008x4096xf32>, %arg5: tensor<4096xf32>, %arg6: tensor<4096x4096xf32>, %arg7: tensor<2048xi64>, %arg8: tensor<4096x4096xf32>, %arg9: tensor<4096xf32>, %arg10: tensor<4096x11008xf32>, %arg11: tensor<11008x4096xf32>, %arg12: tensor<4096xf32>, %arg13: tensor<4096x4096xf32>, %arg14: tensor<4096x4096xf32>, %arg15: tensor<4096xf32>, %arg16: tensor<4096x11008xf32>, %arg17: tensor<11008x4096xf32>, %arg18: tensor<4096xf32>, %arg19: tensor<4096x4096xf32>, %arg20: tensor<4096x4096xf32>, %arg21: tensor<4096xf32>, %arg22: tensor<4096x11008xf32>, %arg23: tensor<11008x4096xf32>, %arg24: tensor<4096xf32>, %arg25: tensor<4096x4096xf32>, %arg26: tensor<4096x4096xf32>, %arg27: tensor<4096xf32>, %arg28: tensor<4096x11008xf32>, %arg29: tensor<11008x4096xf32>, %arg30: tensor<4096xf32>, %arg31: tensor<4096x4096xf32>, %arg32: tensor<4096x4096xf32>, %arg33: tensor<4096xf32>, %arg34: tensor<4096x11008xf32>, %arg35: tensor<11008x4096xf32>, %arg36: tensor<4096xf32>, %arg37: tensor<4096x4096xf32>, %arg38: tensor<4096x4096xf32>, %arg39: tensor<4096xf32>, %arg40: tensor<4096x11008xf32>, %arg41: tensor<11008x4096xf32>, %arg42: tensor<4096xf32>, %arg43: tensor<4096x4096xf32>, %arg44: tensor<4096x4096xf32>, %arg45: tensor<4096xf32>, %arg46: tensor<4096x11008xf32>, %arg47: tensor<11008x4096xf32>, %arg48: tensor<4096xf32>, %arg49: tensor<4096x4096xf32>, %arg50: tensor<4096x4096xf32>, %arg51: tensor<4096xf32>, %arg52: tensor<4096x11008xf32>, %arg53: tensor<11008x4096xf32>, %arg54: tensor<4096xf32>, %arg55: tensor<4096x4096xf32>, %arg56: tensor<4096x4096xf32>, %arg57: tensor<4096xf32>, %arg58: tensor<4096x11008xf32>, %arg59: tensor<11008x4096xf32>, %arg60: tensor<4096xf32>, %arg61: tensor<4096x4096xf32>, %arg62: tensor<4096x4096xf32>, %arg63: tensor<4096xf32>, %arg64: tensor<4096x11008xf32>, %arg65: tensor<11008x4096xf32>, %arg66: tensor<4096xf32>, %arg67: tensor<4096x4096xf32>, %arg68: tensor<4096x4096xf32>, %arg69: tensor<4096xf32>, %arg70: tensor<4096x11008xf32>, %arg71: tensor<11008x4096xf32>, %arg72: tensor<4096xf32>, %arg73: tensor<4096x4096xf32>, %arg74: tensor<4096x4096xf32>, %arg75: tensor<4096xf32>, %arg76: tensor<4096x11008xf32>, %arg77: tensor<11008x4096xf32>, %arg78: tensor<4096xf32>, %arg79: tensor<4096x4096xf32>, %arg80: tensor<4096x4096xf32>, %arg81: tensor<4096xf32>, %arg82: tensor<4096x11008xf32>, %arg83: tensor<11008x4096xf32>, %arg84: tensor<4096xf32>, %arg85: tensor<4096x4096xf32>, %arg86: tensor<4096x4096xf32>, %arg87: tensor<4096xf32>, %arg88: tensor<4096x11008xf32>, %arg89: tensor<11008x4096xf32>, %arg90: tensor<4096xf32>, %arg91: tensor<4096x4096xf32>, %arg92: tensor<4096x4096xf32>, %arg93: tensor<4096xf32>, %arg94: tensor<4096x11008xf32>, %arg95: tensor<11008x4096xf32>, %arg96: tensor<4096xf32>, %arg97: tensor<4096x4096xf32>, %arg98: tensor<4096x4096xf32>, %arg99: tensor<4096xf32>, %arg100: tensor<4096x11008xf32>, %arg101: tensor<11008x4096xf32>, %arg102: tensor<4096xf32>, %arg103: tensor<4096x4096xf32>, %arg104: tensor<4096x4096xf32>, %arg105: tensor<4096xf32>, %arg106: tensor<4096x11008xf32>, %arg107: tensor<11008x4096xf32>, %arg108: tensor<4096xf32>, %arg109: tensor<4096x4096xf32>, %arg110: tensor<4096x4096xf32>, %arg111: tensor<4096xf32>, %arg112: tensor<4096x11008xf32>, %arg113: tensor<11008x4096xf32>, %arg114: tensor<4096xf32>, %arg115: tensor<4096x4096xf32>, %arg116: tensor<4096x4096xf32>, %arg117: tensor<4096xf32>, %arg118: tensor<4096x11008xf32>, %arg119: tensor<11008x4096xf32>, %arg120: tensor<4096xf32>, %arg121: tensor<4096x4096xf32>, %arg122: tensor<4096x4096xf32>, %arg123: tensor<4096xf32>, %arg124: tensor<4096x11008xf32>, %arg125: tensor<11008x4096xf32>, %arg126: tensor<4096xf32>, %arg127: tensor<4096x4096xf32>, %arg128: tensor<4096x4096xf32>, %arg129: tensor<4096xf32>, %arg130: tensor<4096x11008xf32>, %arg131: tensor<11008x4096xf32>, %arg132: tensor<4096xf32>, %arg133: tensor<4096x4096xf32>, %arg134: tensor<4096x4096xf32>, %arg135: tensor<4096xf32>, %arg136: tensor<4096x11008xf32>, %arg137: tensor<11008x4096xf32>, %arg138: tensor<4096xf32>, %arg139: tensor<4096x4096xf32>, %arg140: tensor<4096x4096xf32>, %arg141: tensor<4096xf32>, %arg142: tensor<4096x11008xf32>, %arg143: tensor<11008x4096xf32>, %arg144: tensor<4096xf32>, %arg145: tensor<4096x4096xf32>, %arg146: tensor<4096x4096xf32>, %arg147: tensor<4096xf32>, %arg148: tensor<4096x11008xf32>, %arg149: tensor<11008x4096xf32>, %arg150: tensor<4096xf32>, %arg151: tensor<4096x4096xf32>, %arg152: tensor<4096x4096xf32>, %arg153: tensor<4096xf32>, %arg154: tensor<4096x11008xf32>, %arg155: tensor<11008x4096xf32>, %arg156: tensor<4096xf32>, %arg157: tensor<4096x4096xf32>, %arg158: tensor<4096x4096xf32>, %arg159: tensor<4096xf32>, %arg160: tensor<4096x11008xf32>, %arg161: tensor<11008x4096xf32>, %arg162: tensor<4096xf32>, %arg163: tensor<4096x4096xf32>, %arg164: tensor<4096x4096xf32>, %arg165: tensor<4096xf32>, %arg166: tensor<4096x11008xf32>, %arg167: tensor<11008x4096xf32>, %arg168: tensor<4096xf32>, %arg169: tensor<4096x4096xf32>, %arg170: tensor<4096x4096xf32>, %arg171: tensor<4096xf32>, %arg172: tensor<4096x11008xf32>, %arg173: tensor<11008x4096xf32>, %arg174: tensor<4096xf32>, %arg175: tensor<4096x4096xf32>, %arg176: tensor<4096x4096xf32>, %arg177: tensor<4096xf32>, %arg178: tensor<4096x11008xf32>, %arg179: tensor<11008x4096xf32>, %arg180: tensor<4096xf32>, %arg181: tensor<4096x4096xf32>, %arg182: tensor<4096x4096xf32>, %arg183: tensor<4096xf32>, %arg184: tensor<4096x11008xf32>, %arg185: tensor<11008x4096xf32>, %arg186: tensor<4096xf32>, %arg187: tensor<4096x4096xf32>, %arg188: tensor<4096x4096xf32>, %arg189: tensor<4096xf32>, %arg190: tensor<4096x11008xf32>, %arg191: tensor<11008x4096xf32>, %arg192: tensor<4096xf32>, %arg193: tensor<4096x4096xf32>, %arg194: tensor<4096x4096xf32>, %arg195: tensor<4096xf32>, %arg196: tensor<2x2048xi64>, %arg197: tensor<i64>, %arg198: tensor<32000x4096xf32>, %arg199: tensor<2048xi64>, %arg200: tensor<i64>, %arg201: tensor<2x2304x32x128xf32>, %arg202: tensor<f32>, %arg203: tensor<f32>, %arg204: tensor<4608x64xcomplex<f32>>, %arg205: tensor<4096x4096xf32>, %arg206: tensor<2x2304x32x128xf32>, %arg207: tensor<4096x4096xf32>, %arg208: tensor<11008x4096xf32>, %arg209: tensor<2x2304x32x128xf32>, %arg210: tensor<4096x4096xf32>, %arg211: tensor<2x2304x32x128xf32>, %arg212: tensor<4096x4096xf32>, %arg213: tensor<11008x4096xf32>, %arg214: tensor<2x2304x32x128xf32>, %arg215: tensor<4096x4096xf32>, %arg216: tensor<2x2304x32x128xf32>, %arg217: tensor<4096x4096xf32>, %arg218: tensor<11008x4096xf32>, %arg219: tensor<2x2304x32x128xf32>, %arg220: tensor<4096x4096xf32>, %arg221: tensor<2x2304x32x128xf32>, %arg222: tensor<4096x4096xf32>, %arg223: tensor<11008x4096xf32>, %arg224: tensor<2x2304x32x128xf32>, %arg225: tensor<4096x4096xf32>, %arg226: tensor<2x2304x32x128xf32>, %arg227: tensor<4096x4096xf32>, %arg228: tensor<11008x4096xf32>, %arg229: tensor<2x2304x32x128xf32>, %arg230: tensor<4096x4096xf32>, %arg231: tensor<2x2304x32x128xf32>, %arg232: tensor<4096x4096xf32>, %arg233: tensor<11008x4096xf32>, %arg234: tensor<2x2304x32x128xf32>, %arg235: tensor<4096x4096xf32>, %arg236: tensor<2x2304x32x128xf32>, %arg237: tensor<4096x4096xf32>, %arg238: tensor<11008x4096xf32>, %arg239: tensor<2x2304x32x128xf32>, %arg240: tensor<4096x4096xf32>, %arg241: tensor<2x2304x32x128xf32>, %arg242: tensor<4096x4096xf32>, %arg243: tensor<11008x4096xf32>, %arg244: tensor<2x2304x32x128xf32>, %arg245: tensor<4096x4096xf32>, %arg246: tensor<2x2304x32x128xf32>, %arg247: tensor<4096x4096xf32>, %arg248: tensor<11008x4096xf32>, %arg249: tensor<2x2304x32x128xf32>, %arg250: tensor<4096x4096xf32>, %arg251: tensor<2x2304x32x128xf32>, %arg252: tensor<4096x4096xf32>, %arg253: tensor<11008x4096xf32>, %arg254: tensor<2x2304x32x128xf32>, %arg255: tensor<4096x4096xf32>, %arg256: tensor<2x2304x32x128xf32>, %arg257: tensor<4096x4096xf32>, %arg258: tensor<11008x4096xf32>, %arg259: tensor<2x2304x32x128xf32>, %arg260: tensor<4096x4096xf32>, %arg261: tensor<2x2304x32x128xf32>, %arg262: tensor<4096x4096xf32>, %arg263: tensor<11008x4096xf32>, %arg264: tensor<2x2304x32x128xf32>, %arg265: tensor<4096x4096xf32>, %arg266: tensor<2x2304x32x128xf32>, %arg267: tensor<4096x4096xf32>, %arg268: tensor<11008x4096xf32>, %arg269: tensor<2x2304x32x128xf32>, %arg270: tensor<4096x4096xf32>, %arg271: tensor<2x2304x32x128xf32>, %arg272: tensor<4096x4096xf32>, %arg273: tensor<11008x4096xf32>, %arg274: tensor<2x2304x32x128xf32>, %arg275: tensor<4096x4096xf32>, %arg276: tensor<2x2304x32x128xf32>, %arg277: tensor<4096x4096xf32>, %arg278: tensor<11008x4096xf32>, %arg279: tensor<2x2304x32x128xf32>, %arg280: tensor<4096x4096xf32>, %arg281: tensor<2x2304x32x128xf32>, %arg282: tensor<4096x4096xf32>, %arg283: tensor<11008x4096xf32>, %arg284: tensor<2x2304x32x128xf32>, %arg285: tensor<4096x4096xf32>, %arg286: tensor<2x2304x32x128xf32>, %arg287: tensor<4096x4096xf32>, %arg288: tensor<11008x4096xf32>, %arg289: tensor<2x2304x32x128xf32>, %arg290: tensor<4096x4096xf32>, %arg291: tensor<2x2304x32x128xf32>, %arg292: tensor<4096x4096xf32>, %arg293: tensor<11008x4096xf32>, %arg294: tensor<2x2304x32x128xf32>, %arg295: tensor<4096x4096xf32>, %arg296: tensor<2x2304x32x128xf32>, %arg297: tensor<4096x4096xf32>, %arg298: tensor<11008x4096xf32>, %arg299: tensor<2x2304x32x128xf32>, %arg300: tensor<4096x4096xf32>, %arg301: tensor<2x2304x32x128xf32>, %arg302: tensor<4096x4096xf32>, %arg303: tensor<11008x4096xf32>, %arg304: tensor<2x2304x32x128xf32>, %arg305: tensor<4096x4096xf32>, %arg306: tensor<2x2304x32x128xf32>, %arg307: tensor<4096x4096xf32>, %arg308: tensor<11008x4096xf32>, %arg309: tensor<2x2304x32x128xf32>, %arg310: tensor<4096x4096xf32>, %arg311: tensor<2x2304x32x128xf32>, %arg312: tensor<4096x4096xf32>, %arg313: tensor<11008x4096xf32>, %arg314: tensor<2x2304x32x128xf32>, %arg315: tensor<4096x4096xf32>, %arg316: tensor<2x2304x32x128xf32>, %arg317: tensor<4096x4096xf32>, %arg318: tensor<11008x4096xf32>, %arg319: tensor<2x2304x32x128xf32>, %arg320: tensor<4096x4096xf32>, %arg321: tensor<2x2304x32x128xf32>, %arg322: tensor<4096x4096xf32>, %arg323: tensor<11008x4096xf32>, %arg324: tensor<2x2304x32x128xf32>, %arg325: tensor<4096x4096xf32>, %arg326: tensor<2x2304x32x128xf32>, %arg327: tensor<4096x4096xf32>, %arg328: tensor<11008x4096xf32>, %arg329: tensor<2x2304x32x128xf32>, %arg330: tensor<4096x4096xf32>, %arg331: tensor<2x2304x32x128xf32>, %arg332: tensor<4096x4096xf32>, %arg333: tensor<11008x4096xf32>, %arg334: tensor<2x2304x32x128xf32>, %arg335: tensor<4096x4096xf32>, %arg336: tensor<2x2304x32x128xf32>, %arg337: tensor<4096x4096xf32>, %arg338: tensor<11008x4096xf32>, %arg339: tensor<2x2304x32x128xf32>, %arg340: tensor<4096x4096xf32>, %arg341: tensor<2x2304x32x128xf32>, %arg342: tensor<4096x4096xf32>, %arg343: tensor<11008x4096xf32>, %arg344: tensor<2x2304x32x128xf32>, %arg345: tensor<4096x4096xf32>, %arg346: tensor<2x2304x32x128xf32>, %arg347: tensor<4096x4096xf32>, %arg348: tensor<11008x4096xf32>, %arg349: tensor<2x2304x32x128xf32>, %arg350: tensor<4096x4096xf32>, %arg351: tensor<2x2304x32x128xf32>, %arg352: tensor<4096x4096xf32>, %arg353: tensor<11008x4096xf32>, %arg354: tensor<2x2304x32x128xf32>, %arg355: tensor<4096x4096xf32>, %arg356: tensor<2x2304x32x128xf32>, %arg357: tensor<4096x4096xf32>, %arg358: tensor<11008x4096xf32>, %arg359: tensor<2x2304x32x128xf32>, %arg360: tensor<4096x4096xf32>, %arg361: tensor<2x2304x32x128xf32>, %arg362: tensor<4096x4096xf32>, %arg363: tensor<11008x4096xf32>) -> (tensor<2x2048x32000xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>) {
    %0 = stablehlo.constant dense<2.44140625E-4> : tensor<2x2048xf32>
    %1 = stablehlo.constant dense<2.000000e+00> : tensor<2x2048x4096xf32>
    %2 = stablehlo.constant dense<0> : tensor<2048xi64>
    %3 = stablehlo.constant dense<0.000000e+00> : tensor<1x1x2048x2048xf32>
    %4 = stablehlo.constant dense<1> : tensor<2048x2048xi64>
    %5 = stablehlo.constant dense<"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tensor<2048xi64>
    %6 = stablehlo.constant dense<0> : tensor<2x2048xi64>
    %7 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %8 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %9 = stablehlo.compare  LT, %arg196, %6 : (tensor<2x2048xi64>, tensor<2x2048xi64>) -> tensor<2x2048xi1>
    %10 = stablehlo.broadcast_in_dim %arg197, dims = [] : (tensor<i64>) -> tensor<2x2048xi64>
    %11 = stablehlo.add %arg196, %10 : tensor<2x2048xi64>
    %12 = stablehlo.select %9, %11, %arg196 : tensor<2x2048xi1>, tensor<2x2048xi64>
    %13 = stablehlo.reshape %12 : (tensor<2x2048xi64>) -> tensor<2x2048x1xi64>
    %14 = "stablehlo.gather"(%arg198, %13) {dimension_numbers = #stablehlo.gather<offset_dims = [2], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 2>, indices_are_sorted = false, slice_sizes = dense<[1, 4096]> : tensor<2xi64>} : (tensor<32000x4096xf32>, tensor<2x2048x1xi64>) -> tensor<2x2048x4096xf32>
    %15 = stablehlo.power %14, %1 : tensor<2x2048x4096xf32>
    %16 = stablehlo.reduce(%15 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %17 = stablehlo.multiply %16, %0 : tensor<2x2048xf32>
    %18 = stablehlo.reshape %17 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %19 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %20 = stablehlo.add %18, %19 : tensor<2x2048x1xf32>
    %21 = stablehlo.rsqrt %20 : tensor<2x2048x1xf32>
    %22 = stablehlo.reshape %21 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %23 = stablehlo.broadcast_in_dim %22, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %24 = stablehlo.multiply %14, %23 : tensor<2x2048x4096xf32>
    %25 = stablehlo.broadcast_in_dim %arg195, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %26 = stablehlo.multiply %24, %25 : tensor<2x2048x4096xf32>
    %27 = stablehlo.reshape %26 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %28 = stablehlo.transpose %arg207, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %29 = stablehlo.dot %27, %28, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %30 = stablehlo.reshape %29 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %31 = stablehlo.slice %30 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %32 = stablehlo.reshape %31 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %33 = stablehlo.slice %30 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %34 = stablehlo.reshape %33 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %35 = stablehlo.complex %32, %34 : tensor<2x2048x32x64xcomplex<f32>>
    %36 = stablehlo.convert %arg199 : (tensor<2048xi64>) -> tensor<2048xui32>
    %37 = "stablehlo.gather"(%arg204, %36) {dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[1, 64]> : tensor<2xi64>} : (tensor<4608x64xcomplex<f32>>, tensor<2048xui32>) -> tensor<2048x64xcomplex<f32>>
    %38 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %39 = stablehlo.multiply %35, %38 : tensor<2x2048x32x64xcomplex<f32>>
    %40 = stablehlo.real %39 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %41 = stablehlo.reshape %40 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %42 = stablehlo.imag %39 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %43 = stablehlo.reshape %42 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %44 = stablehlo.concatenate %41, %43, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %45 = stablehlo.reshape %44 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %46 = stablehlo.transpose %45, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %47 = stablehlo.reshape %46 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %48 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %49 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %50 = stablehlo.add %arg199, %49 : tensor<2048xi64>
    %51 = stablehlo.select %48, %50, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %52 = stablehlo.reshape %51 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %53 = stablehlo.reshape %26 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %54 = stablehlo.transpose %arg205, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %55 = stablehlo.dot %53, %54, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %56 = stablehlo.reshape %55 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %57 = stablehlo.slice %56 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %58 = stablehlo.reshape %57 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %59 = stablehlo.slice %56 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %60 = stablehlo.reshape %59 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %61 = stablehlo.complex %58, %60 : tensor<2x2048x32x64xcomplex<f32>>
    %62 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %63 = stablehlo.multiply %61, %62 : tensor<2x2048x32x64xcomplex<f32>>
    %64 = stablehlo.real %63 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %65 = stablehlo.reshape %64 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %66 = stablehlo.imag %63 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %67 = stablehlo.reshape %66 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %68 = stablehlo.concatenate %65, %67, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %69 = stablehlo.reshape %68 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %70 = "stablehlo.scatter"(%arg206, %52, %69) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %71 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %72 = "stablehlo.gather"(%70, %71) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %73 = stablehlo.transpose %72, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %74 = stablehlo.reshape %73 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %75 = stablehlo.dot_general %47, %74, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %76 = stablehlo.reshape %75 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %77 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %78 = stablehlo.divide %76, %77 : tensor<2x32x2048x2048xf32>
    %79 = stablehlo.broadcast_in_dim %5, dims = [1] : (tensor<2048xi64>) -> tensor<2048x2048xi64>
    %80 = stablehlo.broadcast_in_dim %5, dims = [0] : (tensor<2048xi64>) -> tensor<2048x2048xi64>
    %81 = stablehlo.subtract %79, %80 : tensor<2048x2048xi64>
    %82 = stablehlo.compare  GE, %81, %4 : (tensor<2048x2048xi64>, tensor<2048x2048xi64>) -> tensor<2048x2048xi1>
    %83 = stablehlo.reshape %82 : (tensor<2048x2048xi1>) -> tensor<1x1x2048x2048xi1>
    %84 = stablehlo.reshape %arg202 : (tensor<f32>) -> tensor<1x1xf32>
    %85 = stablehlo.broadcast_in_dim %84, dims = [0, 1] : (tensor<1x1xf32>) -> tensor<1x1x2048x2048xf32>
    %86 = stablehlo.select %83, %85, %3 : tensor<1x1x2048x2048xi1>, tensor<1x1x2048x2048xf32>
    %87 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %88 = stablehlo.broadcast_in_dim %87, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %89 = stablehlo.add %78, %88 : tensor<2x32x2048x2048xf32>
    %90 = stablehlo.reduce(%89 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %91 = stablehlo.broadcast_in_dim %90, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %92 = stablehlo.subtract %89, %91 : tensor<2x32x2048x2048xf32>
    %93 = stablehlo.exponential %92 : tensor<2x32x2048x2048xf32>
    %94 = stablehlo.reduce(%93 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %95 = stablehlo.broadcast_in_dim %94, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %96 = stablehlo.divide %93, %95 : tensor<2x32x2048x2048xf32>
    %97 = stablehlo.reshape %96 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %98 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %99 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %100 = stablehlo.add %arg199, %99 : tensor<2048xi64>
    %101 = stablehlo.select %98, %100, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %102 = stablehlo.reshape %101 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %103 = stablehlo.reshape %26 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %104 = stablehlo.transpose %arg194, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %105 = stablehlo.dot %103, %104, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %106 = stablehlo.reshape %105 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %107 = "stablehlo.scatter"(%arg201, %102, %106) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %108 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %109 = "stablehlo.gather"(%107, %108) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %110 = stablehlo.transpose %109, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %111 = stablehlo.reshape %110 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %112 = stablehlo.dot_general %97, %111, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %113 = stablehlo.reshape %112 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %114 = stablehlo.transpose %113, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %115 = stablehlo.reshape %114 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %116 = stablehlo.transpose %arg193, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %117 = stablehlo.dot %115, %116, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %118 = stablehlo.reshape %117 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %119 = stablehlo.add %14, %118 : tensor<2x2048x4096xf32>
    %120 = stablehlo.power %119, %1 : tensor<2x2048x4096xf32>
    %121 = stablehlo.reduce(%120 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %122 = stablehlo.multiply %121, %0 : tensor<2x2048xf32>
    %123 = stablehlo.reshape %122 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %124 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %125 = stablehlo.add %123, %124 : tensor<2x2048x1xf32>
    %126 = stablehlo.rsqrt %125 : tensor<2x2048x1xf32>
    %127 = stablehlo.reshape %126 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %128 = stablehlo.broadcast_in_dim %127, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %129 = stablehlo.multiply %119, %128 : tensor<2x2048x4096xf32>
    %130 = stablehlo.broadcast_in_dim %arg192, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %131 = stablehlo.multiply %129, %130 : tensor<2x2048x4096xf32>
    %132 = stablehlo.reshape %131 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %133 = stablehlo.transpose %arg208, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %134 = stablehlo.dot %132, %133, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %135 = stablehlo.reshape %134 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %136 = stablehlo.logistic %135 : tensor<2x2048x11008xf32>
    %137 = stablehlo.multiply %135, %136 : tensor<2x2048x11008xf32>
    %138 = stablehlo.reshape %131 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %139 = stablehlo.transpose %arg191, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %140 = stablehlo.dot %138, %139, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %141 = stablehlo.reshape %140 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %142 = stablehlo.multiply %137, %141 : tensor<2x2048x11008xf32>
    %143 = stablehlo.reshape %142 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %144 = stablehlo.transpose %arg190, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %145 = stablehlo.dot %143, %144, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %146 = stablehlo.reshape %145 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %147 = stablehlo.add %119, %146 : tensor<2x2048x4096xf32>
    %148 = stablehlo.power %147, %1 : tensor<2x2048x4096xf32>
    %149 = stablehlo.reduce(%148 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %150 = stablehlo.multiply %149, %0 : tensor<2x2048xf32>
    %151 = stablehlo.reshape %150 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %152 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %153 = stablehlo.add %151, %152 : tensor<2x2048x1xf32>
    %154 = stablehlo.rsqrt %153 : tensor<2x2048x1xf32>
    %155 = stablehlo.reshape %154 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %156 = stablehlo.broadcast_in_dim %155, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %157 = stablehlo.multiply %147, %156 : tensor<2x2048x4096xf32>
    %158 = stablehlo.broadcast_in_dim %arg189, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %159 = stablehlo.multiply %157, %158 : tensor<2x2048x4096xf32>
    %160 = stablehlo.reshape %159 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %161 = stablehlo.transpose %arg212, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %162 = stablehlo.dot %160, %161, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %163 = stablehlo.reshape %162 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %164 = stablehlo.slice %163 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %165 = stablehlo.reshape %164 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %166 = stablehlo.slice %163 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %167 = stablehlo.reshape %166 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %168 = stablehlo.complex %165, %167 : tensor<2x2048x32x64xcomplex<f32>>
    %169 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %170 = stablehlo.multiply %168, %169 : tensor<2x2048x32x64xcomplex<f32>>
    %171 = stablehlo.real %170 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %172 = stablehlo.reshape %171 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %173 = stablehlo.imag %170 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %174 = stablehlo.reshape %173 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %175 = stablehlo.concatenate %172, %174, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %176 = stablehlo.reshape %175 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %177 = stablehlo.transpose %176, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %178 = stablehlo.reshape %177 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %179 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %180 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %181 = stablehlo.add %arg199, %180 : tensor<2048xi64>
    %182 = stablehlo.select %179, %181, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %183 = stablehlo.reshape %182 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %184 = stablehlo.reshape %159 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %185 = stablehlo.transpose %arg210, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %186 = stablehlo.dot %184, %185, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %187 = stablehlo.reshape %186 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %188 = stablehlo.slice %187 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %189 = stablehlo.reshape %188 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %190 = stablehlo.slice %187 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %191 = stablehlo.reshape %190 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %192 = stablehlo.complex %189, %191 : tensor<2x2048x32x64xcomplex<f32>>
    %193 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %194 = stablehlo.multiply %192, %193 : tensor<2x2048x32x64xcomplex<f32>>
    %195 = stablehlo.real %194 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %196 = stablehlo.reshape %195 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %197 = stablehlo.imag %194 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %198 = stablehlo.reshape %197 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %199 = stablehlo.concatenate %196, %198, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %200 = stablehlo.reshape %199 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %201 = "stablehlo.scatter"(%arg211, %183, %200) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %202 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %203 = "stablehlo.gather"(%201, %202) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %204 = stablehlo.transpose %203, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %205 = stablehlo.reshape %204 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %206 = stablehlo.dot_general %178, %205, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %207 = stablehlo.reshape %206 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %208 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %209 = stablehlo.divide %207, %208 : tensor<2x32x2048x2048xf32>
    %210 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %211 = stablehlo.broadcast_in_dim %210, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %212 = stablehlo.add %209, %211 : tensor<2x32x2048x2048xf32>
    %213 = stablehlo.reduce(%212 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %214 = stablehlo.broadcast_in_dim %213, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %215 = stablehlo.subtract %212, %214 : tensor<2x32x2048x2048xf32>
    %216 = stablehlo.exponential %215 : tensor<2x32x2048x2048xf32>
    %217 = stablehlo.reduce(%216 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %218 = stablehlo.broadcast_in_dim %217, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %219 = stablehlo.divide %216, %218 : tensor<2x32x2048x2048xf32>
    %220 = stablehlo.reshape %219 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %221 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %222 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %223 = stablehlo.add %arg199, %222 : tensor<2048xi64>
    %224 = stablehlo.select %221, %223, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %225 = stablehlo.reshape %224 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %226 = stablehlo.reshape %159 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %227 = stablehlo.transpose %arg188, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %228 = stablehlo.dot %226, %227, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %229 = stablehlo.reshape %228 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %230 = "stablehlo.scatter"(%arg209, %225, %229) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %231 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %232 = "stablehlo.gather"(%230, %231) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %233 = stablehlo.transpose %232, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %234 = stablehlo.reshape %233 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %235 = stablehlo.dot_general %220, %234, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %236 = stablehlo.reshape %235 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %237 = stablehlo.transpose %236, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %238 = stablehlo.reshape %237 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %239 = stablehlo.transpose %arg187, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %240 = stablehlo.dot %238, %239, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %241 = stablehlo.reshape %240 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %242 = stablehlo.add %147, %241 : tensor<2x2048x4096xf32>
    %243 = stablehlo.power %242, %1 : tensor<2x2048x4096xf32>
    %244 = stablehlo.reduce(%243 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %245 = stablehlo.multiply %244, %0 : tensor<2x2048xf32>
    %246 = stablehlo.reshape %245 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %247 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %248 = stablehlo.add %246, %247 : tensor<2x2048x1xf32>
    %249 = stablehlo.rsqrt %248 : tensor<2x2048x1xf32>
    %250 = stablehlo.reshape %249 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %251 = stablehlo.broadcast_in_dim %250, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %252 = stablehlo.multiply %242, %251 : tensor<2x2048x4096xf32>
    %253 = stablehlo.broadcast_in_dim %arg186, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %254 = stablehlo.multiply %252, %253 : tensor<2x2048x4096xf32>
    %255 = stablehlo.reshape %254 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %256 = stablehlo.transpose %arg213, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %257 = stablehlo.dot %255, %256, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %258 = stablehlo.reshape %257 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %259 = stablehlo.logistic %258 : tensor<2x2048x11008xf32>
    %260 = stablehlo.multiply %258, %259 : tensor<2x2048x11008xf32>
    %261 = stablehlo.reshape %254 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %262 = stablehlo.transpose %arg185, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %263 = stablehlo.dot %261, %262, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %264 = stablehlo.reshape %263 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %265 = stablehlo.multiply %260, %264 : tensor<2x2048x11008xf32>
    %266 = stablehlo.reshape %265 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %267 = stablehlo.transpose %arg184, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %268 = stablehlo.dot %266, %267, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %269 = stablehlo.reshape %268 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %270 = stablehlo.add %242, %269 : tensor<2x2048x4096xf32>
    %271 = stablehlo.power %270, %1 : tensor<2x2048x4096xf32>
    %272 = stablehlo.reduce(%271 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %273 = stablehlo.multiply %272, %0 : tensor<2x2048xf32>
    %274 = stablehlo.reshape %273 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %275 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %276 = stablehlo.add %274, %275 : tensor<2x2048x1xf32>
    %277 = stablehlo.rsqrt %276 : tensor<2x2048x1xf32>
    %278 = stablehlo.reshape %277 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %279 = stablehlo.broadcast_in_dim %278, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %280 = stablehlo.multiply %270, %279 : tensor<2x2048x4096xf32>
    %281 = stablehlo.broadcast_in_dim %arg183, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %282 = stablehlo.multiply %280, %281 : tensor<2x2048x4096xf32>
    %283 = stablehlo.reshape %282 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %284 = stablehlo.transpose %arg217, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %285 = stablehlo.dot %283, %284, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %286 = stablehlo.reshape %285 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %287 = stablehlo.slice %286 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %288 = stablehlo.reshape %287 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %289 = stablehlo.slice %286 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %290 = stablehlo.reshape %289 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %291 = stablehlo.complex %288, %290 : tensor<2x2048x32x64xcomplex<f32>>
    %292 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %293 = stablehlo.multiply %291, %292 : tensor<2x2048x32x64xcomplex<f32>>
    %294 = stablehlo.real %293 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %295 = stablehlo.reshape %294 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %296 = stablehlo.imag %293 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %297 = stablehlo.reshape %296 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %298 = stablehlo.concatenate %295, %297, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %299 = stablehlo.reshape %298 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %300 = stablehlo.transpose %299, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %301 = stablehlo.reshape %300 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %302 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %303 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %304 = stablehlo.add %arg199, %303 : tensor<2048xi64>
    %305 = stablehlo.select %302, %304, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %306 = stablehlo.reshape %305 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %307 = stablehlo.reshape %282 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %308 = stablehlo.transpose %arg215, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %309 = stablehlo.dot %307, %308, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %310 = stablehlo.reshape %309 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %311 = stablehlo.slice %310 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %312 = stablehlo.reshape %311 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %313 = stablehlo.slice %310 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %314 = stablehlo.reshape %313 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %315 = stablehlo.complex %312, %314 : tensor<2x2048x32x64xcomplex<f32>>
    %316 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %317 = stablehlo.multiply %315, %316 : tensor<2x2048x32x64xcomplex<f32>>
    %318 = stablehlo.real %317 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %319 = stablehlo.reshape %318 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %320 = stablehlo.imag %317 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %321 = stablehlo.reshape %320 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %322 = stablehlo.concatenate %319, %321, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %323 = stablehlo.reshape %322 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %324 = "stablehlo.scatter"(%arg216, %306, %323) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %325 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %326 = "stablehlo.gather"(%324, %325) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %327 = stablehlo.transpose %326, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %328 = stablehlo.reshape %327 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %329 = stablehlo.dot_general %301, %328, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %330 = stablehlo.reshape %329 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %331 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %332 = stablehlo.divide %330, %331 : tensor<2x32x2048x2048xf32>
    %333 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %334 = stablehlo.broadcast_in_dim %333, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %335 = stablehlo.add %332, %334 : tensor<2x32x2048x2048xf32>
    %336 = stablehlo.reduce(%335 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %337 = stablehlo.broadcast_in_dim %336, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %338 = stablehlo.subtract %335, %337 : tensor<2x32x2048x2048xf32>
    %339 = stablehlo.exponential %338 : tensor<2x32x2048x2048xf32>
    %340 = stablehlo.reduce(%339 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %341 = stablehlo.broadcast_in_dim %340, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %342 = stablehlo.divide %339, %341 : tensor<2x32x2048x2048xf32>
    %343 = stablehlo.reshape %342 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %344 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %345 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %346 = stablehlo.add %arg199, %345 : tensor<2048xi64>
    %347 = stablehlo.select %344, %346, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %348 = stablehlo.reshape %347 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %349 = stablehlo.reshape %282 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %350 = stablehlo.transpose %arg182, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %351 = stablehlo.dot %349, %350, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %352 = stablehlo.reshape %351 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %353 = "stablehlo.scatter"(%arg214, %348, %352) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %354 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %355 = "stablehlo.gather"(%353, %354) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %356 = stablehlo.transpose %355, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %357 = stablehlo.reshape %356 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %358 = stablehlo.dot_general %343, %357, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %359 = stablehlo.reshape %358 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %360 = stablehlo.transpose %359, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %361 = stablehlo.reshape %360 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %362 = stablehlo.transpose %arg181, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %363 = stablehlo.dot %361, %362, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %364 = stablehlo.reshape %363 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %365 = stablehlo.add %270, %364 : tensor<2x2048x4096xf32>
    %366 = stablehlo.power %365, %1 : tensor<2x2048x4096xf32>
    %367 = stablehlo.reduce(%366 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %368 = stablehlo.multiply %367, %0 : tensor<2x2048xf32>
    %369 = stablehlo.reshape %368 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %370 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %371 = stablehlo.add %369, %370 : tensor<2x2048x1xf32>
    %372 = stablehlo.rsqrt %371 : tensor<2x2048x1xf32>
    %373 = stablehlo.reshape %372 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %374 = stablehlo.broadcast_in_dim %373, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %375 = stablehlo.multiply %365, %374 : tensor<2x2048x4096xf32>
    %376 = stablehlo.broadcast_in_dim %arg180, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %377 = stablehlo.multiply %375, %376 : tensor<2x2048x4096xf32>
    %378 = stablehlo.reshape %377 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %379 = stablehlo.transpose %arg218, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %380 = stablehlo.dot %378, %379, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %381 = stablehlo.reshape %380 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %382 = stablehlo.logistic %381 : tensor<2x2048x11008xf32>
    %383 = stablehlo.multiply %381, %382 : tensor<2x2048x11008xf32>
    %384 = stablehlo.reshape %377 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %385 = stablehlo.transpose %arg179, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %386 = stablehlo.dot %384, %385, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %387 = stablehlo.reshape %386 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %388 = stablehlo.multiply %383, %387 : tensor<2x2048x11008xf32>
    %389 = stablehlo.reshape %388 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %390 = stablehlo.transpose %arg178, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %391 = stablehlo.dot %389, %390, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %392 = stablehlo.reshape %391 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %393 = stablehlo.add %365, %392 : tensor<2x2048x4096xf32>
    %394 = stablehlo.power %393, %1 : tensor<2x2048x4096xf32>
    %395 = stablehlo.reduce(%394 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %396 = stablehlo.multiply %395, %0 : tensor<2x2048xf32>
    %397 = stablehlo.reshape %396 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %398 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %399 = stablehlo.add %397, %398 : tensor<2x2048x1xf32>
    %400 = stablehlo.rsqrt %399 : tensor<2x2048x1xf32>
    %401 = stablehlo.reshape %400 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %402 = stablehlo.broadcast_in_dim %401, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %403 = stablehlo.multiply %393, %402 : tensor<2x2048x4096xf32>
    %404 = stablehlo.broadcast_in_dim %arg177, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %405 = stablehlo.multiply %403, %404 : tensor<2x2048x4096xf32>
    %406 = stablehlo.reshape %405 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %407 = stablehlo.transpose %arg222, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %408 = stablehlo.dot %406, %407, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %409 = stablehlo.reshape %408 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %410 = stablehlo.slice %409 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %411 = stablehlo.reshape %410 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %412 = stablehlo.slice %409 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %413 = stablehlo.reshape %412 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %414 = stablehlo.complex %411, %413 : tensor<2x2048x32x64xcomplex<f32>>
    %415 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %416 = stablehlo.multiply %414, %415 : tensor<2x2048x32x64xcomplex<f32>>
    %417 = stablehlo.real %416 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %418 = stablehlo.reshape %417 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %419 = stablehlo.imag %416 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %420 = stablehlo.reshape %419 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %421 = stablehlo.concatenate %418, %420, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %422 = stablehlo.reshape %421 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %423 = stablehlo.transpose %422, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %424 = stablehlo.reshape %423 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %425 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %426 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %427 = stablehlo.add %arg199, %426 : tensor<2048xi64>
    %428 = stablehlo.select %425, %427, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %429 = stablehlo.reshape %428 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %430 = stablehlo.reshape %405 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %431 = stablehlo.transpose %arg220, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %432 = stablehlo.dot %430, %431, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %433 = stablehlo.reshape %432 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %434 = stablehlo.slice %433 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %435 = stablehlo.reshape %434 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %436 = stablehlo.slice %433 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %437 = stablehlo.reshape %436 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %438 = stablehlo.complex %435, %437 : tensor<2x2048x32x64xcomplex<f32>>
    %439 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %440 = stablehlo.multiply %438, %439 : tensor<2x2048x32x64xcomplex<f32>>
    %441 = stablehlo.real %440 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %442 = stablehlo.reshape %441 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %443 = stablehlo.imag %440 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %444 = stablehlo.reshape %443 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %445 = stablehlo.concatenate %442, %444, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %446 = stablehlo.reshape %445 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %447 = "stablehlo.scatter"(%arg221, %429, %446) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %448 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %449 = "stablehlo.gather"(%447, %448) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %450 = stablehlo.transpose %449, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %451 = stablehlo.reshape %450 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %452 = stablehlo.dot_general %424, %451, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %453 = stablehlo.reshape %452 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %454 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %455 = stablehlo.divide %453, %454 : tensor<2x32x2048x2048xf32>
    %456 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %457 = stablehlo.broadcast_in_dim %456, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %458 = stablehlo.add %455, %457 : tensor<2x32x2048x2048xf32>
    %459 = stablehlo.reduce(%458 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %460 = stablehlo.broadcast_in_dim %459, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %461 = stablehlo.subtract %458, %460 : tensor<2x32x2048x2048xf32>
    %462 = stablehlo.exponential %461 : tensor<2x32x2048x2048xf32>
    %463 = stablehlo.reduce(%462 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %464 = stablehlo.broadcast_in_dim %463, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %465 = stablehlo.divide %462, %464 : tensor<2x32x2048x2048xf32>
    %466 = stablehlo.reshape %465 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %467 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %468 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %469 = stablehlo.add %arg199, %468 : tensor<2048xi64>
    %470 = stablehlo.select %467, %469, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %471 = stablehlo.reshape %470 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %472 = stablehlo.reshape %405 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %473 = stablehlo.transpose %arg176, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %474 = stablehlo.dot %472, %473, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %475 = stablehlo.reshape %474 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %476 = "stablehlo.scatter"(%arg219, %471, %475) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %477 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %478 = "stablehlo.gather"(%476, %477) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %479 = stablehlo.transpose %478, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %480 = stablehlo.reshape %479 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %481 = stablehlo.dot_general %466, %480, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %482 = stablehlo.reshape %481 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %483 = stablehlo.transpose %482, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %484 = stablehlo.reshape %483 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %485 = stablehlo.transpose %arg175, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %486 = stablehlo.dot %484, %485, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %487 = stablehlo.reshape %486 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %488 = stablehlo.add %393, %487 : tensor<2x2048x4096xf32>
    %489 = stablehlo.power %488, %1 : tensor<2x2048x4096xf32>
    %490 = stablehlo.reduce(%489 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %491 = stablehlo.multiply %490, %0 : tensor<2x2048xf32>
    %492 = stablehlo.reshape %491 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %493 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %494 = stablehlo.add %492, %493 : tensor<2x2048x1xf32>
    %495 = stablehlo.rsqrt %494 : tensor<2x2048x1xf32>
    %496 = stablehlo.reshape %495 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %497 = stablehlo.broadcast_in_dim %496, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %498 = stablehlo.multiply %488, %497 : tensor<2x2048x4096xf32>
    %499 = stablehlo.broadcast_in_dim %arg174, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %500 = stablehlo.multiply %498, %499 : tensor<2x2048x4096xf32>
    %501 = stablehlo.reshape %500 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %502 = stablehlo.transpose %arg223, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %503 = stablehlo.dot %501, %502, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %504 = stablehlo.reshape %503 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %505 = stablehlo.logistic %504 : tensor<2x2048x11008xf32>
    %506 = stablehlo.multiply %504, %505 : tensor<2x2048x11008xf32>
    %507 = stablehlo.reshape %500 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %508 = stablehlo.transpose %arg173, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %509 = stablehlo.dot %507, %508, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %510 = stablehlo.reshape %509 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %511 = stablehlo.multiply %506, %510 : tensor<2x2048x11008xf32>
    %512 = stablehlo.reshape %511 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %513 = stablehlo.transpose %arg172, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %514 = stablehlo.dot %512, %513, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %515 = stablehlo.reshape %514 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %516 = stablehlo.add %488, %515 : tensor<2x2048x4096xf32>
    %517 = stablehlo.power %516, %1 : tensor<2x2048x4096xf32>
    %518 = stablehlo.reduce(%517 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %519 = stablehlo.multiply %518, %0 : tensor<2x2048xf32>
    %520 = stablehlo.reshape %519 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %521 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %522 = stablehlo.add %520, %521 : tensor<2x2048x1xf32>
    %523 = stablehlo.rsqrt %522 : tensor<2x2048x1xf32>
    %524 = stablehlo.reshape %523 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %525 = stablehlo.broadcast_in_dim %524, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %526 = stablehlo.multiply %516, %525 : tensor<2x2048x4096xf32>
    %527 = stablehlo.broadcast_in_dim %arg171, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %528 = stablehlo.multiply %526, %527 : tensor<2x2048x4096xf32>
    %529 = stablehlo.reshape %528 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %530 = stablehlo.transpose %arg227, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %531 = stablehlo.dot %529, %530, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %532 = stablehlo.reshape %531 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %533 = stablehlo.slice %532 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %534 = stablehlo.reshape %533 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %535 = stablehlo.slice %532 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %536 = stablehlo.reshape %535 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %537 = stablehlo.complex %534, %536 : tensor<2x2048x32x64xcomplex<f32>>
    %538 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %539 = stablehlo.multiply %537, %538 : tensor<2x2048x32x64xcomplex<f32>>
    %540 = stablehlo.real %539 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %541 = stablehlo.reshape %540 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %542 = stablehlo.imag %539 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %543 = stablehlo.reshape %542 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %544 = stablehlo.concatenate %541, %543, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %545 = stablehlo.reshape %544 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %546 = stablehlo.transpose %545, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %547 = stablehlo.reshape %546 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %548 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %549 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %550 = stablehlo.add %arg199, %549 : tensor<2048xi64>
    %551 = stablehlo.select %548, %550, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %552 = stablehlo.reshape %551 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %553 = stablehlo.reshape %528 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %554 = stablehlo.transpose %arg225, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %555 = stablehlo.dot %553, %554, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %556 = stablehlo.reshape %555 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %557 = stablehlo.slice %556 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %558 = stablehlo.reshape %557 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %559 = stablehlo.slice %556 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %560 = stablehlo.reshape %559 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %561 = stablehlo.complex %558, %560 : tensor<2x2048x32x64xcomplex<f32>>
    %562 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %563 = stablehlo.multiply %561, %562 : tensor<2x2048x32x64xcomplex<f32>>
    %564 = stablehlo.real %563 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %565 = stablehlo.reshape %564 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %566 = stablehlo.imag %563 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %567 = stablehlo.reshape %566 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %568 = stablehlo.concatenate %565, %567, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %569 = stablehlo.reshape %568 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %570 = "stablehlo.scatter"(%arg226, %552, %569) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %571 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %572 = "stablehlo.gather"(%570, %571) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %573 = stablehlo.transpose %572, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %574 = stablehlo.reshape %573 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %575 = stablehlo.dot_general %547, %574, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %576 = stablehlo.reshape %575 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %577 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %578 = stablehlo.divide %576, %577 : tensor<2x32x2048x2048xf32>
    %579 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %580 = stablehlo.broadcast_in_dim %579, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %581 = stablehlo.add %578, %580 : tensor<2x32x2048x2048xf32>
    %582 = stablehlo.reduce(%581 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %583 = stablehlo.broadcast_in_dim %582, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %584 = stablehlo.subtract %581, %583 : tensor<2x32x2048x2048xf32>
    %585 = stablehlo.exponential %584 : tensor<2x32x2048x2048xf32>
    %586 = stablehlo.reduce(%585 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %587 = stablehlo.broadcast_in_dim %586, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %588 = stablehlo.divide %585, %587 : tensor<2x32x2048x2048xf32>
    %589 = stablehlo.reshape %588 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %590 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %591 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %592 = stablehlo.add %arg199, %591 : tensor<2048xi64>
    %593 = stablehlo.select %590, %592, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %594 = stablehlo.reshape %593 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %595 = stablehlo.reshape %528 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %596 = stablehlo.transpose %arg170, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %597 = stablehlo.dot %595, %596, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %598 = stablehlo.reshape %597 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %599 = "stablehlo.scatter"(%arg224, %594, %598) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %600 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %601 = "stablehlo.gather"(%599, %600) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %602 = stablehlo.transpose %601, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %603 = stablehlo.reshape %602 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %604 = stablehlo.dot_general %589, %603, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %605 = stablehlo.reshape %604 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %606 = stablehlo.transpose %605, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %607 = stablehlo.reshape %606 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %608 = stablehlo.transpose %arg169, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %609 = stablehlo.dot %607, %608, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %610 = stablehlo.reshape %609 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %611 = stablehlo.add %516, %610 : tensor<2x2048x4096xf32>
    %612 = stablehlo.power %611, %1 : tensor<2x2048x4096xf32>
    %613 = stablehlo.reduce(%612 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %614 = stablehlo.multiply %613, %0 : tensor<2x2048xf32>
    %615 = stablehlo.reshape %614 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %616 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %617 = stablehlo.add %615, %616 : tensor<2x2048x1xf32>
    %618 = stablehlo.rsqrt %617 : tensor<2x2048x1xf32>
    %619 = stablehlo.reshape %618 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %620 = stablehlo.broadcast_in_dim %619, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %621 = stablehlo.multiply %611, %620 : tensor<2x2048x4096xf32>
    %622 = stablehlo.broadcast_in_dim %arg168, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %623 = stablehlo.multiply %621, %622 : tensor<2x2048x4096xf32>
    %624 = stablehlo.reshape %623 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %625 = stablehlo.transpose %arg228, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %626 = stablehlo.dot %624, %625, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %627 = stablehlo.reshape %626 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %628 = stablehlo.logistic %627 : tensor<2x2048x11008xf32>
    %629 = stablehlo.multiply %627, %628 : tensor<2x2048x11008xf32>
    %630 = stablehlo.reshape %623 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %631 = stablehlo.transpose %arg167, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %632 = stablehlo.dot %630, %631, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %633 = stablehlo.reshape %632 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %634 = stablehlo.multiply %629, %633 : tensor<2x2048x11008xf32>
    %635 = stablehlo.reshape %634 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %636 = stablehlo.transpose %arg166, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %637 = stablehlo.dot %635, %636, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %638 = stablehlo.reshape %637 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %639 = stablehlo.add %611, %638 : tensor<2x2048x4096xf32>
    %640 = stablehlo.power %639, %1 : tensor<2x2048x4096xf32>
    %641 = stablehlo.reduce(%640 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %642 = stablehlo.multiply %641, %0 : tensor<2x2048xf32>
    %643 = stablehlo.reshape %642 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %644 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %645 = stablehlo.add %643, %644 : tensor<2x2048x1xf32>
    %646 = stablehlo.rsqrt %645 : tensor<2x2048x1xf32>
    %647 = stablehlo.reshape %646 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %648 = stablehlo.broadcast_in_dim %647, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %649 = stablehlo.multiply %639, %648 : tensor<2x2048x4096xf32>
    %650 = stablehlo.broadcast_in_dim %arg165, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %651 = stablehlo.multiply %649, %650 : tensor<2x2048x4096xf32>
    %652 = stablehlo.reshape %651 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %653 = stablehlo.transpose %arg232, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %654 = stablehlo.dot %652, %653, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %655 = stablehlo.reshape %654 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %656 = stablehlo.slice %655 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %657 = stablehlo.reshape %656 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %658 = stablehlo.slice %655 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %659 = stablehlo.reshape %658 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %660 = stablehlo.complex %657, %659 : tensor<2x2048x32x64xcomplex<f32>>
    %661 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %662 = stablehlo.multiply %660, %661 : tensor<2x2048x32x64xcomplex<f32>>
    %663 = stablehlo.real %662 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %664 = stablehlo.reshape %663 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %665 = stablehlo.imag %662 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %666 = stablehlo.reshape %665 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %667 = stablehlo.concatenate %664, %666, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %668 = stablehlo.reshape %667 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %669 = stablehlo.transpose %668, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %670 = stablehlo.reshape %669 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %671 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %672 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %673 = stablehlo.add %arg199, %672 : tensor<2048xi64>
    %674 = stablehlo.select %671, %673, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %675 = stablehlo.reshape %674 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %676 = stablehlo.reshape %651 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %677 = stablehlo.transpose %arg230, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %678 = stablehlo.dot %676, %677, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %679 = stablehlo.reshape %678 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %680 = stablehlo.slice %679 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %681 = stablehlo.reshape %680 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %682 = stablehlo.slice %679 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %683 = stablehlo.reshape %682 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %684 = stablehlo.complex %681, %683 : tensor<2x2048x32x64xcomplex<f32>>
    %685 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %686 = stablehlo.multiply %684, %685 : tensor<2x2048x32x64xcomplex<f32>>
    %687 = stablehlo.real %686 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %688 = stablehlo.reshape %687 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %689 = stablehlo.imag %686 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %690 = stablehlo.reshape %689 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %691 = stablehlo.concatenate %688, %690, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %692 = stablehlo.reshape %691 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %693 = "stablehlo.scatter"(%arg231, %675, %692) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %694 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %695 = "stablehlo.gather"(%693, %694) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %696 = stablehlo.transpose %695, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %697 = stablehlo.reshape %696 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %698 = stablehlo.dot_general %670, %697, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %699 = stablehlo.reshape %698 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %700 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %701 = stablehlo.divide %699, %700 : tensor<2x32x2048x2048xf32>
    %702 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %703 = stablehlo.broadcast_in_dim %702, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %704 = stablehlo.add %701, %703 : tensor<2x32x2048x2048xf32>
    %705 = stablehlo.reduce(%704 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %706 = stablehlo.broadcast_in_dim %705, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %707 = stablehlo.subtract %704, %706 : tensor<2x32x2048x2048xf32>
    %708 = stablehlo.exponential %707 : tensor<2x32x2048x2048xf32>
    %709 = stablehlo.reduce(%708 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %710 = stablehlo.broadcast_in_dim %709, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %711 = stablehlo.divide %708, %710 : tensor<2x32x2048x2048xf32>
    %712 = stablehlo.reshape %711 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %713 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %714 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %715 = stablehlo.add %arg199, %714 : tensor<2048xi64>
    %716 = stablehlo.select %713, %715, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %717 = stablehlo.reshape %716 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %718 = stablehlo.reshape %651 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %719 = stablehlo.transpose %arg164, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %720 = stablehlo.dot %718, %719, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %721 = stablehlo.reshape %720 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %722 = "stablehlo.scatter"(%arg229, %717, %721) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %723 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %724 = "stablehlo.gather"(%722, %723) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %725 = stablehlo.transpose %724, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %726 = stablehlo.reshape %725 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %727 = stablehlo.dot_general %712, %726, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %728 = stablehlo.reshape %727 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %729 = stablehlo.transpose %728, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %730 = stablehlo.reshape %729 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %731 = stablehlo.transpose %arg163, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %732 = stablehlo.dot %730, %731, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %733 = stablehlo.reshape %732 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %734 = stablehlo.add %639, %733 : tensor<2x2048x4096xf32>
    %735 = stablehlo.power %734, %1 : tensor<2x2048x4096xf32>
    %736 = stablehlo.reduce(%735 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %737 = stablehlo.multiply %736, %0 : tensor<2x2048xf32>
    %738 = stablehlo.reshape %737 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %739 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %740 = stablehlo.add %738, %739 : tensor<2x2048x1xf32>
    %741 = stablehlo.rsqrt %740 : tensor<2x2048x1xf32>
    %742 = stablehlo.reshape %741 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %743 = stablehlo.broadcast_in_dim %742, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %744 = stablehlo.multiply %734, %743 : tensor<2x2048x4096xf32>
    %745 = stablehlo.broadcast_in_dim %arg162, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %746 = stablehlo.multiply %744, %745 : tensor<2x2048x4096xf32>
    %747 = stablehlo.reshape %746 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %748 = stablehlo.transpose %arg233, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %749 = stablehlo.dot %747, %748, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %750 = stablehlo.reshape %749 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %751 = stablehlo.logistic %750 : tensor<2x2048x11008xf32>
    %752 = stablehlo.multiply %750, %751 : tensor<2x2048x11008xf32>
    %753 = stablehlo.reshape %746 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %754 = stablehlo.transpose %arg161, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %755 = stablehlo.dot %753, %754, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %756 = stablehlo.reshape %755 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %757 = stablehlo.multiply %752, %756 : tensor<2x2048x11008xf32>
    %758 = stablehlo.reshape %757 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %759 = stablehlo.transpose %arg160, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %760 = stablehlo.dot %758, %759, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %761 = stablehlo.reshape %760 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %762 = stablehlo.add %734, %761 : tensor<2x2048x4096xf32>
    %763 = stablehlo.power %762, %1 : tensor<2x2048x4096xf32>
    %764 = stablehlo.reduce(%763 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %765 = stablehlo.multiply %764, %0 : tensor<2x2048xf32>
    %766 = stablehlo.reshape %765 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %767 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %768 = stablehlo.add %766, %767 : tensor<2x2048x1xf32>
    %769 = stablehlo.rsqrt %768 : tensor<2x2048x1xf32>
    %770 = stablehlo.reshape %769 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %771 = stablehlo.broadcast_in_dim %770, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %772 = stablehlo.multiply %762, %771 : tensor<2x2048x4096xf32>
    %773 = stablehlo.broadcast_in_dim %arg159, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %774 = stablehlo.multiply %772, %773 : tensor<2x2048x4096xf32>
    %775 = stablehlo.reshape %774 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %776 = stablehlo.transpose %arg237, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %777 = stablehlo.dot %775, %776, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %778 = stablehlo.reshape %777 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %779 = stablehlo.slice %778 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %780 = stablehlo.reshape %779 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %781 = stablehlo.slice %778 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %782 = stablehlo.reshape %781 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %783 = stablehlo.complex %780, %782 : tensor<2x2048x32x64xcomplex<f32>>
    %784 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %785 = stablehlo.multiply %783, %784 : tensor<2x2048x32x64xcomplex<f32>>
    %786 = stablehlo.real %785 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %787 = stablehlo.reshape %786 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %788 = stablehlo.imag %785 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %789 = stablehlo.reshape %788 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %790 = stablehlo.concatenate %787, %789, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %791 = stablehlo.reshape %790 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %792 = stablehlo.transpose %791, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %793 = stablehlo.reshape %792 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %794 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %795 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %796 = stablehlo.add %arg199, %795 : tensor<2048xi64>
    %797 = stablehlo.select %794, %796, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %798 = stablehlo.reshape %797 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %799 = stablehlo.reshape %774 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %800 = stablehlo.transpose %arg235, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %801 = stablehlo.dot %799, %800, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %802 = stablehlo.reshape %801 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %803 = stablehlo.slice %802 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %804 = stablehlo.reshape %803 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %805 = stablehlo.slice %802 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %806 = stablehlo.reshape %805 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %807 = stablehlo.complex %804, %806 : tensor<2x2048x32x64xcomplex<f32>>
    %808 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %809 = stablehlo.multiply %807, %808 : tensor<2x2048x32x64xcomplex<f32>>
    %810 = stablehlo.real %809 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %811 = stablehlo.reshape %810 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %812 = stablehlo.imag %809 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %813 = stablehlo.reshape %812 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %814 = stablehlo.concatenate %811, %813, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %815 = stablehlo.reshape %814 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %816 = "stablehlo.scatter"(%arg236, %798, %815) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %817 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %818 = "stablehlo.gather"(%816, %817) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %819 = stablehlo.transpose %818, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %820 = stablehlo.reshape %819 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %821 = stablehlo.dot_general %793, %820, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %822 = stablehlo.reshape %821 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %823 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %824 = stablehlo.divide %822, %823 : tensor<2x32x2048x2048xf32>
    %825 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %826 = stablehlo.broadcast_in_dim %825, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %827 = stablehlo.add %824, %826 : tensor<2x32x2048x2048xf32>
    %828 = stablehlo.reduce(%827 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %829 = stablehlo.broadcast_in_dim %828, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %830 = stablehlo.subtract %827, %829 : tensor<2x32x2048x2048xf32>
    %831 = stablehlo.exponential %830 : tensor<2x32x2048x2048xf32>
    %832 = stablehlo.reduce(%831 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %833 = stablehlo.broadcast_in_dim %832, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %834 = stablehlo.divide %831, %833 : tensor<2x32x2048x2048xf32>
    %835 = stablehlo.reshape %834 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %836 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %837 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %838 = stablehlo.add %arg199, %837 : tensor<2048xi64>
    %839 = stablehlo.select %836, %838, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %840 = stablehlo.reshape %839 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %841 = stablehlo.reshape %774 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %842 = stablehlo.transpose %arg158, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %843 = stablehlo.dot %841, %842, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %844 = stablehlo.reshape %843 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %845 = "stablehlo.scatter"(%arg234, %840, %844) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %846 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %847 = "stablehlo.gather"(%845, %846) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %848 = stablehlo.transpose %847, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %849 = stablehlo.reshape %848 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %850 = stablehlo.dot_general %835, %849, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %851 = stablehlo.reshape %850 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %852 = stablehlo.transpose %851, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %853 = stablehlo.reshape %852 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %854 = stablehlo.transpose %arg157, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %855 = stablehlo.dot %853, %854, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %856 = stablehlo.reshape %855 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %857 = stablehlo.add %762, %856 : tensor<2x2048x4096xf32>
    %858 = stablehlo.power %857, %1 : tensor<2x2048x4096xf32>
    %859 = stablehlo.reduce(%858 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %860 = stablehlo.multiply %859, %0 : tensor<2x2048xf32>
    %861 = stablehlo.reshape %860 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %862 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %863 = stablehlo.add %861, %862 : tensor<2x2048x1xf32>
    %864 = stablehlo.rsqrt %863 : tensor<2x2048x1xf32>
    %865 = stablehlo.reshape %864 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %866 = stablehlo.broadcast_in_dim %865, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %867 = stablehlo.multiply %857, %866 : tensor<2x2048x4096xf32>
    %868 = stablehlo.broadcast_in_dim %arg156, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %869 = stablehlo.multiply %867, %868 : tensor<2x2048x4096xf32>
    %870 = stablehlo.reshape %869 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %871 = stablehlo.transpose %arg238, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %872 = stablehlo.dot %870, %871, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %873 = stablehlo.reshape %872 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %874 = stablehlo.logistic %873 : tensor<2x2048x11008xf32>
    %875 = stablehlo.multiply %873, %874 : tensor<2x2048x11008xf32>
    %876 = stablehlo.reshape %869 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %877 = stablehlo.transpose %arg155, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %878 = stablehlo.dot %876, %877, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %879 = stablehlo.reshape %878 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %880 = stablehlo.multiply %875, %879 : tensor<2x2048x11008xf32>
    %881 = stablehlo.reshape %880 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %882 = stablehlo.transpose %arg154, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %883 = stablehlo.dot %881, %882, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %884 = stablehlo.reshape %883 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %885 = stablehlo.add %857, %884 : tensor<2x2048x4096xf32>
    %886 = stablehlo.power %885, %1 : tensor<2x2048x4096xf32>
    %887 = stablehlo.reduce(%886 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %888 = stablehlo.multiply %887, %0 : tensor<2x2048xf32>
    %889 = stablehlo.reshape %888 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %890 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %891 = stablehlo.add %889, %890 : tensor<2x2048x1xf32>
    %892 = stablehlo.rsqrt %891 : tensor<2x2048x1xf32>
    %893 = stablehlo.reshape %892 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %894 = stablehlo.broadcast_in_dim %893, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %895 = stablehlo.multiply %885, %894 : tensor<2x2048x4096xf32>
    %896 = stablehlo.broadcast_in_dim %arg153, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %897 = stablehlo.multiply %895, %896 : tensor<2x2048x4096xf32>
    %898 = stablehlo.reshape %897 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %899 = stablehlo.transpose %arg242, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %900 = stablehlo.dot %898, %899, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %901 = stablehlo.reshape %900 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %902 = stablehlo.slice %901 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %903 = stablehlo.reshape %902 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %904 = stablehlo.slice %901 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %905 = stablehlo.reshape %904 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %906 = stablehlo.complex %903, %905 : tensor<2x2048x32x64xcomplex<f32>>
    %907 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %908 = stablehlo.multiply %906, %907 : tensor<2x2048x32x64xcomplex<f32>>
    %909 = stablehlo.real %908 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %910 = stablehlo.reshape %909 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %911 = stablehlo.imag %908 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %912 = stablehlo.reshape %911 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %913 = stablehlo.concatenate %910, %912, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %914 = stablehlo.reshape %913 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %915 = stablehlo.transpose %914, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %916 = stablehlo.reshape %915 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %917 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %918 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %919 = stablehlo.add %arg199, %918 : tensor<2048xi64>
    %920 = stablehlo.select %917, %919, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %921 = stablehlo.reshape %920 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %922 = stablehlo.reshape %897 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %923 = stablehlo.transpose %arg240, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %924 = stablehlo.dot %922, %923, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %925 = stablehlo.reshape %924 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %926 = stablehlo.slice %925 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %927 = stablehlo.reshape %926 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %928 = stablehlo.slice %925 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %929 = stablehlo.reshape %928 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %930 = stablehlo.complex %927, %929 : tensor<2x2048x32x64xcomplex<f32>>
    %931 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %932 = stablehlo.multiply %930, %931 : tensor<2x2048x32x64xcomplex<f32>>
    %933 = stablehlo.real %932 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %934 = stablehlo.reshape %933 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %935 = stablehlo.imag %932 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %936 = stablehlo.reshape %935 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %937 = stablehlo.concatenate %934, %936, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %938 = stablehlo.reshape %937 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %939 = "stablehlo.scatter"(%arg241, %921, %938) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %940 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %941 = "stablehlo.gather"(%939, %940) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %942 = stablehlo.transpose %941, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %943 = stablehlo.reshape %942 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %944 = stablehlo.dot_general %916, %943, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %945 = stablehlo.reshape %944 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %946 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %947 = stablehlo.divide %945, %946 : tensor<2x32x2048x2048xf32>
    %948 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %949 = stablehlo.broadcast_in_dim %948, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %950 = stablehlo.add %947, %949 : tensor<2x32x2048x2048xf32>
    %951 = stablehlo.reduce(%950 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %952 = stablehlo.broadcast_in_dim %951, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %953 = stablehlo.subtract %950, %952 : tensor<2x32x2048x2048xf32>
    %954 = stablehlo.exponential %953 : tensor<2x32x2048x2048xf32>
    %955 = stablehlo.reduce(%954 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %956 = stablehlo.broadcast_in_dim %955, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %957 = stablehlo.divide %954, %956 : tensor<2x32x2048x2048xf32>
    %958 = stablehlo.reshape %957 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %959 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %960 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %961 = stablehlo.add %arg199, %960 : tensor<2048xi64>
    %962 = stablehlo.select %959, %961, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %963 = stablehlo.reshape %962 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %964 = stablehlo.reshape %897 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %965 = stablehlo.transpose %arg152, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %966 = stablehlo.dot %964, %965, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %967 = stablehlo.reshape %966 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %968 = "stablehlo.scatter"(%arg239, %963, %967) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %969 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %970 = "stablehlo.gather"(%968, %969) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %971 = stablehlo.transpose %970, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %972 = stablehlo.reshape %971 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %973 = stablehlo.dot_general %958, %972, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %974 = stablehlo.reshape %973 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %975 = stablehlo.transpose %974, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %976 = stablehlo.reshape %975 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %977 = stablehlo.transpose %arg151, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %978 = stablehlo.dot %976, %977, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %979 = stablehlo.reshape %978 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %980 = stablehlo.add %885, %979 : tensor<2x2048x4096xf32>
    %981 = stablehlo.power %980, %1 : tensor<2x2048x4096xf32>
    %982 = stablehlo.reduce(%981 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %983 = stablehlo.multiply %982, %0 : tensor<2x2048xf32>
    %984 = stablehlo.reshape %983 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %985 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %986 = stablehlo.add %984, %985 : tensor<2x2048x1xf32>
    %987 = stablehlo.rsqrt %986 : tensor<2x2048x1xf32>
    %988 = stablehlo.reshape %987 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %989 = stablehlo.broadcast_in_dim %988, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %990 = stablehlo.multiply %980, %989 : tensor<2x2048x4096xf32>
    %991 = stablehlo.broadcast_in_dim %arg150, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %992 = stablehlo.multiply %990, %991 : tensor<2x2048x4096xf32>
    %993 = stablehlo.reshape %992 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %994 = stablehlo.transpose %arg243, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %995 = stablehlo.dot %993, %994, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %996 = stablehlo.reshape %995 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %997 = stablehlo.logistic %996 : tensor<2x2048x11008xf32>
    %998 = stablehlo.multiply %996, %997 : tensor<2x2048x11008xf32>
    %999 = stablehlo.reshape %992 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1000 = stablehlo.transpose %arg149, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1001 = stablehlo.dot %999, %1000, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1002 = stablehlo.reshape %1001 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1003 = stablehlo.multiply %998, %1002 : tensor<2x2048x11008xf32>
    %1004 = stablehlo.reshape %1003 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1005 = stablehlo.transpose %arg148, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1006 = stablehlo.dot %1004, %1005, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1007 = stablehlo.reshape %1006 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1008 = stablehlo.add %980, %1007 : tensor<2x2048x4096xf32>
    %1009 = stablehlo.power %1008, %1 : tensor<2x2048x4096xf32>
    %1010 = stablehlo.reduce(%1009 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1011 = stablehlo.multiply %1010, %0 : tensor<2x2048xf32>
    %1012 = stablehlo.reshape %1011 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1013 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1014 = stablehlo.add %1012, %1013 : tensor<2x2048x1xf32>
    %1015 = stablehlo.rsqrt %1014 : tensor<2x2048x1xf32>
    %1016 = stablehlo.reshape %1015 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1017 = stablehlo.broadcast_in_dim %1016, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1018 = stablehlo.multiply %1008, %1017 : tensor<2x2048x4096xf32>
    %1019 = stablehlo.broadcast_in_dim %arg147, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1020 = stablehlo.multiply %1018, %1019 : tensor<2x2048x4096xf32>
    %1021 = stablehlo.reshape %1020 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1022 = stablehlo.transpose %arg247, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1023 = stablehlo.dot %1021, %1022, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1024 = stablehlo.reshape %1023 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1025 = stablehlo.slice %1024 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1026 = stablehlo.reshape %1025 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1027 = stablehlo.slice %1024 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1028 = stablehlo.reshape %1027 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1029 = stablehlo.complex %1026, %1028 : tensor<2x2048x32x64xcomplex<f32>>
    %1030 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1031 = stablehlo.multiply %1029, %1030 : tensor<2x2048x32x64xcomplex<f32>>
    %1032 = stablehlo.real %1031 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1033 = stablehlo.reshape %1032 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1034 = stablehlo.imag %1031 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1035 = stablehlo.reshape %1034 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1036 = stablehlo.concatenate %1033, %1035, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1037 = stablehlo.reshape %1036 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1038 = stablehlo.transpose %1037, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1039 = stablehlo.reshape %1038 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1040 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1041 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1042 = stablehlo.add %arg199, %1041 : tensor<2048xi64>
    %1043 = stablehlo.select %1040, %1042, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1044 = stablehlo.reshape %1043 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1045 = stablehlo.reshape %1020 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1046 = stablehlo.transpose %arg245, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1047 = stablehlo.dot %1045, %1046, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1048 = stablehlo.reshape %1047 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1049 = stablehlo.slice %1048 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1050 = stablehlo.reshape %1049 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1051 = stablehlo.slice %1048 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1052 = stablehlo.reshape %1051 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1053 = stablehlo.complex %1050, %1052 : tensor<2x2048x32x64xcomplex<f32>>
    %1054 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1055 = stablehlo.multiply %1053, %1054 : tensor<2x2048x32x64xcomplex<f32>>
    %1056 = stablehlo.real %1055 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1057 = stablehlo.reshape %1056 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1058 = stablehlo.imag %1055 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1059 = stablehlo.reshape %1058 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1060 = stablehlo.concatenate %1057, %1059, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1061 = stablehlo.reshape %1060 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1062 = "stablehlo.scatter"(%arg246, %1044, %1061) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1063 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1064 = "stablehlo.gather"(%1062, %1063) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1065 = stablehlo.transpose %1064, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1066 = stablehlo.reshape %1065 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1067 = stablehlo.dot_general %1039, %1066, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1068 = stablehlo.reshape %1067 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1069 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1070 = stablehlo.divide %1068, %1069 : tensor<2x32x2048x2048xf32>
    %1071 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1072 = stablehlo.broadcast_in_dim %1071, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1073 = stablehlo.add %1070, %1072 : tensor<2x32x2048x2048xf32>
    %1074 = stablehlo.reduce(%1073 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1075 = stablehlo.broadcast_in_dim %1074, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1076 = stablehlo.subtract %1073, %1075 : tensor<2x32x2048x2048xf32>
    %1077 = stablehlo.exponential %1076 : tensor<2x32x2048x2048xf32>
    %1078 = stablehlo.reduce(%1077 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1079 = stablehlo.broadcast_in_dim %1078, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1080 = stablehlo.divide %1077, %1079 : tensor<2x32x2048x2048xf32>
    %1081 = stablehlo.reshape %1080 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1082 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1083 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1084 = stablehlo.add %arg199, %1083 : tensor<2048xi64>
    %1085 = stablehlo.select %1082, %1084, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1086 = stablehlo.reshape %1085 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1087 = stablehlo.reshape %1020 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1088 = stablehlo.transpose %arg146, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1089 = stablehlo.dot %1087, %1088, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1090 = stablehlo.reshape %1089 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1091 = "stablehlo.scatter"(%arg244, %1086, %1090) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1092 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1093 = "stablehlo.gather"(%1091, %1092) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1094 = stablehlo.transpose %1093, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1095 = stablehlo.reshape %1094 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1096 = stablehlo.dot_general %1081, %1095, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1097 = stablehlo.reshape %1096 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1098 = stablehlo.transpose %1097, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1099 = stablehlo.reshape %1098 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1100 = stablehlo.transpose %arg145, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1101 = stablehlo.dot %1099, %1100, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1102 = stablehlo.reshape %1101 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1103 = stablehlo.add %1008, %1102 : tensor<2x2048x4096xf32>
    %1104 = stablehlo.power %1103, %1 : tensor<2x2048x4096xf32>
    %1105 = stablehlo.reduce(%1104 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1106 = stablehlo.multiply %1105, %0 : tensor<2x2048xf32>
    %1107 = stablehlo.reshape %1106 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1108 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1109 = stablehlo.add %1107, %1108 : tensor<2x2048x1xf32>
    %1110 = stablehlo.rsqrt %1109 : tensor<2x2048x1xf32>
    %1111 = stablehlo.reshape %1110 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1112 = stablehlo.broadcast_in_dim %1111, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1113 = stablehlo.multiply %1103, %1112 : tensor<2x2048x4096xf32>
    %1114 = stablehlo.broadcast_in_dim %arg144, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1115 = stablehlo.multiply %1113, %1114 : tensor<2x2048x4096xf32>
    %1116 = stablehlo.reshape %1115 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1117 = stablehlo.transpose %arg248, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1118 = stablehlo.dot %1116, %1117, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1119 = stablehlo.reshape %1118 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1120 = stablehlo.logistic %1119 : tensor<2x2048x11008xf32>
    %1121 = stablehlo.multiply %1119, %1120 : tensor<2x2048x11008xf32>
    %1122 = stablehlo.reshape %1115 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1123 = stablehlo.transpose %arg143, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1124 = stablehlo.dot %1122, %1123, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1125 = stablehlo.reshape %1124 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1126 = stablehlo.multiply %1121, %1125 : tensor<2x2048x11008xf32>
    %1127 = stablehlo.reshape %1126 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1128 = stablehlo.transpose %arg142, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1129 = stablehlo.dot %1127, %1128, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1130 = stablehlo.reshape %1129 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1131 = stablehlo.add %1103, %1130 : tensor<2x2048x4096xf32>
    %1132 = stablehlo.power %1131, %1 : tensor<2x2048x4096xf32>
    %1133 = stablehlo.reduce(%1132 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1134 = stablehlo.multiply %1133, %0 : tensor<2x2048xf32>
    %1135 = stablehlo.reshape %1134 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1136 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1137 = stablehlo.add %1135, %1136 : tensor<2x2048x1xf32>
    %1138 = stablehlo.rsqrt %1137 : tensor<2x2048x1xf32>
    %1139 = stablehlo.reshape %1138 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1140 = stablehlo.broadcast_in_dim %1139, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1141 = stablehlo.multiply %1131, %1140 : tensor<2x2048x4096xf32>
    %1142 = stablehlo.broadcast_in_dim %arg141, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1143 = stablehlo.multiply %1141, %1142 : tensor<2x2048x4096xf32>
    %1144 = stablehlo.reshape %1143 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1145 = stablehlo.transpose %arg252, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1146 = stablehlo.dot %1144, %1145, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1147 = stablehlo.reshape %1146 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1148 = stablehlo.slice %1147 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1149 = stablehlo.reshape %1148 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1150 = stablehlo.slice %1147 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1151 = stablehlo.reshape %1150 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1152 = stablehlo.complex %1149, %1151 : tensor<2x2048x32x64xcomplex<f32>>
    %1153 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1154 = stablehlo.multiply %1152, %1153 : tensor<2x2048x32x64xcomplex<f32>>
    %1155 = stablehlo.real %1154 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1156 = stablehlo.reshape %1155 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1157 = stablehlo.imag %1154 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1158 = stablehlo.reshape %1157 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1159 = stablehlo.concatenate %1156, %1158, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1160 = stablehlo.reshape %1159 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1161 = stablehlo.transpose %1160, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1162 = stablehlo.reshape %1161 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1163 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1164 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1165 = stablehlo.add %arg199, %1164 : tensor<2048xi64>
    %1166 = stablehlo.select %1163, %1165, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1167 = stablehlo.reshape %1166 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1168 = stablehlo.reshape %1143 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1169 = stablehlo.transpose %arg250, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1170 = stablehlo.dot %1168, %1169, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1171 = stablehlo.reshape %1170 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1172 = stablehlo.slice %1171 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1173 = stablehlo.reshape %1172 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1174 = stablehlo.slice %1171 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1175 = stablehlo.reshape %1174 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1176 = stablehlo.complex %1173, %1175 : tensor<2x2048x32x64xcomplex<f32>>
    %1177 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1178 = stablehlo.multiply %1176, %1177 : tensor<2x2048x32x64xcomplex<f32>>
    %1179 = stablehlo.real %1178 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1180 = stablehlo.reshape %1179 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1181 = stablehlo.imag %1178 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1182 = stablehlo.reshape %1181 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1183 = stablehlo.concatenate %1180, %1182, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1184 = stablehlo.reshape %1183 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1185 = "stablehlo.scatter"(%arg251, %1167, %1184) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1186 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1187 = "stablehlo.gather"(%1185, %1186) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1188 = stablehlo.transpose %1187, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1189 = stablehlo.reshape %1188 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1190 = stablehlo.dot_general %1162, %1189, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1191 = stablehlo.reshape %1190 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1192 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1193 = stablehlo.divide %1191, %1192 : tensor<2x32x2048x2048xf32>
    %1194 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1195 = stablehlo.broadcast_in_dim %1194, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1196 = stablehlo.add %1193, %1195 : tensor<2x32x2048x2048xf32>
    %1197 = stablehlo.reduce(%1196 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1198 = stablehlo.broadcast_in_dim %1197, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1199 = stablehlo.subtract %1196, %1198 : tensor<2x32x2048x2048xf32>
    %1200 = stablehlo.exponential %1199 : tensor<2x32x2048x2048xf32>
    %1201 = stablehlo.reduce(%1200 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1202 = stablehlo.broadcast_in_dim %1201, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1203 = stablehlo.divide %1200, %1202 : tensor<2x32x2048x2048xf32>
    %1204 = stablehlo.reshape %1203 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1205 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1206 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1207 = stablehlo.add %arg199, %1206 : tensor<2048xi64>
    %1208 = stablehlo.select %1205, %1207, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1209 = stablehlo.reshape %1208 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1210 = stablehlo.reshape %1143 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1211 = stablehlo.transpose %arg140, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1212 = stablehlo.dot %1210, %1211, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1213 = stablehlo.reshape %1212 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1214 = "stablehlo.scatter"(%arg249, %1209, %1213) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1215 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1216 = "stablehlo.gather"(%1214, %1215) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1217 = stablehlo.transpose %1216, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1218 = stablehlo.reshape %1217 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1219 = stablehlo.dot_general %1204, %1218, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1220 = stablehlo.reshape %1219 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1221 = stablehlo.transpose %1220, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1222 = stablehlo.reshape %1221 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1223 = stablehlo.transpose %arg139, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1224 = stablehlo.dot %1222, %1223, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1225 = stablehlo.reshape %1224 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1226 = stablehlo.add %1131, %1225 : tensor<2x2048x4096xf32>
    %1227 = stablehlo.power %1226, %1 : tensor<2x2048x4096xf32>
    %1228 = stablehlo.reduce(%1227 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1229 = stablehlo.multiply %1228, %0 : tensor<2x2048xf32>
    %1230 = stablehlo.reshape %1229 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1231 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1232 = stablehlo.add %1230, %1231 : tensor<2x2048x1xf32>
    %1233 = stablehlo.rsqrt %1232 : tensor<2x2048x1xf32>
    %1234 = stablehlo.reshape %1233 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1235 = stablehlo.broadcast_in_dim %1234, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1236 = stablehlo.multiply %1226, %1235 : tensor<2x2048x4096xf32>
    %1237 = stablehlo.broadcast_in_dim %arg138, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1238 = stablehlo.multiply %1236, %1237 : tensor<2x2048x4096xf32>
    %1239 = stablehlo.reshape %1238 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1240 = stablehlo.transpose %arg253, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1241 = stablehlo.dot %1239, %1240, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1242 = stablehlo.reshape %1241 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1243 = stablehlo.logistic %1242 : tensor<2x2048x11008xf32>
    %1244 = stablehlo.multiply %1242, %1243 : tensor<2x2048x11008xf32>
    %1245 = stablehlo.reshape %1238 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1246 = stablehlo.transpose %arg137, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1247 = stablehlo.dot %1245, %1246, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1248 = stablehlo.reshape %1247 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1249 = stablehlo.multiply %1244, %1248 : tensor<2x2048x11008xf32>
    %1250 = stablehlo.reshape %1249 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1251 = stablehlo.transpose %arg136, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1252 = stablehlo.dot %1250, %1251, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1253 = stablehlo.reshape %1252 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1254 = stablehlo.add %1226, %1253 : tensor<2x2048x4096xf32>
    %1255 = stablehlo.power %1254, %1 : tensor<2x2048x4096xf32>
    %1256 = stablehlo.reduce(%1255 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1257 = stablehlo.multiply %1256, %0 : tensor<2x2048xf32>
    %1258 = stablehlo.reshape %1257 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1259 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1260 = stablehlo.add %1258, %1259 : tensor<2x2048x1xf32>
    %1261 = stablehlo.rsqrt %1260 : tensor<2x2048x1xf32>
    %1262 = stablehlo.reshape %1261 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1263 = stablehlo.broadcast_in_dim %1262, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1264 = stablehlo.multiply %1254, %1263 : tensor<2x2048x4096xf32>
    %1265 = stablehlo.broadcast_in_dim %arg135, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1266 = stablehlo.multiply %1264, %1265 : tensor<2x2048x4096xf32>
    %1267 = stablehlo.reshape %1266 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1268 = stablehlo.transpose %arg257, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1269 = stablehlo.dot %1267, %1268, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1270 = stablehlo.reshape %1269 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1271 = stablehlo.slice %1270 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1272 = stablehlo.reshape %1271 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1273 = stablehlo.slice %1270 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1274 = stablehlo.reshape %1273 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1275 = stablehlo.complex %1272, %1274 : tensor<2x2048x32x64xcomplex<f32>>
    %1276 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1277 = stablehlo.multiply %1275, %1276 : tensor<2x2048x32x64xcomplex<f32>>
    %1278 = stablehlo.real %1277 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1279 = stablehlo.reshape %1278 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1280 = stablehlo.imag %1277 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1281 = stablehlo.reshape %1280 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1282 = stablehlo.concatenate %1279, %1281, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1283 = stablehlo.reshape %1282 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1284 = stablehlo.transpose %1283, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1285 = stablehlo.reshape %1284 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1286 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1287 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1288 = stablehlo.add %arg199, %1287 : tensor<2048xi64>
    %1289 = stablehlo.select %1286, %1288, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1290 = stablehlo.reshape %1289 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1291 = stablehlo.reshape %1266 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1292 = stablehlo.transpose %arg255, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1293 = stablehlo.dot %1291, %1292, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1294 = stablehlo.reshape %1293 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1295 = stablehlo.slice %1294 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1296 = stablehlo.reshape %1295 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1297 = stablehlo.slice %1294 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1298 = stablehlo.reshape %1297 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1299 = stablehlo.complex %1296, %1298 : tensor<2x2048x32x64xcomplex<f32>>
    %1300 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1301 = stablehlo.multiply %1299, %1300 : tensor<2x2048x32x64xcomplex<f32>>
    %1302 = stablehlo.real %1301 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1303 = stablehlo.reshape %1302 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1304 = stablehlo.imag %1301 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1305 = stablehlo.reshape %1304 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1306 = stablehlo.concatenate %1303, %1305, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1307 = stablehlo.reshape %1306 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1308 = "stablehlo.scatter"(%arg256, %1290, %1307) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1309 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1310 = "stablehlo.gather"(%1308, %1309) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1311 = stablehlo.transpose %1310, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1312 = stablehlo.reshape %1311 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1313 = stablehlo.dot_general %1285, %1312, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1314 = stablehlo.reshape %1313 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1315 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1316 = stablehlo.divide %1314, %1315 : tensor<2x32x2048x2048xf32>
    %1317 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1318 = stablehlo.broadcast_in_dim %1317, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1319 = stablehlo.add %1316, %1318 : tensor<2x32x2048x2048xf32>
    %1320 = stablehlo.reduce(%1319 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1321 = stablehlo.broadcast_in_dim %1320, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1322 = stablehlo.subtract %1319, %1321 : tensor<2x32x2048x2048xf32>
    %1323 = stablehlo.exponential %1322 : tensor<2x32x2048x2048xf32>
    %1324 = stablehlo.reduce(%1323 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1325 = stablehlo.broadcast_in_dim %1324, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1326 = stablehlo.divide %1323, %1325 : tensor<2x32x2048x2048xf32>
    %1327 = stablehlo.reshape %1326 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1328 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1329 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1330 = stablehlo.add %arg199, %1329 : tensor<2048xi64>
    %1331 = stablehlo.select %1328, %1330, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1332 = stablehlo.reshape %1331 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1333 = stablehlo.reshape %1266 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1334 = stablehlo.transpose %arg134, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1335 = stablehlo.dot %1333, %1334, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1336 = stablehlo.reshape %1335 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1337 = "stablehlo.scatter"(%arg254, %1332, %1336) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1338 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1339 = "stablehlo.gather"(%1337, %1338) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1340 = stablehlo.transpose %1339, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1341 = stablehlo.reshape %1340 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1342 = stablehlo.dot_general %1327, %1341, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1343 = stablehlo.reshape %1342 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1344 = stablehlo.transpose %1343, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1345 = stablehlo.reshape %1344 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1346 = stablehlo.transpose %arg133, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1347 = stablehlo.dot %1345, %1346, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1348 = stablehlo.reshape %1347 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1349 = stablehlo.add %1254, %1348 : tensor<2x2048x4096xf32>
    %1350 = stablehlo.power %1349, %1 : tensor<2x2048x4096xf32>
    %1351 = stablehlo.reduce(%1350 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1352 = stablehlo.multiply %1351, %0 : tensor<2x2048xf32>
    %1353 = stablehlo.reshape %1352 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1354 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1355 = stablehlo.add %1353, %1354 : tensor<2x2048x1xf32>
    %1356 = stablehlo.rsqrt %1355 : tensor<2x2048x1xf32>
    %1357 = stablehlo.reshape %1356 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1358 = stablehlo.broadcast_in_dim %1357, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1359 = stablehlo.multiply %1349, %1358 : tensor<2x2048x4096xf32>
    %1360 = stablehlo.broadcast_in_dim %arg132, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1361 = stablehlo.multiply %1359, %1360 : tensor<2x2048x4096xf32>
    %1362 = stablehlo.reshape %1361 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1363 = stablehlo.transpose %arg258, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1364 = stablehlo.dot %1362, %1363, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1365 = stablehlo.reshape %1364 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1366 = stablehlo.logistic %1365 : tensor<2x2048x11008xf32>
    %1367 = stablehlo.multiply %1365, %1366 : tensor<2x2048x11008xf32>
    %1368 = stablehlo.reshape %1361 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1369 = stablehlo.transpose %arg131, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1370 = stablehlo.dot %1368, %1369, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1371 = stablehlo.reshape %1370 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1372 = stablehlo.multiply %1367, %1371 : tensor<2x2048x11008xf32>
    %1373 = stablehlo.reshape %1372 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1374 = stablehlo.transpose %arg130, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1375 = stablehlo.dot %1373, %1374, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1376 = stablehlo.reshape %1375 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1377 = stablehlo.add %1349, %1376 : tensor<2x2048x4096xf32>
    %1378 = stablehlo.power %1377, %1 : tensor<2x2048x4096xf32>
    %1379 = stablehlo.reduce(%1378 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1380 = stablehlo.multiply %1379, %0 : tensor<2x2048xf32>
    %1381 = stablehlo.reshape %1380 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1382 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1383 = stablehlo.add %1381, %1382 : tensor<2x2048x1xf32>
    %1384 = stablehlo.rsqrt %1383 : tensor<2x2048x1xf32>
    %1385 = stablehlo.reshape %1384 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1386 = stablehlo.broadcast_in_dim %1385, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1387 = stablehlo.multiply %1377, %1386 : tensor<2x2048x4096xf32>
    %1388 = stablehlo.broadcast_in_dim %arg129, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1389 = stablehlo.multiply %1387, %1388 : tensor<2x2048x4096xf32>
    %1390 = stablehlo.reshape %1389 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1391 = stablehlo.transpose %arg262, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1392 = stablehlo.dot %1390, %1391, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1393 = stablehlo.reshape %1392 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1394 = stablehlo.slice %1393 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1395 = stablehlo.reshape %1394 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1396 = stablehlo.slice %1393 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1397 = stablehlo.reshape %1396 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1398 = stablehlo.complex %1395, %1397 : tensor<2x2048x32x64xcomplex<f32>>
    %1399 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1400 = stablehlo.multiply %1398, %1399 : tensor<2x2048x32x64xcomplex<f32>>
    %1401 = stablehlo.real %1400 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1402 = stablehlo.reshape %1401 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1403 = stablehlo.imag %1400 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1404 = stablehlo.reshape %1403 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1405 = stablehlo.concatenate %1402, %1404, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1406 = stablehlo.reshape %1405 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1407 = stablehlo.transpose %1406, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1408 = stablehlo.reshape %1407 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1409 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1410 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1411 = stablehlo.add %arg199, %1410 : tensor<2048xi64>
    %1412 = stablehlo.select %1409, %1411, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1413 = stablehlo.reshape %1412 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1414 = stablehlo.reshape %1389 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1415 = stablehlo.transpose %arg260, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1416 = stablehlo.dot %1414, %1415, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1417 = stablehlo.reshape %1416 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1418 = stablehlo.slice %1417 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1419 = stablehlo.reshape %1418 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1420 = stablehlo.slice %1417 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1421 = stablehlo.reshape %1420 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1422 = stablehlo.complex %1419, %1421 : tensor<2x2048x32x64xcomplex<f32>>
    %1423 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1424 = stablehlo.multiply %1422, %1423 : tensor<2x2048x32x64xcomplex<f32>>
    %1425 = stablehlo.real %1424 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1426 = stablehlo.reshape %1425 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1427 = stablehlo.imag %1424 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1428 = stablehlo.reshape %1427 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1429 = stablehlo.concatenate %1426, %1428, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1430 = stablehlo.reshape %1429 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1431 = "stablehlo.scatter"(%arg261, %1413, %1430) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1432 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1433 = "stablehlo.gather"(%1431, %1432) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1434 = stablehlo.transpose %1433, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1435 = stablehlo.reshape %1434 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1436 = stablehlo.dot_general %1408, %1435, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1437 = stablehlo.reshape %1436 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1438 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1439 = stablehlo.divide %1437, %1438 : tensor<2x32x2048x2048xf32>
    %1440 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1441 = stablehlo.broadcast_in_dim %1440, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1442 = stablehlo.add %1439, %1441 : tensor<2x32x2048x2048xf32>
    %1443 = stablehlo.reduce(%1442 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1444 = stablehlo.broadcast_in_dim %1443, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1445 = stablehlo.subtract %1442, %1444 : tensor<2x32x2048x2048xf32>
    %1446 = stablehlo.exponential %1445 : tensor<2x32x2048x2048xf32>
    %1447 = stablehlo.reduce(%1446 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1448 = stablehlo.broadcast_in_dim %1447, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1449 = stablehlo.divide %1446, %1448 : tensor<2x32x2048x2048xf32>
    %1450 = stablehlo.reshape %1449 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1451 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1452 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1453 = stablehlo.add %arg199, %1452 : tensor<2048xi64>
    %1454 = stablehlo.select %1451, %1453, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1455 = stablehlo.reshape %1454 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1456 = stablehlo.reshape %1389 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1457 = stablehlo.transpose %arg128, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1458 = stablehlo.dot %1456, %1457, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1459 = stablehlo.reshape %1458 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1460 = "stablehlo.scatter"(%arg259, %1455, %1459) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1461 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1462 = "stablehlo.gather"(%1460, %1461) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1463 = stablehlo.transpose %1462, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1464 = stablehlo.reshape %1463 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1465 = stablehlo.dot_general %1450, %1464, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1466 = stablehlo.reshape %1465 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1467 = stablehlo.transpose %1466, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1468 = stablehlo.reshape %1467 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1469 = stablehlo.transpose %arg127, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1470 = stablehlo.dot %1468, %1469, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1471 = stablehlo.reshape %1470 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1472 = stablehlo.add %1377, %1471 : tensor<2x2048x4096xf32>
    %1473 = stablehlo.power %1472, %1 : tensor<2x2048x4096xf32>
    %1474 = stablehlo.reduce(%1473 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1475 = stablehlo.multiply %1474, %0 : tensor<2x2048xf32>
    %1476 = stablehlo.reshape %1475 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1477 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1478 = stablehlo.add %1476, %1477 : tensor<2x2048x1xf32>
    %1479 = stablehlo.rsqrt %1478 : tensor<2x2048x1xf32>
    %1480 = stablehlo.reshape %1479 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1481 = stablehlo.broadcast_in_dim %1480, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1482 = stablehlo.multiply %1472, %1481 : tensor<2x2048x4096xf32>
    %1483 = stablehlo.broadcast_in_dim %arg126, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1484 = stablehlo.multiply %1482, %1483 : tensor<2x2048x4096xf32>
    %1485 = stablehlo.reshape %1484 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1486 = stablehlo.transpose %arg263, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1487 = stablehlo.dot %1485, %1486, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1488 = stablehlo.reshape %1487 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1489 = stablehlo.logistic %1488 : tensor<2x2048x11008xf32>
    %1490 = stablehlo.multiply %1488, %1489 : tensor<2x2048x11008xf32>
    %1491 = stablehlo.reshape %1484 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1492 = stablehlo.transpose %arg125, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1493 = stablehlo.dot %1491, %1492, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1494 = stablehlo.reshape %1493 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1495 = stablehlo.multiply %1490, %1494 : tensor<2x2048x11008xf32>
    %1496 = stablehlo.reshape %1495 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1497 = stablehlo.transpose %arg124, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1498 = stablehlo.dot %1496, %1497, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1499 = stablehlo.reshape %1498 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1500 = stablehlo.add %1472, %1499 : tensor<2x2048x4096xf32>
    %1501 = stablehlo.power %1500, %1 : tensor<2x2048x4096xf32>
    %1502 = stablehlo.reduce(%1501 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1503 = stablehlo.multiply %1502, %0 : tensor<2x2048xf32>
    %1504 = stablehlo.reshape %1503 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1505 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1506 = stablehlo.add %1504, %1505 : tensor<2x2048x1xf32>
    %1507 = stablehlo.rsqrt %1506 : tensor<2x2048x1xf32>
    %1508 = stablehlo.reshape %1507 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1509 = stablehlo.broadcast_in_dim %1508, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1510 = stablehlo.multiply %1500, %1509 : tensor<2x2048x4096xf32>
    %1511 = stablehlo.broadcast_in_dim %arg123, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1512 = stablehlo.multiply %1510, %1511 : tensor<2x2048x4096xf32>
    %1513 = stablehlo.reshape %1512 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1514 = stablehlo.transpose %arg267, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1515 = stablehlo.dot %1513, %1514, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1516 = stablehlo.reshape %1515 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1517 = stablehlo.slice %1516 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1518 = stablehlo.reshape %1517 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1519 = stablehlo.slice %1516 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1520 = stablehlo.reshape %1519 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1521 = stablehlo.complex %1518, %1520 : tensor<2x2048x32x64xcomplex<f32>>
    %1522 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1523 = stablehlo.multiply %1521, %1522 : tensor<2x2048x32x64xcomplex<f32>>
    %1524 = stablehlo.real %1523 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1525 = stablehlo.reshape %1524 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1526 = stablehlo.imag %1523 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1527 = stablehlo.reshape %1526 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1528 = stablehlo.concatenate %1525, %1527, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1529 = stablehlo.reshape %1528 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1530 = stablehlo.transpose %1529, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1531 = stablehlo.reshape %1530 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1532 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1533 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1534 = stablehlo.add %arg199, %1533 : tensor<2048xi64>
    %1535 = stablehlo.select %1532, %1534, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1536 = stablehlo.reshape %1535 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1537 = stablehlo.reshape %1512 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1538 = stablehlo.transpose %arg265, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1539 = stablehlo.dot %1537, %1538, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1540 = stablehlo.reshape %1539 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1541 = stablehlo.slice %1540 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1542 = stablehlo.reshape %1541 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1543 = stablehlo.slice %1540 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1544 = stablehlo.reshape %1543 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1545 = stablehlo.complex %1542, %1544 : tensor<2x2048x32x64xcomplex<f32>>
    %1546 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1547 = stablehlo.multiply %1545, %1546 : tensor<2x2048x32x64xcomplex<f32>>
    %1548 = stablehlo.real %1547 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1549 = stablehlo.reshape %1548 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1550 = stablehlo.imag %1547 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1551 = stablehlo.reshape %1550 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1552 = stablehlo.concatenate %1549, %1551, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1553 = stablehlo.reshape %1552 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1554 = "stablehlo.scatter"(%arg266, %1536, %1553) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1555 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1556 = "stablehlo.gather"(%1554, %1555) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1557 = stablehlo.transpose %1556, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1558 = stablehlo.reshape %1557 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1559 = stablehlo.dot_general %1531, %1558, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1560 = stablehlo.reshape %1559 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1561 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1562 = stablehlo.divide %1560, %1561 : tensor<2x32x2048x2048xf32>
    %1563 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1564 = stablehlo.broadcast_in_dim %1563, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1565 = stablehlo.add %1562, %1564 : tensor<2x32x2048x2048xf32>
    %1566 = stablehlo.reduce(%1565 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1567 = stablehlo.broadcast_in_dim %1566, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1568 = stablehlo.subtract %1565, %1567 : tensor<2x32x2048x2048xf32>
    %1569 = stablehlo.exponential %1568 : tensor<2x32x2048x2048xf32>
    %1570 = stablehlo.reduce(%1569 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1571 = stablehlo.broadcast_in_dim %1570, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1572 = stablehlo.divide %1569, %1571 : tensor<2x32x2048x2048xf32>
    %1573 = stablehlo.reshape %1572 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1574 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1575 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1576 = stablehlo.add %arg199, %1575 : tensor<2048xi64>
    %1577 = stablehlo.select %1574, %1576, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1578 = stablehlo.reshape %1577 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1579 = stablehlo.reshape %1512 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1580 = stablehlo.transpose %arg122, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1581 = stablehlo.dot %1579, %1580, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1582 = stablehlo.reshape %1581 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1583 = "stablehlo.scatter"(%arg264, %1578, %1582) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1584 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1585 = "stablehlo.gather"(%1583, %1584) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1586 = stablehlo.transpose %1585, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1587 = stablehlo.reshape %1586 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1588 = stablehlo.dot_general %1573, %1587, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1589 = stablehlo.reshape %1588 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1590 = stablehlo.transpose %1589, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1591 = stablehlo.reshape %1590 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1592 = stablehlo.transpose %arg121, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1593 = stablehlo.dot %1591, %1592, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1594 = stablehlo.reshape %1593 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1595 = stablehlo.add %1500, %1594 : tensor<2x2048x4096xf32>
    %1596 = stablehlo.power %1595, %1 : tensor<2x2048x4096xf32>
    %1597 = stablehlo.reduce(%1596 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1598 = stablehlo.multiply %1597, %0 : tensor<2x2048xf32>
    %1599 = stablehlo.reshape %1598 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1600 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1601 = stablehlo.add %1599, %1600 : tensor<2x2048x1xf32>
    %1602 = stablehlo.rsqrt %1601 : tensor<2x2048x1xf32>
    %1603 = stablehlo.reshape %1602 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1604 = stablehlo.broadcast_in_dim %1603, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1605 = stablehlo.multiply %1595, %1604 : tensor<2x2048x4096xf32>
    %1606 = stablehlo.broadcast_in_dim %arg120, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1607 = stablehlo.multiply %1605, %1606 : tensor<2x2048x4096xf32>
    %1608 = stablehlo.reshape %1607 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1609 = stablehlo.transpose %arg268, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1610 = stablehlo.dot %1608, %1609, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1611 = stablehlo.reshape %1610 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1612 = stablehlo.logistic %1611 : tensor<2x2048x11008xf32>
    %1613 = stablehlo.multiply %1611, %1612 : tensor<2x2048x11008xf32>
    %1614 = stablehlo.reshape %1607 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1615 = stablehlo.transpose %arg119, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1616 = stablehlo.dot %1614, %1615, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1617 = stablehlo.reshape %1616 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1618 = stablehlo.multiply %1613, %1617 : tensor<2x2048x11008xf32>
    %1619 = stablehlo.reshape %1618 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1620 = stablehlo.transpose %arg118, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1621 = stablehlo.dot %1619, %1620, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1622 = stablehlo.reshape %1621 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1623 = stablehlo.add %1595, %1622 : tensor<2x2048x4096xf32>
    %1624 = stablehlo.power %1623, %1 : tensor<2x2048x4096xf32>
    %1625 = stablehlo.reduce(%1624 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1626 = stablehlo.multiply %1625, %0 : tensor<2x2048xf32>
    %1627 = stablehlo.reshape %1626 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1628 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1629 = stablehlo.add %1627, %1628 : tensor<2x2048x1xf32>
    %1630 = stablehlo.rsqrt %1629 : tensor<2x2048x1xf32>
    %1631 = stablehlo.reshape %1630 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1632 = stablehlo.broadcast_in_dim %1631, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1633 = stablehlo.multiply %1623, %1632 : tensor<2x2048x4096xf32>
    %1634 = stablehlo.broadcast_in_dim %arg117, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1635 = stablehlo.multiply %1633, %1634 : tensor<2x2048x4096xf32>
    %1636 = stablehlo.reshape %1635 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1637 = stablehlo.transpose %arg272, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1638 = stablehlo.dot %1636, %1637, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1639 = stablehlo.reshape %1638 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1640 = stablehlo.slice %1639 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1641 = stablehlo.reshape %1640 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1642 = stablehlo.slice %1639 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1643 = stablehlo.reshape %1642 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1644 = stablehlo.complex %1641, %1643 : tensor<2x2048x32x64xcomplex<f32>>
    %1645 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1646 = stablehlo.multiply %1644, %1645 : tensor<2x2048x32x64xcomplex<f32>>
    %1647 = stablehlo.real %1646 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1648 = stablehlo.reshape %1647 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1649 = stablehlo.imag %1646 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1650 = stablehlo.reshape %1649 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1651 = stablehlo.concatenate %1648, %1650, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1652 = stablehlo.reshape %1651 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1653 = stablehlo.transpose %1652, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1654 = stablehlo.reshape %1653 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1655 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1656 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1657 = stablehlo.add %arg199, %1656 : tensor<2048xi64>
    %1658 = stablehlo.select %1655, %1657, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1659 = stablehlo.reshape %1658 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1660 = stablehlo.reshape %1635 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1661 = stablehlo.transpose %arg270, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1662 = stablehlo.dot %1660, %1661, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1663 = stablehlo.reshape %1662 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1664 = stablehlo.slice %1663 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1665 = stablehlo.reshape %1664 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1666 = stablehlo.slice %1663 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1667 = stablehlo.reshape %1666 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1668 = stablehlo.complex %1665, %1667 : tensor<2x2048x32x64xcomplex<f32>>
    %1669 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1670 = stablehlo.multiply %1668, %1669 : tensor<2x2048x32x64xcomplex<f32>>
    %1671 = stablehlo.real %1670 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1672 = stablehlo.reshape %1671 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1673 = stablehlo.imag %1670 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1674 = stablehlo.reshape %1673 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1675 = stablehlo.concatenate %1672, %1674, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1676 = stablehlo.reshape %1675 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1677 = "stablehlo.scatter"(%arg271, %1659, %1676) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1678 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1679 = "stablehlo.gather"(%1677, %1678) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1680 = stablehlo.transpose %1679, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1681 = stablehlo.reshape %1680 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1682 = stablehlo.dot_general %1654, %1681, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1683 = stablehlo.reshape %1682 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1684 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1685 = stablehlo.divide %1683, %1684 : tensor<2x32x2048x2048xf32>
    %1686 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1687 = stablehlo.broadcast_in_dim %1686, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1688 = stablehlo.add %1685, %1687 : tensor<2x32x2048x2048xf32>
    %1689 = stablehlo.reduce(%1688 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1690 = stablehlo.broadcast_in_dim %1689, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1691 = stablehlo.subtract %1688, %1690 : tensor<2x32x2048x2048xf32>
    %1692 = stablehlo.exponential %1691 : tensor<2x32x2048x2048xf32>
    %1693 = stablehlo.reduce(%1692 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1694 = stablehlo.broadcast_in_dim %1693, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1695 = stablehlo.divide %1692, %1694 : tensor<2x32x2048x2048xf32>
    %1696 = stablehlo.reshape %1695 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1697 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1698 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1699 = stablehlo.add %arg199, %1698 : tensor<2048xi64>
    %1700 = stablehlo.select %1697, %1699, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1701 = stablehlo.reshape %1700 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1702 = stablehlo.reshape %1635 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1703 = stablehlo.transpose %arg116, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1704 = stablehlo.dot %1702, %1703, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1705 = stablehlo.reshape %1704 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1706 = "stablehlo.scatter"(%arg269, %1701, %1705) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1707 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1708 = "stablehlo.gather"(%1706, %1707) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1709 = stablehlo.transpose %1708, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1710 = stablehlo.reshape %1709 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1711 = stablehlo.dot_general %1696, %1710, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1712 = stablehlo.reshape %1711 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1713 = stablehlo.transpose %1712, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1714 = stablehlo.reshape %1713 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1715 = stablehlo.transpose %arg115, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1716 = stablehlo.dot %1714, %1715, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1717 = stablehlo.reshape %1716 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1718 = stablehlo.add %1623, %1717 : tensor<2x2048x4096xf32>
    %1719 = stablehlo.power %1718, %1 : tensor<2x2048x4096xf32>
    %1720 = stablehlo.reduce(%1719 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1721 = stablehlo.multiply %1720, %0 : tensor<2x2048xf32>
    %1722 = stablehlo.reshape %1721 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1723 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1724 = stablehlo.add %1722, %1723 : tensor<2x2048x1xf32>
    %1725 = stablehlo.rsqrt %1724 : tensor<2x2048x1xf32>
    %1726 = stablehlo.reshape %1725 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1727 = stablehlo.broadcast_in_dim %1726, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1728 = stablehlo.multiply %1718, %1727 : tensor<2x2048x4096xf32>
    %1729 = stablehlo.broadcast_in_dim %arg114, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1730 = stablehlo.multiply %1728, %1729 : tensor<2x2048x4096xf32>
    %1731 = stablehlo.reshape %1730 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1732 = stablehlo.transpose %arg273, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1733 = stablehlo.dot %1731, %1732, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1734 = stablehlo.reshape %1733 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1735 = stablehlo.logistic %1734 : tensor<2x2048x11008xf32>
    %1736 = stablehlo.multiply %1734, %1735 : tensor<2x2048x11008xf32>
    %1737 = stablehlo.reshape %1730 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1738 = stablehlo.transpose %arg113, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1739 = stablehlo.dot %1737, %1738, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1740 = stablehlo.reshape %1739 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1741 = stablehlo.multiply %1736, %1740 : tensor<2x2048x11008xf32>
    %1742 = stablehlo.reshape %1741 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1743 = stablehlo.transpose %arg112, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1744 = stablehlo.dot %1742, %1743, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1745 = stablehlo.reshape %1744 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1746 = stablehlo.add %1718, %1745 : tensor<2x2048x4096xf32>
    %1747 = stablehlo.power %1746, %1 : tensor<2x2048x4096xf32>
    %1748 = stablehlo.reduce(%1747 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1749 = stablehlo.multiply %1748, %0 : tensor<2x2048xf32>
    %1750 = stablehlo.reshape %1749 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1751 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1752 = stablehlo.add %1750, %1751 : tensor<2x2048x1xf32>
    %1753 = stablehlo.rsqrt %1752 : tensor<2x2048x1xf32>
    %1754 = stablehlo.reshape %1753 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1755 = stablehlo.broadcast_in_dim %1754, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1756 = stablehlo.multiply %1746, %1755 : tensor<2x2048x4096xf32>
    %1757 = stablehlo.broadcast_in_dim %arg111, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1758 = stablehlo.multiply %1756, %1757 : tensor<2x2048x4096xf32>
    %1759 = stablehlo.reshape %1758 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1760 = stablehlo.transpose %arg277, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1761 = stablehlo.dot %1759, %1760, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1762 = stablehlo.reshape %1761 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1763 = stablehlo.slice %1762 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1764 = stablehlo.reshape %1763 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1765 = stablehlo.slice %1762 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1766 = stablehlo.reshape %1765 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1767 = stablehlo.complex %1764, %1766 : tensor<2x2048x32x64xcomplex<f32>>
    %1768 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1769 = stablehlo.multiply %1767, %1768 : tensor<2x2048x32x64xcomplex<f32>>
    %1770 = stablehlo.real %1769 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1771 = stablehlo.reshape %1770 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1772 = stablehlo.imag %1769 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1773 = stablehlo.reshape %1772 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1774 = stablehlo.concatenate %1771, %1773, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1775 = stablehlo.reshape %1774 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1776 = stablehlo.transpose %1775, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1777 = stablehlo.reshape %1776 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1778 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1779 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1780 = stablehlo.add %arg199, %1779 : tensor<2048xi64>
    %1781 = stablehlo.select %1778, %1780, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1782 = stablehlo.reshape %1781 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1783 = stablehlo.reshape %1758 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1784 = stablehlo.transpose %arg275, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1785 = stablehlo.dot %1783, %1784, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1786 = stablehlo.reshape %1785 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1787 = stablehlo.slice %1786 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1788 = stablehlo.reshape %1787 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1789 = stablehlo.slice %1786 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1790 = stablehlo.reshape %1789 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1791 = stablehlo.complex %1788, %1790 : tensor<2x2048x32x64xcomplex<f32>>
    %1792 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1793 = stablehlo.multiply %1791, %1792 : tensor<2x2048x32x64xcomplex<f32>>
    %1794 = stablehlo.real %1793 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1795 = stablehlo.reshape %1794 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1796 = stablehlo.imag %1793 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1797 = stablehlo.reshape %1796 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1798 = stablehlo.concatenate %1795, %1797, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1799 = stablehlo.reshape %1798 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1800 = "stablehlo.scatter"(%arg276, %1782, %1799) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1801 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1802 = "stablehlo.gather"(%1800, %1801) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1803 = stablehlo.transpose %1802, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1804 = stablehlo.reshape %1803 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1805 = stablehlo.dot_general %1777, %1804, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1806 = stablehlo.reshape %1805 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1807 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1808 = stablehlo.divide %1806, %1807 : tensor<2x32x2048x2048xf32>
    %1809 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1810 = stablehlo.broadcast_in_dim %1809, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1811 = stablehlo.add %1808, %1810 : tensor<2x32x2048x2048xf32>
    %1812 = stablehlo.reduce(%1811 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1813 = stablehlo.broadcast_in_dim %1812, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1814 = stablehlo.subtract %1811, %1813 : tensor<2x32x2048x2048xf32>
    %1815 = stablehlo.exponential %1814 : tensor<2x32x2048x2048xf32>
    %1816 = stablehlo.reduce(%1815 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1817 = stablehlo.broadcast_in_dim %1816, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1818 = stablehlo.divide %1815, %1817 : tensor<2x32x2048x2048xf32>
    %1819 = stablehlo.reshape %1818 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1820 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1821 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1822 = stablehlo.add %arg199, %1821 : tensor<2048xi64>
    %1823 = stablehlo.select %1820, %1822, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1824 = stablehlo.reshape %1823 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1825 = stablehlo.reshape %1758 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1826 = stablehlo.transpose %arg110, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1827 = stablehlo.dot %1825, %1826, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1828 = stablehlo.reshape %1827 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1829 = "stablehlo.scatter"(%arg274, %1824, %1828) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1830 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1831 = "stablehlo.gather"(%1829, %1830) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1832 = stablehlo.transpose %1831, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1833 = stablehlo.reshape %1832 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1834 = stablehlo.dot_general %1819, %1833, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1835 = stablehlo.reshape %1834 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1836 = stablehlo.transpose %1835, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1837 = stablehlo.reshape %1836 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1838 = stablehlo.transpose %arg109, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1839 = stablehlo.dot %1837, %1838, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1840 = stablehlo.reshape %1839 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1841 = stablehlo.add %1746, %1840 : tensor<2x2048x4096xf32>
    %1842 = stablehlo.power %1841, %1 : tensor<2x2048x4096xf32>
    %1843 = stablehlo.reduce(%1842 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1844 = stablehlo.multiply %1843, %0 : tensor<2x2048xf32>
    %1845 = stablehlo.reshape %1844 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1846 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1847 = stablehlo.add %1845, %1846 : tensor<2x2048x1xf32>
    %1848 = stablehlo.rsqrt %1847 : tensor<2x2048x1xf32>
    %1849 = stablehlo.reshape %1848 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1850 = stablehlo.broadcast_in_dim %1849, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1851 = stablehlo.multiply %1841, %1850 : tensor<2x2048x4096xf32>
    %1852 = stablehlo.broadcast_in_dim %arg108, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1853 = stablehlo.multiply %1851, %1852 : tensor<2x2048x4096xf32>
    %1854 = stablehlo.reshape %1853 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1855 = stablehlo.transpose %arg278, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1856 = stablehlo.dot %1854, %1855, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1857 = stablehlo.reshape %1856 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1858 = stablehlo.logistic %1857 : tensor<2x2048x11008xf32>
    %1859 = stablehlo.multiply %1857, %1858 : tensor<2x2048x11008xf32>
    %1860 = stablehlo.reshape %1853 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1861 = stablehlo.transpose %arg107, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1862 = stablehlo.dot %1860, %1861, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1863 = stablehlo.reshape %1862 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1864 = stablehlo.multiply %1859, %1863 : tensor<2x2048x11008xf32>
    %1865 = stablehlo.reshape %1864 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1866 = stablehlo.transpose %arg106, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1867 = stablehlo.dot %1865, %1866, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1868 = stablehlo.reshape %1867 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1869 = stablehlo.add %1841, %1868 : tensor<2x2048x4096xf32>
    %1870 = stablehlo.power %1869, %1 : tensor<2x2048x4096xf32>
    %1871 = stablehlo.reduce(%1870 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1872 = stablehlo.multiply %1871, %0 : tensor<2x2048xf32>
    %1873 = stablehlo.reshape %1872 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1874 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1875 = stablehlo.add %1873, %1874 : tensor<2x2048x1xf32>
    %1876 = stablehlo.rsqrt %1875 : tensor<2x2048x1xf32>
    %1877 = stablehlo.reshape %1876 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1878 = stablehlo.broadcast_in_dim %1877, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1879 = stablehlo.multiply %1869, %1878 : tensor<2x2048x4096xf32>
    %1880 = stablehlo.broadcast_in_dim %arg105, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1881 = stablehlo.multiply %1879, %1880 : tensor<2x2048x4096xf32>
    %1882 = stablehlo.reshape %1881 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1883 = stablehlo.transpose %arg282, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1884 = stablehlo.dot %1882, %1883, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1885 = stablehlo.reshape %1884 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1886 = stablehlo.slice %1885 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1887 = stablehlo.reshape %1886 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1888 = stablehlo.slice %1885 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1889 = stablehlo.reshape %1888 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1890 = stablehlo.complex %1887, %1889 : tensor<2x2048x32x64xcomplex<f32>>
    %1891 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1892 = stablehlo.multiply %1890, %1891 : tensor<2x2048x32x64xcomplex<f32>>
    %1893 = stablehlo.real %1892 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1894 = stablehlo.reshape %1893 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1895 = stablehlo.imag %1892 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1896 = stablehlo.reshape %1895 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1897 = stablehlo.concatenate %1894, %1896, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1898 = stablehlo.reshape %1897 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1899 = stablehlo.transpose %1898, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1900 = stablehlo.reshape %1899 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1901 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1902 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1903 = stablehlo.add %arg199, %1902 : tensor<2048xi64>
    %1904 = stablehlo.select %1901, %1903, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1905 = stablehlo.reshape %1904 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1906 = stablehlo.reshape %1881 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1907 = stablehlo.transpose %arg280, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1908 = stablehlo.dot %1906, %1907, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1909 = stablehlo.reshape %1908 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %1910 = stablehlo.slice %1909 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1911 = stablehlo.reshape %1910 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1912 = stablehlo.slice %1909 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %1913 = stablehlo.reshape %1912 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %1914 = stablehlo.complex %1911, %1913 : tensor<2x2048x32x64xcomplex<f32>>
    %1915 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %1916 = stablehlo.multiply %1914, %1915 : tensor<2x2048x32x64xcomplex<f32>>
    %1917 = stablehlo.real %1916 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1918 = stablehlo.reshape %1917 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1919 = stablehlo.imag %1916 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %1920 = stablehlo.reshape %1919 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %1921 = stablehlo.concatenate %1918, %1920, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %1922 = stablehlo.reshape %1921 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %1923 = "stablehlo.scatter"(%arg281, %1905, %1922) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1924 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1925 = "stablehlo.gather"(%1923, %1924) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1926 = stablehlo.transpose %1925, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %1927 = stablehlo.reshape %1926 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %1928 = stablehlo.dot_general %1900, %1927, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %1929 = stablehlo.reshape %1928 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1930 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %1931 = stablehlo.divide %1929, %1930 : tensor<2x32x2048x2048xf32>
    %1932 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %1933 = stablehlo.broadcast_in_dim %1932, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1934 = stablehlo.add %1931, %1933 : tensor<2x32x2048x2048xf32>
    %1935 = stablehlo.reduce(%1934 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1936 = stablehlo.broadcast_in_dim %1935, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1937 = stablehlo.subtract %1934, %1936 : tensor<2x32x2048x2048xf32>
    %1938 = stablehlo.exponential %1937 : tensor<2x32x2048x2048xf32>
    %1939 = stablehlo.reduce(%1938 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1940 = stablehlo.broadcast_in_dim %1939, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %1941 = stablehlo.divide %1938, %1940 : tensor<2x32x2048x2048xf32>
    %1942 = stablehlo.reshape %1941 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %1943 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %1944 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %1945 = stablehlo.add %arg199, %1944 : tensor<2048xi64>
    %1946 = stablehlo.select %1943, %1945, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %1947 = stablehlo.reshape %1946 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %1948 = stablehlo.reshape %1881 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1949 = stablehlo.transpose %arg104, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1950 = stablehlo.dot %1948, %1949, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1951 = stablehlo.reshape %1950 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %1952 = "stablehlo.scatter"(%arg279, %1947, %1951) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %1953 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %1954 = "stablehlo.gather"(%1952, %1953) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %1955 = stablehlo.transpose %1954, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %1956 = stablehlo.reshape %1955 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1957 = stablehlo.dot_general %1942, %1956, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %1958 = stablehlo.reshape %1957 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %1959 = stablehlo.transpose %1958, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %1960 = stablehlo.reshape %1959 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %1961 = stablehlo.transpose %arg103, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1962 = stablehlo.dot %1960, %1961, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %1963 = stablehlo.reshape %1962 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1964 = stablehlo.add %1869, %1963 : tensor<2x2048x4096xf32>
    %1965 = stablehlo.power %1964, %1 : tensor<2x2048x4096xf32>
    %1966 = stablehlo.reduce(%1965 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1967 = stablehlo.multiply %1966, %0 : tensor<2x2048xf32>
    %1968 = stablehlo.reshape %1967 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1969 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1970 = stablehlo.add %1968, %1969 : tensor<2x2048x1xf32>
    %1971 = stablehlo.rsqrt %1970 : tensor<2x2048x1xf32>
    %1972 = stablehlo.reshape %1971 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %1973 = stablehlo.broadcast_in_dim %1972, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %1974 = stablehlo.multiply %1964, %1973 : tensor<2x2048x4096xf32>
    %1975 = stablehlo.broadcast_in_dim %arg102, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %1976 = stablehlo.multiply %1974, %1975 : tensor<2x2048x4096xf32>
    %1977 = stablehlo.reshape %1976 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1978 = stablehlo.transpose %arg283, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1979 = stablehlo.dot %1977, %1978, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1980 = stablehlo.reshape %1979 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1981 = stablehlo.logistic %1980 : tensor<2x2048x11008xf32>
    %1982 = stablehlo.multiply %1980, %1981 : tensor<2x2048x11008xf32>
    %1983 = stablehlo.reshape %1976 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %1984 = stablehlo.transpose %arg101, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %1985 = stablehlo.dot %1983, %1984, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %1986 = stablehlo.reshape %1985 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %1987 = stablehlo.multiply %1982, %1986 : tensor<2x2048x11008xf32>
    %1988 = stablehlo.reshape %1987 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %1989 = stablehlo.transpose %arg100, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %1990 = stablehlo.dot %1988, %1989, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %1991 = stablehlo.reshape %1990 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %1992 = stablehlo.add %1964, %1991 : tensor<2x2048x4096xf32>
    %1993 = stablehlo.power %1992, %1 : tensor<2x2048x4096xf32>
    %1994 = stablehlo.reduce(%1993 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %1995 = stablehlo.multiply %1994, %0 : tensor<2x2048xf32>
    %1996 = stablehlo.reshape %1995 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %1997 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %1998 = stablehlo.add %1996, %1997 : tensor<2x2048x1xf32>
    %1999 = stablehlo.rsqrt %1998 : tensor<2x2048x1xf32>
    %2000 = stablehlo.reshape %1999 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2001 = stablehlo.broadcast_in_dim %2000, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2002 = stablehlo.multiply %1992, %2001 : tensor<2x2048x4096xf32>
    %2003 = stablehlo.broadcast_in_dim %arg99, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2004 = stablehlo.multiply %2002, %2003 : tensor<2x2048x4096xf32>
    %2005 = stablehlo.reshape %2004 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2006 = stablehlo.transpose %arg287, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2007 = stablehlo.dot %2005, %2006, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2008 = stablehlo.reshape %2007 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2009 = stablehlo.slice %2008 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2010 = stablehlo.reshape %2009 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2011 = stablehlo.slice %2008 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2012 = stablehlo.reshape %2011 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2013 = stablehlo.complex %2010, %2012 : tensor<2x2048x32x64xcomplex<f32>>
    %2014 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2015 = stablehlo.multiply %2013, %2014 : tensor<2x2048x32x64xcomplex<f32>>
    %2016 = stablehlo.real %2015 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2017 = stablehlo.reshape %2016 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2018 = stablehlo.imag %2015 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2019 = stablehlo.reshape %2018 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2020 = stablehlo.concatenate %2017, %2019, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2021 = stablehlo.reshape %2020 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2022 = stablehlo.transpose %2021, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2023 = stablehlo.reshape %2022 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2024 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2025 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2026 = stablehlo.add %arg199, %2025 : tensor<2048xi64>
    %2027 = stablehlo.select %2024, %2026, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2028 = stablehlo.reshape %2027 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2029 = stablehlo.reshape %2004 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2030 = stablehlo.transpose %arg285, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2031 = stablehlo.dot %2029, %2030, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2032 = stablehlo.reshape %2031 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2033 = stablehlo.slice %2032 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2034 = stablehlo.reshape %2033 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2035 = stablehlo.slice %2032 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2036 = stablehlo.reshape %2035 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2037 = stablehlo.complex %2034, %2036 : tensor<2x2048x32x64xcomplex<f32>>
    %2038 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2039 = stablehlo.multiply %2037, %2038 : tensor<2x2048x32x64xcomplex<f32>>
    %2040 = stablehlo.real %2039 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2041 = stablehlo.reshape %2040 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2042 = stablehlo.imag %2039 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2043 = stablehlo.reshape %2042 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2044 = stablehlo.concatenate %2041, %2043, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2045 = stablehlo.reshape %2044 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2046 = "stablehlo.scatter"(%arg286, %2028, %2045) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2047 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2048 = "stablehlo.gather"(%2046, %2047) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2049 = stablehlo.transpose %2048, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2050 = stablehlo.reshape %2049 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2051 = stablehlo.dot_general %2023, %2050, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2052 = stablehlo.reshape %2051 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2053 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2054 = stablehlo.divide %2052, %2053 : tensor<2x32x2048x2048xf32>
    %2055 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2056 = stablehlo.broadcast_in_dim %2055, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2057 = stablehlo.add %2054, %2056 : tensor<2x32x2048x2048xf32>
    %2058 = stablehlo.reduce(%2057 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2059 = stablehlo.broadcast_in_dim %2058, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2060 = stablehlo.subtract %2057, %2059 : tensor<2x32x2048x2048xf32>
    %2061 = stablehlo.exponential %2060 : tensor<2x32x2048x2048xf32>
    %2062 = stablehlo.reduce(%2061 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2063 = stablehlo.broadcast_in_dim %2062, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2064 = stablehlo.divide %2061, %2063 : tensor<2x32x2048x2048xf32>
    %2065 = stablehlo.reshape %2064 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2066 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2067 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2068 = stablehlo.add %arg199, %2067 : tensor<2048xi64>
    %2069 = stablehlo.select %2066, %2068, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2070 = stablehlo.reshape %2069 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2071 = stablehlo.reshape %2004 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2072 = stablehlo.transpose %arg98, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2073 = stablehlo.dot %2071, %2072, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2074 = stablehlo.reshape %2073 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2075 = "stablehlo.scatter"(%arg284, %2070, %2074) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2076 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2077 = "stablehlo.gather"(%2075, %2076) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2078 = stablehlo.transpose %2077, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2079 = stablehlo.reshape %2078 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2080 = stablehlo.dot_general %2065, %2079, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2081 = stablehlo.reshape %2080 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2082 = stablehlo.transpose %2081, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2083 = stablehlo.reshape %2082 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2084 = stablehlo.transpose %arg97, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2085 = stablehlo.dot %2083, %2084, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2086 = stablehlo.reshape %2085 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2087 = stablehlo.add %1992, %2086 : tensor<2x2048x4096xf32>
    %2088 = stablehlo.power %2087, %1 : tensor<2x2048x4096xf32>
    %2089 = stablehlo.reduce(%2088 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2090 = stablehlo.multiply %2089, %0 : tensor<2x2048xf32>
    %2091 = stablehlo.reshape %2090 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2092 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2093 = stablehlo.add %2091, %2092 : tensor<2x2048x1xf32>
    %2094 = stablehlo.rsqrt %2093 : tensor<2x2048x1xf32>
    %2095 = stablehlo.reshape %2094 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2096 = stablehlo.broadcast_in_dim %2095, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2097 = stablehlo.multiply %2087, %2096 : tensor<2x2048x4096xf32>
    %2098 = stablehlo.broadcast_in_dim %arg96, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2099 = stablehlo.multiply %2097, %2098 : tensor<2x2048x4096xf32>
    %2100 = stablehlo.reshape %2099 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2101 = stablehlo.transpose %arg288, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2102 = stablehlo.dot %2100, %2101, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2103 = stablehlo.reshape %2102 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2104 = stablehlo.logistic %2103 : tensor<2x2048x11008xf32>
    %2105 = stablehlo.multiply %2103, %2104 : tensor<2x2048x11008xf32>
    %2106 = stablehlo.reshape %2099 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2107 = stablehlo.transpose %arg95, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2108 = stablehlo.dot %2106, %2107, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2109 = stablehlo.reshape %2108 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2110 = stablehlo.multiply %2105, %2109 : tensor<2x2048x11008xf32>
    %2111 = stablehlo.reshape %2110 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2112 = stablehlo.transpose %arg94, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2113 = stablehlo.dot %2111, %2112, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2114 = stablehlo.reshape %2113 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2115 = stablehlo.add %2087, %2114 : tensor<2x2048x4096xf32>
    %2116 = stablehlo.power %2115, %1 : tensor<2x2048x4096xf32>
    %2117 = stablehlo.reduce(%2116 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2118 = stablehlo.multiply %2117, %0 : tensor<2x2048xf32>
    %2119 = stablehlo.reshape %2118 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2120 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2121 = stablehlo.add %2119, %2120 : tensor<2x2048x1xf32>
    %2122 = stablehlo.rsqrt %2121 : tensor<2x2048x1xf32>
    %2123 = stablehlo.reshape %2122 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2124 = stablehlo.broadcast_in_dim %2123, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2125 = stablehlo.multiply %2115, %2124 : tensor<2x2048x4096xf32>
    %2126 = stablehlo.broadcast_in_dim %arg93, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2127 = stablehlo.multiply %2125, %2126 : tensor<2x2048x4096xf32>
    %2128 = stablehlo.reshape %2127 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2129 = stablehlo.transpose %arg292, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2130 = stablehlo.dot %2128, %2129, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2131 = stablehlo.reshape %2130 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2132 = stablehlo.slice %2131 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2133 = stablehlo.reshape %2132 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2134 = stablehlo.slice %2131 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2135 = stablehlo.reshape %2134 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2136 = stablehlo.complex %2133, %2135 : tensor<2x2048x32x64xcomplex<f32>>
    %2137 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2138 = stablehlo.multiply %2136, %2137 : tensor<2x2048x32x64xcomplex<f32>>
    %2139 = stablehlo.real %2138 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2140 = stablehlo.reshape %2139 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2141 = stablehlo.imag %2138 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2142 = stablehlo.reshape %2141 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2143 = stablehlo.concatenate %2140, %2142, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2144 = stablehlo.reshape %2143 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2145 = stablehlo.transpose %2144, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2146 = stablehlo.reshape %2145 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2147 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2148 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2149 = stablehlo.add %arg199, %2148 : tensor<2048xi64>
    %2150 = stablehlo.select %2147, %2149, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2151 = stablehlo.reshape %2150 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2152 = stablehlo.reshape %2127 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2153 = stablehlo.transpose %arg290, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2154 = stablehlo.dot %2152, %2153, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2155 = stablehlo.reshape %2154 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2156 = stablehlo.slice %2155 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2157 = stablehlo.reshape %2156 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2158 = stablehlo.slice %2155 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2159 = stablehlo.reshape %2158 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2160 = stablehlo.complex %2157, %2159 : tensor<2x2048x32x64xcomplex<f32>>
    %2161 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2162 = stablehlo.multiply %2160, %2161 : tensor<2x2048x32x64xcomplex<f32>>
    %2163 = stablehlo.real %2162 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2164 = stablehlo.reshape %2163 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2165 = stablehlo.imag %2162 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2166 = stablehlo.reshape %2165 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2167 = stablehlo.concatenate %2164, %2166, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2168 = stablehlo.reshape %2167 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2169 = "stablehlo.scatter"(%arg291, %2151, %2168) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2170 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2171 = "stablehlo.gather"(%2169, %2170) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2172 = stablehlo.transpose %2171, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2173 = stablehlo.reshape %2172 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2174 = stablehlo.dot_general %2146, %2173, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2175 = stablehlo.reshape %2174 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2176 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2177 = stablehlo.divide %2175, %2176 : tensor<2x32x2048x2048xf32>
    %2178 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2179 = stablehlo.broadcast_in_dim %2178, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2180 = stablehlo.add %2177, %2179 : tensor<2x32x2048x2048xf32>
    %2181 = stablehlo.reduce(%2180 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2182 = stablehlo.broadcast_in_dim %2181, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2183 = stablehlo.subtract %2180, %2182 : tensor<2x32x2048x2048xf32>
    %2184 = stablehlo.exponential %2183 : tensor<2x32x2048x2048xf32>
    %2185 = stablehlo.reduce(%2184 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2186 = stablehlo.broadcast_in_dim %2185, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2187 = stablehlo.divide %2184, %2186 : tensor<2x32x2048x2048xf32>
    %2188 = stablehlo.reshape %2187 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2189 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2190 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2191 = stablehlo.add %arg199, %2190 : tensor<2048xi64>
    %2192 = stablehlo.select %2189, %2191, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2193 = stablehlo.reshape %2192 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2194 = stablehlo.reshape %2127 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2195 = stablehlo.transpose %arg92, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2196 = stablehlo.dot %2194, %2195, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2197 = stablehlo.reshape %2196 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2198 = "stablehlo.scatter"(%arg289, %2193, %2197) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2199 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2200 = "stablehlo.gather"(%2198, %2199) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2201 = stablehlo.transpose %2200, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2202 = stablehlo.reshape %2201 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2203 = stablehlo.dot_general %2188, %2202, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2204 = stablehlo.reshape %2203 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2205 = stablehlo.transpose %2204, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2206 = stablehlo.reshape %2205 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2207 = stablehlo.transpose %arg91, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2208 = stablehlo.dot %2206, %2207, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2209 = stablehlo.reshape %2208 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2210 = stablehlo.add %2115, %2209 : tensor<2x2048x4096xf32>
    %2211 = stablehlo.power %2210, %1 : tensor<2x2048x4096xf32>
    %2212 = stablehlo.reduce(%2211 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2213 = stablehlo.multiply %2212, %0 : tensor<2x2048xf32>
    %2214 = stablehlo.reshape %2213 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2215 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2216 = stablehlo.add %2214, %2215 : tensor<2x2048x1xf32>
    %2217 = stablehlo.rsqrt %2216 : tensor<2x2048x1xf32>
    %2218 = stablehlo.reshape %2217 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2219 = stablehlo.broadcast_in_dim %2218, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2220 = stablehlo.multiply %2210, %2219 : tensor<2x2048x4096xf32>
    %2221 = stablehlo.broadcast_in_dim %arg90, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2222 = stablehlo.multiply %2220, %2221 : tensor<2x2048x4096xf32>
    %2223 = stablehlo.reshape %2222 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2224 = stablehlo.transpose %arg293, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2225 = stablehlo.dot %2223, %2224, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2226 = stablehlo.reshape %2225 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2227 = stablehlo.logistic %2226 : tensor<2x2048x11008xf32>
    %2228 = stablehlo.multiply %2226, %2227 : tensor<2x2048x11008xf32>
    %2229 = stablehlo.reshape %2222 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2230 = stablehlo.transpose %arg89, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2231 = stablehlo.dot %2229, %2230, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2232 = stablehlo.reshape %2231 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2233 = stablehlo.multiply %2228, %2232 : tensor<2x2048x11008xf32>
    %2234 = stablehlo.reshape %2233 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2235 = stablehlo.transpose %arg88, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2236 = stablehlo.dot %2234, %2235, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2237 = stablehlo.reshape %2236 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2238 = stablehlo.add %2210, %2237 : tensor<2x2048x4096xf32>
    %2239 = stablehlo.power %2238, %1 : tensor<2x2048x4096xf32>
    %2240 = stablehlo.reduce(%2239 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2241 = stablehlo.multiply %2240, %0 : tensor<2x2048xf32>
    %2242 = stablehlo.reshape %2241 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2243 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2244 = stablehlo.add %2242, %2243 : tensor<2x2048x1xf32>
    %2245 = stablehlo.rsqrt %2244 : tensor<2x2048x1xf32>
    %2246 = stablehlo.reshape %2245 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2247 = stablehlo.broadcast_in_dim %2246, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2248 = stablehlo.multiply %2238, %2247 : tensor<2x2048x4096xf32>
    %2249 = stablehlo.broadcast_in_dim %arg87, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2250 = stablehlo.multiply %2248, %2249 : tensor<2x2048x4096xf32>
    %2251 = stablehlo.reshape %2250 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2252 = stablehlo.transpose %arg297, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2253 = stablehlo.dot %2251, %2252, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2254 = stablehlo.reshape %2253 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2255 = stablehlo.slice %2254 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2256 = stablehlo.reshape %2255 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2257 = stablehlo.slice %2254 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2258 = stablehlo.reshape %2257 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2259 = stablehlo.complex %2256, %2258 : tensor<2x2048x32x64xcomplex<f32>>
    %2260 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2261 = stablehlo.multiply %2259, %2260 : tensor<2x2048x32x64xcomplex<f32>>
    %2262 = stablehlo.real %2261 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2263 = stablehlo.reshape %2262 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2264 = stablehlo.imag %2261 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2265 = stablehlo.reshape %2264 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2266 = stablehlo.concatenate %2263, %2265, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2267 = stablehlo.reshape %2266 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2268 = stablehlo.transpose %2267, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2269 = stablehlo.reshape %2268 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2270 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2271 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2272 = stablehlo.add %arg199, %2271 : tensor<2048xi64>
    %2273 = stablehlo.select %2270, %2272, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2274 = stablehlo.reshape %2273 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2275 = stablehlo.reshape %2250 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2276 = stablehlo.transpose %arg295, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2277 = stablehlo.dot %2275, %2276, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2278 = stablehlo.reshape %2277 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2279 = stablehlo.slice %2278 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2280 = stablehlo.reshape %2279 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2281 = stablehlo.slice %2278 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2282 = stablehlo.reshape %2281 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2283 = stablehlo.complex %2280, %2282 : tensor<2x2048x32x64xcomplex<f32>>
    %2284 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2285 = stablehlo.multiply %2283, %2284 : tensor<2x2048x32x64xcomplex<f32>>
    %2286 = stablehlo.real %2285 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2287 = stablehlo.reshape %2286 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2288 = stablehlo.imag %2285 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2289 = stablehlo.reshape %2288 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2290 = stablehlo.concatenate %2287, %2289, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2291 = stablehlo.reshape %2290 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2292 = "stablehlo.scatter"(%arg296, %2274, %2291) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2293 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2294 = "stablehlo.gather"(%2292, %2293) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2295 = stablehlo.transpose %2294, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2296 = stablehlo.reshape %2295 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2297 = stablehlo.dot_general %2269, %2296, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2298 = stablehlo.reshape %2297 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2299 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2300 = stablehlo.divide %2298, %2299 : tensor<2x32x2048x2048xf32>
    %2301 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2302 = stablehlo.broadcast_in_dim %2301, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2303 = stablehlo.add %2300, %2302 : tensor<2x32x2048x2048xf32>
    %2304 = stablehlo.reduce(%2303 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2305 = stablehlo.broadcast_in_dim %2304, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2306 = stablehlo.subtract %2303, %2305 : tensor<2x32x2048x2048xf32>
    %2307 = stablehlo.exponential %2306 : tensor<2x32x2048x2048xf32>
    %2308 = stablehlo.reduce(%2307 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2309 = stablehlo.broadcast_in_dim %2308, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2310 = stablehlo.divide %2307, %2309 : tensor<2x32x2048x2048xf32>
    %2311 = stablehlo.reshape %2310 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2312 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2313 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2314 = stablehlo.add %arg199, %2313 : tensor<2048xi64>
    %2315 = stablehlo.select %2312, %2314, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2316 = stablehlo.reshape %2315 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2317 = stablehlo.reshape %2250 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2318 = stablehlo.transpose %arg86, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2319 = stablehlo.dot %2317, %2318, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2320 = stablehlo.reshape %2319 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2321 = "stablehlo.scatter"(%arg294, %2316, %2320) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2322 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2323 = "stablehlo.gather"(%2321, %2322) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2324 = stablehlo.transpose %2323, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2325 = stablehlo.reshape %2324 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2326 = stablehlo.dot_general %2311, %2325, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2327 = stablehlo.reshape %2326 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2328 = stablehlo.transpose %2327, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2329 = stablehlo.reshape %2328 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2330 = stablehlo.transpose %arg85, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2331 = stablehlo.dot %2329, %2330, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2332 = stablehlo.reshape %2331 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2333 = stablehlo.add %2238, %2332 : tensor<2x2048x4096xf32>
    %2334 = stablehlo.power %2333, %1 : tensor<2x2048x4096xf32>
    %2335 = stablehlo.reduce(%2334 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2336 = stablehlo.multiply %2335, %0 : tensor<2x2048xf32>
    %2337 = stablehlo.reshape %2336 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2338 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2339 = stablehlo.add %2337, %2338 : tensor<2x2048x1xf32>
    %2340 = stablehlo.rsqrt %2339 : tensor<2x2048x1xf32>
    %2341 = stablehlo.reshape %2340 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2342 = stablehlo.broadcast_in_dim %2341, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2343 = stablehlo.multiply %2333, %2342 : tensor<2x2048x4096xf32>
    %2344 = stablehlo.broadcast_in_dim %arg84, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2345 = stablehlo.multiply %2343, %2344 : tensor<2x2048x4096xf32>
    %2346 = stablehlo.reshape %2345 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2347 = stablehlo.transpose %arg298, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2348 = stablehlo.dot %2346, %2347, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2349 = stablehlo.reshape %2348 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2350 = stablehlo.logistic %2349 : tensor<2x2048x11008xf32>
    %2351 = stablehlo.multiply %2349, %2350 : tensor<2x2048x11008xf32>
    %2352 = stablehlo.reshape %2345 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2353 = stablehlo.transpose %arg83, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2354 = stablehlo.dot %2352, %2353, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2355 = stablehlo.reshape %2354 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2356 = stablehlo.multiply %2351, %2355 : tensor<2x2048x11008xf32>
    %2357 = stablehlo.reshape %2356 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2358 = stablehlo.transpose %arg82, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2359 = stablehlo.dot %2357, %2358, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2360 = stablehlo.reshape %2359 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2361 = stablehlo.add %2333, %2360 : tensor<2x2048x4096xf32>
    %2362 = stablehlo.power %2361, %1 : tensor<2x2048x4096xf32>
    %2363 = stablehlo.reduce(%2362 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2364 = stablehlo.multiply %2363, %0 : tensor<2x2048xf32>
    %2365 = stablehlo.reshape %2364 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2366 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2367 = stablehlo.add %2365, %2366 : tensor<2x2048x1xf32>
    %2368 = stablehlo.rsqrt %2367 : tensor<2x2048x1xf32>
    %2369 = stablehlo.reshape %2368 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2370 = stablehlo.broadcast_in_dim %2369, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2371 = stablehlo.multiply %2361, %2370 : tensor<2x2048x4096xf32>
    %2372 = stablehlo.broadcast_in_dim %arg81, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2373 = stablehlo.multiply %2371, %2372 : tensor<2x2048x4096xf32>
    %2374 = stablehlo.reshape %2373 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2375 = stablehlo.transpose %arg302, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2376 = stablehlo.dot %2374, %2375, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2377 = stablehlo.reshape %2376 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2378 = stablehlo.slice %2377 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2379 = stablehlo.reshape %2378 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2380 = stablehlo.slice %2377 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2381 = stablehlo.reshape %2380 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2382 = stablehlo.complex %2379, %2381 : tensor<2x2048x32x64xcomplex<f32>>
    %2383 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2384 = stablehlo.multiply %2382, %2383 : tensor<2x2048x32x64xcomplex<f32>>
    %2385 = stablehlo.real %2384 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2386 = stablehlo.reshape %2385 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2387 = stablehlo.imag %2384 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2388 = stablehlo.reshape %2387 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2389 = stablehlo.concatenate %2386, %2388, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2390 = stablehlo.reshape %2389 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2391 = stablehlo.transpose %2390, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2392 = stablehlo.reshape %2391 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2393 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2394 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2395 = stablehlo.add %arg199, %2394 : tensor<2048xi64>
    %2396 = stablehlo.select %2393, %2395, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2397 = stablehlo.reshape %2396 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2398 = stablehlo.reshape %2373 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2399 = stablehlo.transpose %arg300, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2400 = stablehlo.dot %2398, %2399, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2401 = stablehlo.reshape %2400 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2402 = stablehlo.slice %2401 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2403 = stablehlo.reshape %2402 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2404 = stablehlo.slice %2401 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2405 = stablehlo.reshape %2404 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2406 = stablehlo.complex %2403, %2405 : tensor<2x2048x32x64xcomplex<f32>>
    %2407 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2408 = stablehlo.multiply %2406, %2407 : tensor<2x2048x32x64xcomplex<f32>>
    %2409 = stablehlo.real %2408 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2410 = stablehlo.reshape %2409 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2411 = stablehlo.imag %2408 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2412 = stablehlo.reshape %2411 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2413 = stablehlo.concatenate %2410, %2412, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2414 = stablehlo.reshape %2413 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2415 = "stablehlo.scatter"(%arg301, %2397, %2414) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2416 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2417 = "stablehlo.gather"(%2415, %2416) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2418 = stablehlo.transpose %2417, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2419 = stablehlo.reshape %2418 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2420 = stablehlo.dot_general %2392, %2419, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2421 = stablehlo.reshape %2420 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2422 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2423 = stablehlo.divide %2421, %2422 : tensor<2x32x2048x2048xf32>
    %2424 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2425 = stablehlo.broadcast_in_dim %2424, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2426 = stablehlo.add %2423, %2425 : tensor<2x32x2048x2048xf32>
    %2427 = stablehlo.reduce(%2426 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2428 = stablehlo.broadcast_in_dim %2427, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2429 = stablehlo.subtract %2426, %2428 : tensor<2x32x2048x2048xf32>
    %2430 = stablehlo.exponential %2429 : tensor<2x32x2048x2048xf32>
    %2431 = stablehlo.reduce(%2430 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2432 = stablehlo.broadcast_in_dim %2431, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2433 = stablehlo.divide %2430, %2432 : tensor<2x32x2048x2048xf32>
    %2434 = stablehlo.reshape %2433 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2435 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2436 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2437 = stablehlo.add %arg199, %2436 : tensor<2048xi64>
    %2438 = stablehlo.select %2435, %2437, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2439 = stablehlo.reshape %2438 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2440 = stablehlo.reshape %2373 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2441 = stablehlo.transpose %arg80, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2442 = stablehlo.dot %2440, %2441, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2443 = stablehlo.reshape %2442 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2444 = "stablehlo.scatter"(%arg299, %2439, %2443) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2445 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2446 = "stablehlo.gather"(%2444, %2445) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2447 = stablehlo.transpose %2446, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2448 = stablehlo.reshape %2447 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2449 = stablehlo.dot_general %2434, %2448, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2450 = stablehlo.reshape %2449 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2451 = stablehlo.transpose %2450, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2452 = stablehlo.reshape %2451 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2453 = stablehlo.transpose %arg79, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2454 = stablehlo.dot %2452, %2453, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2455 = stablehlo.reshape %2454 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2456 = stablehlo.add %2361, %2455 : tensor<2x2048x4096xf32>
    %2457 = stablehlo.power %2456, %1 : tensor<2x2048x4096xf32>
    %2458 = stablehlo.reduce(%2457 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2459 = stablehlo.multiply %2458, %0 : tensor<2x2048xf32>
    %2460 = stablehlo.reshape %2459 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2461 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2462 = stablehlo.add %2460, %2461 : tensor<2x2048x1xf32>
    %2463 = stablehlo.rsqrt %2462 : tensor<2x2048x1xf32>
    %2464 = stablehlo.reshape %2463 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2465 = stablehlo.broadcast_in_dim %2464, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2466 = stablehlo.multiply %2456, %2465 : tensor<2x2048x4096xf32>
    %2467 = stablehlo.broadcast_in_dim %arg78, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2468 = stablehlo.multiply %2466, %2467 : tensor<2x2048x4096xf32>
    %2469 = stablehlo.reshape %2468 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2470 = stablehlo.transpose %arg303, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2471 = stablehlo.dot %2469, %2470, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2472 = stablehlo.reshape %2471 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2473 = stablehlo.logistic %2472 : tensor<2x2048x11008xf32>
    %2474 = stablehlo.multiply %2472, %2473 : tensor<2x2048x11008xf32>
    %2475 = stablehlo.reshape %2468 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2476 = stablehlo.transpose %arg77, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2477 = stablehlo.dot %2475, %2476, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2478 = stablehlo.reshape %2477 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2479 = stablehlo.multiply %2474, %2478 : tensor<2x2048x11008xf32>
    %2480 = stablehlo.reshape %2479 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2481 = stablehlo.transpose %arg76, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2482 = stablehlo.dot %2480, %2481, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2483 = stablehlo.reshape %2482 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2484 = stablehlo.add %2456, %2483 : tensor<2x2048x4096xf32>
    %2485 = stablehlo.power %2484, %1 : tensor<2x2048x4096xf32>
    %2486 = stablehlo.reduce(%2485 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2487 = stablehlo.multiply %2486, %0 : tensor<2x2048xf32>
    %2488 = stablehlo.reshape %2487 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2489 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2490 = stablehlo.add %2488, %2489 : tensor<2x2048x1xf32>
    %2491 = stablehlo.rsqrt %2490 : tensor<2x2048x1xf32>
    %2492 = stablehlo.reshape %2491 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2493 = stablehlo.broadcast_in_dim %2492, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2494 = stablehlo.multiply %2484, %2493 : tensor<2x2048x4096xf32>
    %2495 = stablehlo.broadcast_in_dim %arg75, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2496 = stablehlo.multiply %2494, %2495 : tensor<2x2048x4096xf32>
    %2497 = stablehlo.reshape %2496 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2498 = stablehlo.transpose %arg307, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2499 = stablehlo.dot %2497, %2498, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2500 = stablehlo.reshape %2499 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2501 = stablehlo.slice %2500 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2502 = stablehlo.reshape %2501 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2503 = stablehlo.slice %2500 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2504 = stablehlo.reshape %2503 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2505 = stablehlo.complex %2502, %2504 : tensor<2x2048x32x64xcomplex<f32>>
    %2506 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2507 = stablehlo.multiply %2505, %2506 : tensor<2x2048x32x64xcomplex<f32>>
    %2508 = stablehlo.real %2507 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2509 = stablehlo.reshape %2508 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2510 = stablehlo.imag %2507 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2511 = stablehlo.reshape %2510 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2512 = stablehlo.concatenate %2509, %2511, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2513 = stablehlo.reshape %2512 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2514 = stablehlo.transpose %2513, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2515 = stablehlo.reshape %2514 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2516 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2517 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2518 = stablehlo.add %arg199, %2517 : tensor<2048xi64>
    %2519 = stablehlo.select %2516, %2518, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2520 = stablehlo.reshape %2519 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2521 = stablehlo.reshape %2496 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2522 = stablehlo.transpose %arg305, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2523 = stablehlo.dot %2521, %2522, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2524 = stablehlo.reshape %2523 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2525 = stablehlo.slice %2524 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2526 = stablehlo.reshape %2525 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2527 = stablehlo.slice %2524 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2528 = stablehlo.reshape %2527 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2529 = stablehlo.complex %2526, %2528 : tensor<2x2048x32x64xcomplex<f32>>
    %2530 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2531 = stablehlo.multiply %2529, %2530 : tensor<2x2048x32x64xcomplex<f32>>
    %2532 = stablehlo.real %2531 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2533 = stablehlo.reshape %2532 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2534 = stablehlo.imag %2531 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2535 = stablehlo.reshape %2534 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2536 = stablehlo.concatenate %2533, %2535, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2537 = stablehlo.reshape %2536 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2538 = "stablehlo.scatter"(%arg306, %2520, %2537) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2539 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2540 = "stablehlo.gather"(%2538, %2539) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2541 = stablehlo.transpose %2540, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2542 = stablehlo.reshape %2541 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2543 = stablehlo.dot_general %2515, %2542, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2544 = stablehlo.reshape %2543 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2545 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2546 = stablehlo.divide %2544, %2545 : tensor<2x32x2048x2048xf32>
    %2547 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2548 = stablehlo.broadcast_in_dim %2547, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2549 = stablehlo.add %2546, %2548 : tensor<2x32x2048x2048xf32>
    %2550 = stablehlo.reduce(%2549 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2551 = stablehlo.broadcast_in_dim %2550, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2552 = stablehlo.subtract %2549, %2551 : tensor<2x32x2048x2048xf32>
    %2553 = stablehlo.exponential %2552 : tensor<2x32x2048x2048xf32>
    %2554 = stablehlo.reduce(%2553 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2555 = stablehlo.broadcast_in_dim %2554, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2556 = stablehlo.divide %2553, %2555 : tensor<2x32x2048x2048xf32>
    %2557 = stablehlo.reshape %2556 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2558 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2559 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2560 = stablehlo.add %arg199, %2559 : tensor<2048xi64>
    %2561 = stablehlo.select %2558, %2560, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2562 = stablehlo.reshape %2561 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2563 = stablehlo.reshape %2496 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2564 = stablehlo.transpose %arg74, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2565 = stablehlo.dot %2563, %2564, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2566 = stablehlo.reshape %2565 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2567 = "stablehlo.scatter"(%arg304, %2562, %2566) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2568 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2569 = "stablehlo.gather"(%2567, %2568) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2570 = stablehlo.transpose %2569, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2571 = stablehlo.reshape %2570 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2572 = stablehlo.dot_general %2557, %2571, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2573 = stablehlo.reshape %2572 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2574 = stablehlo.transpose %2573, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2575 = stablehlo.reshape %2574 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2576 = stablehlo.transpose %arg73, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2577 = stablehlo.dot %2575, %2576, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2578 = stablehlo.reshape %2577 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2579 = stablehlo.add %2484, %2578 : tensor<2x2048x4096xf32>
    %2580 = stablehlo.power %2579, %1 : tensor<2x2048x4096xf32>
    %2581 = stablehlo.reduce(%2580 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2582 = stablehlo.multiply %2581, %0 : tensor<2x2048xf32>
    %2583 = stablehlo.reshape %2582 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2584 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2585 = stablehlo.add %2583, %2584 : tensor<2x2048x1xf32>
    %2586 = stablehlo.rsqrt %2585 : tensor<2x2048x1xf32>
    %2587 = stablehlo.reshape %2586 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2588 = stablehlo.broadcast_in_dim %2587, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2589 = stablehlo.multiply %2579, %2588 : tensor<2x2048x4096xf32>
    %2590 = stablehlo.broadcast_in_dim %arg72, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2591 = stablehlo.multiply %2589, %2590 : tensor<2x2048x4096xf32>
    %2592 = stablehlo.reshape %2591 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2593 = stablehlo.transpose %arg308, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2594 = stablehlo.dot %2592, %2593, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2595 = stablehlo.reshape %2594 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2596 = stablehlo.logistic %2595 : tensor<2x2048x11008xf32>
    %2597 = stablehlo.multiply %2595, %2596 : tensor<2x2048x11008xf32>
    %2598 = stablehlo.reshape %2591 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2599 = stablehlo.transpose %arg71, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2600 = stablehlo.dot %2598, %2599, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2601 = stablehlo.reshape %2600 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2602 = stablehlo.multiply %2597, %2601 : tensor<2x2048x11008xf32>
    %2603 = stablehlo.reshape %2602 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2604 = stablehlo.transpose %arg70, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2605 = stablehlo.dot %2603, %2604, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2606 = stablehlo.reshape %2605 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2607 = stablehlo.add %2579, %2606 : tensor<2x2048x4096xf32>
    %2608 = stablehlo.power %2607, %1 : tensor<2x2048x4096xf32>
    %2609 = stablehlo.reduce(%2608 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2610 = stablehlo.multiply %2609, %0 : tensor<2x2048xf32>
    %2611 = stablehlo.reshape %2610 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2612 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2613 = stablehlo.add %2611, %2612 : tensor<2x2048x1xf32>
    %2614 = stablehlo.rsqrt %2613 : tensor<2x2048x1xf32>
    %2615 = stablehlo.reshape %2614 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2616 = stablehlo.broadcast_in_dim %2615, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2617 = stablehlo.multiply %2607, %2616 : tensor<2x2048x4096xf32>
    %2618 = stablehlo.broadcast_in_dim %arg69, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2619 = stablehlo.multiply %2617, %2618 : tensor<2x2048x4096xf32>
    %2620 = stablehlo.reshape %2619 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2621 = stablehlo.transpose %arg312, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2622 = stablehlo.dot %2620, %2621, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2623 = stablehlo.reshape %2622 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2624 = stablehlo.slice %2623 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2625 = stablehlo.reshape %2624 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2626 = stablehlo.slice %2623 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2627 = stablehlo.reshape %2626 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2628 = stablehlo.complex %2625, %2627 : tensor<2x2048x32x64xcomplex<f32>>
    %2629 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2630 = stablehlo.multiply %2628, %2629 : tensor<2x2048x32x64xcomplex<f32>>
    %2631 = stablehlo.real %2630 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2632 = stablehlo.reshape %2631 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2633 = stablehlo.imag %2630 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2634 = stablehlo.reshape %2633 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2635 = stablehlo.concatenate %2632, %2634, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2636 = stablehlo.reshape %2635 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2637 = stablehlo.transpose %2636, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2638 = stablehlo.reshape %2637 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2639 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2640 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2641 = stablehlo.add %arg199, %2640 : tensor<2048xi64>
    %2642 = stablehlo.select %2639, %2641, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2643 = stablehlo.reshape %2642 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2644 = stablehlo.reshape %2619 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2645 = stablehlo.transpose %arg310, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2646 = stablehlo.dot %2644, %2645, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2647 = stablehlo.reshape %2646 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2648 = stablehlo.slice %2647 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2649 = stablehlo.reshape %2648 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2650 = stablehlo.slice %2647 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2651 = stablehlo.reshape %2650 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2652 = stablehlo.complex %2649, %2651 : tensor<2x2048x32x64xcomplex<f32>>
    %2653 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2654 = stablehlo.multiply %2652, %2653 : tensor<2x2048x32x64xcomplex<f32>>
    %2655 = stablehlo.real %2654 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2656 = stablehlo.reshape %2655 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2657 = stablehlo.imag %2654 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2658 = stablehlo.reshape %2657 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2659 = stablehlo.concatenate %2656, %2658, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2660 = stablehlo.reshape %2659 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2661 = "stablehlo.scatter"(%arg311, %2643, %2660) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2662 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2663 = "stablehlo.gather"(%2661, %2662) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2664 = stablehlo.transpose %2663, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2665 = stablehlo.reshape %2664 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2666 = stablehlo.dot_general %2638, %2665, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2667 = stablehlo.reshape %2666 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2668 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2669 = stablehlo.divide %2667, %2668 : tensor<2x32x2048x2048xf32>
    %2670 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2671 = stablehlo.broadcast_in_dim %2670, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2672 = stablehlo.add %2669, %2671 : tensor<2x32x2048x2048xf32>
    %2673 = stablehlo.reduce(%2672 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2674 = stablehlo.broadcast_in_dim %2673, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2675 = stablehlo.subtract %2672, %2674 : tensor<2x32x2048x2048xf32>
    %2676 = stablehlo.exponential %2675 : tensor<2x32x2048x2048xf32>
    %2677 = stablehlo.reduce(%2676 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2678 = stablehlo.broadcast_in_dim %2677, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2679 = stablehlo.divide %2676, %2678 : tensor<2x32x2048x2048xf32>
    %2680 = stablehlo.reshape %2679 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2681 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2682 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2683 = stablehlo.add %arg199, %2682 : tensor<2048xi64>
    %2684 = stablehlo.select %2681, %2683, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2685 = stablehlo.reshape %2684 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2686 = stablehlo.reshape %2619 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2687 = stablehlo.transpose %arg68, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2688 = stablehlo.dot %2686, %2687, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2689 = stablehlo.reshape %2688 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2690 = "stablehlo.scatter"(%arg309, %2685, %2689) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2691 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2692 = "stablehlo.gather"(%2690, %2691) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2693 = stablehlo.transpose %2692, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2694 = stablehlo.reshape %2693 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2695 = stablehlo.dot_general %2680, %2694, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2696 = stablehlo.reshape %2695 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2697 = stablehlo.transpose %2696, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2698 = stablehlo.reshape %2697 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2699 = stablehlo.transpose %arg67, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2700 = stablehlo.dot %2698, %2699, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2701 = stablehlo.reshape %2700 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2702 = stablehlo.add %2607, %2701 : tensor<2x2048x4096xf32>
    %2703 = stablehlo.power %2702, %1 : tensor<2x2048x4096xf32>
    %2704 = stablehlo.reduce(%2703 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2705 = stablehlo.multiply %2704, %0 : tensor<2x2048xf32>
    %2706 = stablehlo.reshape %2705 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2707 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2708 = stablehlo.add %2706, %2707 : tensor<2x2048x1xf32>
    %2709 = stablehlo.rsqrt %2708 : tensor<2x2048x1xf32>
    %2710 = stablehlo.reshape %2709 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2711 = stablehlo.broadcast_in_dim %2710, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2712 = stablehlo.multiply %2702, %2711 : tensor<2x2048x4096xf32>
    %2713 = stablehlo.broadcast_in_dim %arg66, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2714 = stablehlo.multiply %2712, %2713 : tensor<2x2048x4096xf32>
    %2715 = stablehlo.reshape %2714 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2716 = stablehlo.transpose %arg313, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2717 = stablehlo.dot %2715, %2716, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2718 = stablehlo.reshape %2717 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2719 = stablehlo.logistic %2718 : tensor<2x2048x11008xf32>
    %2720 = stablehlo.multiply %2718, %2719 : tensor<2x2048x11008xf32>
    %2721 = stablehlo.reshape %2714 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2722 = stablehlo.transpose %arg65, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2723 = stablehlo.dot %2721, %2722, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2724 = stablehlo.reshape %2723 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2725 = stablehlo.multiply %2720, %2724 : tensor<2x2048x11008xf32>
    %2726 = stablehlo.reshape %2725 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2727 = stablehlo.transpose %arg64, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2728 = stablehlo.dot %2726, %2727, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2729 = stablehlo.reshape %2728 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2730 = stablehlo.add %2702, %2729 : tensor<2x2048x4096xf32>
    %2731 = stablehlo.power %2730, %1 : tensor<2x2048x4096xf32>
    %2732 = stablehlo.reduce(%2731 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2733 = stablehlo.multiply %2732, %0 : tensor<2x2048xf32>
    %2734 = stablehlo.reshape %2733 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2735 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2736 = stablehlo.add %2734, %2735 : tensor<2x2048x1xf32>
    %2737 = stablehlo.rsqrt %2736 : tensor<2x2048x1xf32>
    %2738 = stablehlo.reshape %2737 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2739 = stablehlo.broadcast_in_dim %2738, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2740 = stablehlo.multiply %2730, %2739 : tensor<2x2048x4096xf32>
    %2741 = stablehlo.broadcast_in_dim %arg63, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2742 = stablehlo.multiply %2740, %2741 : tensor<2x2048x4096xf32>
    %2743 = stablehlo.reshape %2742 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2744 = stablehlo.transpose %arg317, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2745 = stablehlo.dot %2743, %2744, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2746 = stablehlo.reshape %2745 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2747 = stablehlo.slice %2746 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2748 = stablehlo.reshape %2747 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2749 = stablehlo.slice %2746 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2750 = stablehlo.reshape %2749 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2751 = stablehlo.complex %2748, %2750 : tensor<2x2048x32x64xcomplex<f32>>
    %2752 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2753 = stablehlo.multiply %2751, %2752 : tensor<2x2048x32x64xcomplex<f32>>
    %2754 = stablehlo.real %2753 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2755 = stablehlo.reshape %2754 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2756 = stablehlo.imag %2753 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2757 = stablehlo.reshape %2756 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2758 = stablehlo.concatenate %2755, %2757, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2759 = stablehlo.reshape %2758 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2760 = stablehlo.transpose %2759, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2761 = stablehlo.reshape %2760 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2762 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2763 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2764 = stablehlo.add %arg199, %2763 : tensor<2048xi64>
    %2765 = stablehlo.select %2762, %2764, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2766 = stablehlo.reshape %2765 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2767 = stablehlo.reshape %2742 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2768 = stablehlo.transpose %arg315, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2769 = stablehlo.dot %2767, %2768, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2770 = stablehlo.reshape %2769 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2771 = stablehlo.slice %2770 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2772 = stablehlo.reshape %2771 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2773 = stablehlo.slice %2770 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2774 = stablehlo.reshape %2773 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2775 = stablehlo.complex %2772, %2774 : tensor<2x2048x32x64xcomplex<f32>>
    %2776 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2777 = stablehlo.multiply %2775, %2776 : tensor<2x2048x32x64xcomplex<f32>>
    %2778 = stablehlo.real %2777 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2779 = stablehlo.reshape %2778 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2780 = stablehlo.imag %2777 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2781 = stablehlo.reshape %2780 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2782 = stablehlo.concatenate %2779, %2781, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2783 = stablehlo.reshape %2782 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2784 = "stablehlo.scatter"(%arg316, %2766, %2783) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2785 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2786 = "stablehlo.gather"(%2784, %2785) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2787 = stablehlo.transpose %2786, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2788 = stablehlo.reshape %2787 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2789 = stablehlo.dot_general %2761, %2788, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2790 = stablehlo.reshape %2789 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2791 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2792 = stablehlo.divide %2790, %2791 : tensor<2x32x2048x2048xf32>
    %2793 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2794 = stablehlo.broadcast_in_dim %2793, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2795 = stablehlo.add %2792, %2794 : tensor<2x32x2048x2048xf32>
    %2796 = stablehlo.reduce(%2795 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2797 = stablehlo.broadcast_in_dim %2796, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2798 = stablehlo.subtract %2795, %2797 : tensor<2x32x2048x2048xf32>
    %2799 = stablehlo.exponential %2798 : tensor<2x32x2048x2048xf32>
    %2800 = stablehlo.reduce(%2799 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2801 = stablehlo.broadcast_in_dim %2800, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2802 = stablehlo.divide %2799, %2801 : tensor<2x32x2048x2048xf32>
    %2803 = stablehlo.reshape %2802 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2804 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2805 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2806 = stablehlo.add %arg199, %2805 : tensor<2048xi64>
    %2807 = stablehlo.select %2804, %2806, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2808 = stablehlo.reshape %2807 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2809 = stablehlo.reshape %2742 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2810 = stablehlo.transpose %arg62, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2811 = stablehlo.dot %2809, %2810, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2812 = stablehlo.reshape %2811 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2813 = "stablehlo.scatter"(%arg314, %2808, %2812) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2814 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2815 = "stablehlo.gather"(%2813, %2814) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2816 = stablehlo.transpose %2815, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2817 = stablehlo.reshape %2816 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2818 = stablehlo.dot_general %2803, %2817, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2819 = stablehlo.reshape %2818 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2820 = stablehlo.transpose %2819, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2821 = stablehlo.reshape %2820 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2822 = stablehlo.transpose %arg61, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2823 = stablehlo.dot %2821, %2822, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2824 = stablehlo.reshape %2823 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2825 = stablehlo.add %2730, %2824 : tensor<2x2048x4096xf32>
    %2826 = stablehlo.power %2825, %1 : tensor<2x2048x4096xf32>
    %2827 = stablehlo.reduce(%2826 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2828 = stablehlo.multiply %2827, %0 : tensor<2x2048xf32>
    %2829 = stablehlo.reshape %2828 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2830 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2831 = stablehlo.add %2829, %2830 : tensor<2x2048x1xf32>
    %2832 = stablehlo.rsqrt %2831 : tensor<2x2048x1xf32>
    %2833 = stablehlo.reshape %2832 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2834 = stablehlo.broadcast_in_dim %2833, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2835 = stablehlo.multiply %2825, %2834 : tensor<2x2048x4096xf32>
    %2836 = stablehlo.broadcast_in_dim %arg60, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2837 = stablehlo.multiply %2835, %2836 : tensor<2x2048x4096xf32>
    %2838 = stablehlo.reshape %2837 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2839 = stablehlo.transpose %arg318, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2840 = stablehlo.dot %2838, %2839, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2841 = stablehlo.reshape %2840 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2842 = stablehlo.logistic %2841 : tensor<2x2048x11008xf32>
    %2843 = stablehlo.multiply %2841, %2842 : tensor<2x2048x11008xf32>
    %2844 = stablehlo.reshape %2837 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2845 = stablehlo.transpose %arg59, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2846 = stablehlo.dot %2844, %2845, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2847 = stablehlo.reshape %2846 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2848 = stablehlo.multiply %2843, %2847 : tensor<2x2048x11008xf32>
    %2849 = stablehlo.reshape %2848 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2850 = stablehlo.transpose %arg58, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2851 = stablehlo.dot %2849, %2850, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2852 = stablehlo.reshape %2851 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2853 = stablehlo.add %2825, %2852 : tensor<2x2048x4096xf32>
    %2854 = stablehlo.power %2853, %1 : tensor<2x2048x4096xf32>
    %2855 = stablehlo.reduce(%2854 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2856 = stablehlo.multiply %2855, %0 : tensor<2x2048xf32>
    %2857 = stablehlo.reshape %2856 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2858 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2859 = stablehlo.add %2857, %2858 : tensor<2x2048x1xf32>
    %2860 = stablehlo.rsqrt %2859 : tensor<2x2048x1xf32>
    %2861 = stablehlo.reshape %2860 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2862 = stablehlo.broadcast_in_dim %2861, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2863 = stablehlo.multiply %2853, %2862 : tensor<2x2048x4096xf32>
    %2864 = stablehlo.broadcast_in_dim %arg57, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2865 = stablehlo.multiply %2863, %2864 : tensor<2x2048x4096xf32>
    %2866 = stablehlo.reshape %2865 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2867 = stablehlo.transpose %arg322, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2868 = stablehlo.dot %2866, %2867, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2869 = stablehlo.reshape %2868 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2870 = stablehlo.slice %2869 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2871 = stablehlo.reshape %2870 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2872 = stablehlo.slice %2869 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2873 = stablehlo.reshape %2872 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2874 = stablehlo.complex %2871, %2873 : tensor<2x2048x32x64xcomplex<f32>>
    %2875 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2876 = stablehlo.multiply %2874, %2875 : tensor<2x2048x32x64xcomplex<f32>>
    %2877 = stablehlo.real %2876 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2878 = stablehlo.reshape %2877 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2879 = stablehlo.imag %2876 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2880 = stablehlo.reshape %2879 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2881 = stablehlo.concatenate %2878, %2880, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2882 = stablehlo.reshape %2881 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2883 = stablehlo.transpose %2882, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2884 = stablehlo.reshape %2883 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2885 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2886 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2887 = stablehlo.add %arg199, %2886 : tensor<2048xi64>
    %2888 = stablehlo.select %2885, %2887, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2889 = stablehlo.reshape %2888 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2890 = stablehlo.reshape %2865 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2891 = stablehlo.transpose %arg320, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2892 = stablehlo.dot %2890, %2891, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2893 = stablehlo.reshape %2892 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2894 = stablehlo.slice %2893 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2895 = stablehlo.reshape %2894 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2896 = stablehlo.slice %2893 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2897 = stablehlo.reshape %2896 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2898 = stablehlo.complex %2895, %2897 : tensor<2x2048x32x64xcomplex<f32>>
    %2899 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2900 = stablehlo.multiply %2898, %2899 : tensor<2x2048x32x64xcomplex<f32>>
    %2901 = stablehlo.real %2900 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2902 = stablehlo.reshape %2901 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2903 = stablehlo.imag %2900 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %2904 = stablehlo.reshape %2903 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %2905 = stablehlo.concatenate %2902, %2904, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %2906 = stablehlo.reshape %2905 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %2907 = "stablehlo.scatter"(%arg321, %2889, %2906) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2908 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2909 = "stablehlo.gather"(%2907, %2908) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2910 = stablehlo.transpose %2909, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %2911 = stablehlo.reshape %2910 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %2912 = stablehlo.dot_general %2884, %2911, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %2913 = stablehlo.reshape %2912 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2914 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %2915 = stablehlo.divide %2913, %2914 : tensor<2x32x2048x2048xf32>
    %2916 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %2917 = stablehlo.broadcast_in_dim %2916, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2918 = stablehlo.add %2915, %2917 : tensor<2x32x2048x2048xf32>
    %2919 = stablehlo.reduce(%2918 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2920 = stablehlo.broadcast_in_dim %2919, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2921 = stablehlo.subtract %2918, %2920 : tensor<2x32x2048x2048xf32>
    %2922 = stablehlo.exponential %2921 : tensor<2x32x2048x2048xf32>
    %2923 = stablehlo.reduce(%2922 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2924 = stablehlo.broadcast_in_dim %2923, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %2925 = stablehlo.divide %2922, %2924 : tensor<2x32x2048x2048xf32>
    %2926 = stablehlo.reshape %2925 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %2927 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %2928 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %2929 = stablehlo.add %arg199, %2928 : tensor<2048xi64>
    %2930 = stablehlo.select %2927, %2929, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %2931 = stablehlo.reshape %2930 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %2932 = stablehlo.reshape %2865 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2933 = stablehlo.transpose %arg56, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2934 = stablehlo.dot %2932, %2933, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2935 = stablehlo.reshape %2934 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %2936 = "stablehlo.scatter"(%arg319, %2931, %2935) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %2937 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %2938 = "stablehlo.gather"(%2936, %2937) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %2939 = stablehlo.transpose %2938, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %2940 = stablehlo.reshape %2939 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2941 = stablehlo.dot_general %2926, %2940, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %2942 = stablehlo.reshape %2941 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %2943 = stablehlo.transpose %2942, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %2944 = stablehlo.reshape %2943 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %2945 = stablehlo.transpose %arg55, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2946 = stablehlo.dot %2944, %2945, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2947 = stablehlo.reshape %2946 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2948 = stablehlo.add %2853, %2947 : tensor<2x2048x4096xf32>
    %2949 = stablehlo.power %2948, %1 : tensor<2x2048x4096xf32>
    %2950 = stablehlo.reduce(%2949 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2951 = stablehlo.multiply %2950, %0 : tensor<2x2048xf32>
    %2952 = stablehlo.reshape %2951 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2953 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2954 = stablehlo.add %2952, %2953 : tensor<2x2048x1xf32>
    %2955 = stablehlo.rsqrt %2954 : tensor<2x2048x1xf32>
    %2956 = stablehlo.reshape %2955 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2957 = stablehlo.broadcast_in_dim %2956, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2958 = stablehlo.multiply %2948, %2957 : tensor<2x2048x4096xf32>
    %2959 = stablehlo.broadcast_in_dim %arg54, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2960 = stablehlo.multiply %2958, %2959 : tensor<2x2048x4096xf32>
    %2961 = stablehlo.reshape %2960 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2962 = stablehlo.transpose %arg323, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2963 = stablehlo.dot %2961, %2962, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2964 = stablehlo.reshape %2963 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2965 = stablehlo.logistic %2964 : tensor<2x2048x11008xf32>
    %2966 = stablehlo.multiply %2964, %2965 : tensor<2x2048x11008xf32>
    %2967 = stablehlo.reshape %2960 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2968 = stablehlo.transpose %arg53, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %2969 = stablehlo.dot %2967, %2968, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %2970 = stablehlo.reshape %2969 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %2971 = stablehlo.multiply %2966, %2970 : tensor<2x2048x11008xf32>
    %2972 = stablehlo.reshape %2971 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %2973 = stablehlo.transpose %arg52, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %2974 = stablehlo.dot %2972, %2973, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %2975 = stablehlo.reshape %2974 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %2976 = stablehlo.add %2948, %2975 : tensor<2x2048x4096xf32>
    %2977 = stablehlo.power %2976, %1 : tensor<2x2048x4096xf32>
    %2978 = stablehlo.reduce(%2977 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %2979 = stablehlo.multiply %2978, %0 : tensor<2x2048xf32>
    %2980 = stablehlo.reshape %2979 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %2981 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %2982 = stablehlo.add %2980, %2981 : tensor<2x2048x1xf32>
    %2983 = stablehlo.rsqrt %2982 : tensor<2x2048x1xf32>
    %2984 = stablehlo.reshape %2983 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %2985 = stablehlo.broadcast_in_dim %2984, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %2986 = stablehlo.multiply %2976, %2985 : tensor<2x2048x4096xf32>
    %2987 = stablehlo.broadcast_in_dim %arg51, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %2988 = stablehlo.multiply %2986, %2987 : tensor<2x2048x4096xf32>
    %2989 = stablehlo.reshape %2988 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %2990 = stablehlo.transpose %arg327, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2991 = stablehlo.dot %2989, %2990, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %2992 = stablehlo.reshape %2991 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %2993 = stablehlo.slice %2992 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2994 = stablehlo.reshape %2993 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2995 = stablehlo.slice %2992 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %2996 = stablehlo.reshape %2995 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %2997 = stablehlo.complex %2994, %2996 : tensor<2x2048x32x64xcomplex<f32>>
    %2998 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %2999 = stablehlo.multiply %2997, %2998 : tensor<2x2048x32x64xcomplex<f32>>
    %3000 = stablehlo.real %2999 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3001 = stablehlo.reshape %3000 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3002 = stablehlo.imag %2999 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3003 = stablehlo.reshape %3002 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3004 = stablehlo.concatenate %3001, %3003, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3005 = stablehlo.reshape %3004 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3006 = stablehlo.transpose %3005, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3007 = stablehlo.reshape %3006 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3008 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3009 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3010 = stablehlo.add %arg199, %3009 : tensor<2048xi64>
    %3011 = stablehlo.select %3008, %3010, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3012 = stablehlo.reshape %3011 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3013 = stablehlo.reshape %2988 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3014 = stablehlo.transpose %arg325, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3015 = stablehlo.dot %3013, %3014, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3016 = stablehlo.reshape %3015 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3017 = stablehlo.slice %3016 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3018 = stablehlo.reshape %3017 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3019 = stablehlo.slice %3016 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3020 = stablehlo.reshape %3019 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3021 = stablehlo.complex %3018, %3020 : tensor<2x2048x32x64xcomplex<f32>>
    %3022 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3023 = stablehlo.multiply %3021, %3022 : tensor<2x2048x32x64xcomplex<f32>>
    %3024 = stablehlo.real %3023 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3025 = stablehlo.reshape %3024 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3026 = stablehlo.imag %3023 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3027 = stablehlo.reshape %3026 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3028 = stablehlo.concatenate %3025, %3027, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3029 = stablehlo.reshape %3028 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3030 = "stablehlo.scatter"(%arg326, %3012, %3029) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3031 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3032 = "stablehlo.gather"(%3030, %3031) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3033 = stablehlo.transpose %3032, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3034 = stablehlo.reshape %3033 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3035 = stablehlo.dot_general %3007, %3034, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3036 = stablehlo.reshape %3035 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3037 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3038 = stablehlo.divide %3036, %3037 : tensor<2x32x2048x2048xf32>
    %3039 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3040 = stablehlo.broadcast_in_dim %3039, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3041 = stablehlo.add %3038, %3040 : tensor<2x32x2048x2048xf32>
    %3042 = stablehlo.reduce(%3041 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3043 = stablehlo.broadcast_in_dim %3042, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3044 = stablehlo.subtract %3041, %3043 : tensor<2x32x2048x2048xf32>
    %3045 = stablehlo.exponential %3044 : tensor<2x32x2048x2048xf32>
    %3046 = stablehlo.reduce(%3045 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3047 = stablehlo.broadcast_in_dim %3046, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3048 = stablehlo.divide %3045, %3047 : tensor<2x32x2048x2048xf32>
    %3049 = stablehlo.reshape %3048 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3050 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3051 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3052 = stablehlo.add %arg199, %3051 : tensor<2048xi64>
    %3053 = stablehlo.select %3050, %3052, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3054 = stablehlo.reshape %3053 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3055 = stablehlo.reshape %2988 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3056 = stablehlo.transpose %arg50, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3057 = stablehlo.dot %3055, %3056, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3058 = stablehlo.reshape %3057 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3059 = "stablehlo.scatter"(%arg324, %3054, %3058) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3060 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3061 = "stablehlo.gather"(%3059, %3060) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3062 = stablehlo.transpose %3061, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3063 = stablehlo.reshape %3062 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3064 = stablehlo.dot_general %3049, %3063, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3065 = stablehlo.reshape %3064 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3066 = stablehlo.transpose %3065, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3067 = stablehlo.reshape %3066 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3068 = stablehlo.transpose %arg49, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3069 = stablehlo.dot %3067, %3068, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3070 = stablehlo.reshape %3069 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3071 = stablehlo.add %2976, %3070 : tensor<2x2048x4096xf32>
    %3072 = stablehlo.power %3071, %1 : tensor<2x2048x4096xf32>
    %3073 = stablehlo.reduce(%3072 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3074 = stablehlo.multiply %3073, %0 : tensor<2x2048xf32>
    %3075 = stablehlo.reshape %3074 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3076 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3077 = stablehlo.add %3075, %3076 : tensor<2x2048x1xf32>
    %3078 = stablehlo.rsqrt %3077 : tensor<2x2048x1xf32>
    %3079 = stablehlo.reshape %3078 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3080 = stablehlo.broadcast_in_dim %3079, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3081 = stablehlo.multiply %3071, %3080 : tensor<2x2048x4096xf32>
    %3082 = stablehlo.broadcast_in_dim %arg48, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3083 = stablehlo.multiply %3081, %3082 : tensor<2x2048x4096xf32>
    %3084 = stablehlo.reshape %3083 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3085 = stablehlo.transpose %arg328, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3086 = stablehlo.dot %3084, %3085, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3087 = stablehlo.reshape %3086 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3088 = stablehlo.logistic %3087 : tensor<2x2048x11008xf32>
    %3089 = stablehlo.multiply %3087, %3088 : tensor<2x2048x11008xf32>
    %3090 = stablehlo.reshape %3083 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3091 = stablehlo.transpose %arg47, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3092 = stablehlo.dot %3090, %3091, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3093 = stablehlo.reshape %3092 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3094 = stablehlo.multiply %3089, %3093 : tensor<2x2048x11008xf32>
    %3095 = stablehlo.reshape %3094 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3096 = stablehlo.transpose %arg46, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3097 = stablehlo.dot %3095, %3096, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3098 = stablehlo.reshape %3097 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3099 = stablehlo.add %3071, %3098 : tensor<2x2048x4096xf32>
    %3100 = stablehlo.power %3099, %1 : tensor<2x2048x4096xf32>
    %3101 = stablehlo.reduce(%3100 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3102 = stablehlo.multiply %3101, %0 : tensor<2x2048xf32>
    %3103 = stablehlo.reshape %3102 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3104 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3105 = stablehlo.add %3103, %3104 : tensor<2x2048x1xf32>
    %3106 = stablehlo.rsqrt %3105 : tensor<2x2048x1xf32>
    %3107 = stablehlo.reshape %3106 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3108 = stablehlo.broadcast_in_dim %3107, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3109 = stablehlo.multiply %3099, %3108 : tensor<2x2048x4096xf32>
    %3110 = stablehlo.broadcast_in_dim %arg45, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3111 = stablehlo.multiply %3109, %3110 : tensor<2x2048x4096xf32>
    %3112 = stablehlo.reshape %3111 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3113 = stablehlo.transpose %arg332, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3114 = stablehlo.dot %3112, %3113, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3115 = stablehlo.reshape %3114 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3116 = stablehlo.slice %3115 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3117 = stablehlo.reshape %3116 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3118 = stablehlo.slice %3115 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3119 = stablehlo.reshape %3118 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3120 = stablehlo.complex %3117, %3119 : tensor<2x2048x32x64xcomplex<f32>>
    %3121 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3122 = stablehlo.multiply %3120, %3121 : tensor<2x2048x32x64xcomplex<f32>>
    %3123 = stablehlo.real %3122 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3124 = stablehlo.reshape %3123 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3125 = stablehlo.imag %3122 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3126 = stablehlo.reshape %3125 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3127 = stablehlo.concatenate %3124, %3126, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3128 = stablehlo.reshape %3127 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3129 = stablehlo.transpose %3128, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3130 = stablehlo.reshape %3129 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3131 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3132 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3133 = stablehlo.add %arg199, %3132 : tensor<2048xi64>
    %3134 = stablehlo.select %3131, %3133, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3135 = stablehlo.reshape %3134 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3136 = stablehlo.reshape %3111 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3137 = stablehlo.transpose %arg330, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3138 = stablehlo.dot %3136, %3137, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3139 = stablehlo.reshape %3138 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3140 = stablehlo.slice %3139 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3141 = stablehlo.reshape %3140 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3142 = stablehlo.slice %3139 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3143 = stablehlo.reshape %3142 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3144 = stablehlo.complex %3141, %3143 : tensor<2x2048x32x64xcomplex<f32>>
    %3145 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3146 = stablehlo.multiply %3144, %3145 : tensor<2x2048x32x64xcomplex<f32>>
    %3147 = stablehlo.real %3146 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3148 = stablehlo.reshape %3147 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3149 = stablehlo.imag %3146 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3150 = stablehlo.reshape %3149 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3151 = stablehlo.concatenate %3148, %3150, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3152 = stablehlo.reshape %3151 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3153 = "stablehlo.scatter"(%arg331, %3135, %3152) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3154 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3155 = "stablehlo.gather"(%3153, %3154) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3156 = stablehlo.transpose %3155, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3157 = stablehlo.reshape %3156 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3158 = stablehlo.dot_general %3130, %3157, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3159 = stablehlo.reshape %3158 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3160 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3161 = stablehlo.divide %3159, %3160 : tensor<2x32x2048x2048xf32>
    %3162 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3163 = stablehlo.broadcast_in_dim %3162, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3164 = stablehlo.add %3161, %3163 : tensor<2x32x2048x2048xf32>
    %3165 = stablehlo.reduce(%3164 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3166 = stablehlo.broadcast_in_dim %3165, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3167 = stablehlo.subtract %3164, %3166 : tensor<2x32x2048x2048xf32>
    %3168 = stablehlo.exponential %3167 : tensor<2x32x2048x2048xf32>
    %3169 = stablehlo.reduce(%3168 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3170 = stablehlo.broadcast_in_dim %3169, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3171 = stablehlo.divide %3168, %3170 : tensor<2x32x2048x2048xf32>
    %3172 = stablehlo.reshape %3171 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3173 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3174 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3175 = stablehlo.add %arg199, %3174 : tensor<2048xi64>
    %3176 = stablehlo.select %3173, %3175, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3177 = stablehlo.reshape %3176 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3178 = stablehlo.reshape %3111 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3179 = stablehlo.transpose %arg44, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3180 = stablehlo.dot %3178, %3179, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3181 = stablehlo.reshape %3180 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3182 = "stablehlo.scatter"(%arg329, %3177, %3181) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3183 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3184 = "stablehlo.gather"(%3182, %3183) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3185 = stablehlo.transpose %3184, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3186 = stablehlo.reshape %3185 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3187 = stablehlo.dot_general %3172, %3186, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3188 = stablehlo.reshape %3187 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3189 = stablehlo.transpose %3188, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3190 = stablehlo.reshape %3189 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3191 = stablehlo.transpose %arg43, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3192 = stablehlo.dot %3190, %3191, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3193 = stablehlo.reshape %3192 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3194 = stablehlo.add %3099, %3193 : tensor<2x2048x4096xf32>
    %3195 = stablehlo.power %3194, %1 : tensor<2x2048x4096xf32>
    %3196 = stablehlo.reduce(%3195 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3197 = stablehlo.multiply %3196, %0 : tensor<2x2048xf32>
    %3198 = stablehlo.reshape %3197 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3199 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3200 = stablehlo.add %3198, %3199 : tensor<2x2048x1xf32>
    %3201 = stablehlo.rsqrt %3200 : tensor<2x2048x1xf32>
    %3202 = stablehlo.reshape %3201 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3203 = stablehlo.broadcast_in_dim %3202, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3204 = stablehlo.multiply %3194, %3203 : tensor<2x2048x4096xf32>
    %3205 = stablehlo.broadcast_in_dim %arg42, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3206 = stablehlo.multiply %3204, %3205 : tensor<2x2048x4096xf32>
    %3207 = stablehlo.reshape %3206 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3208 = stablehlo.transpose %arg333, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3209 = stablehlo.dot %3207, %3208, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3210 = stablehlo.reshape %3209 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3211 = stablehlo.logistic %3210 : tensor<2x2048x11008xf32>
    %3212 = stablehlo.multiply %3210, %3211 : tensor<2x2048x11008xf32>
    %3213 = stablehlo.reshape %3206 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3214 = stablehlo.transpose %arg41, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3215 = stablehlo.dot %3213, %3214, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3216 = stablehlo.reshape %3215 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3217 = stablehlo.multiply %3212, %3216 : tensor<2x2048x11008xf32>
    %3218 = stablehlo.reshape %3217 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3219 = stablehlo.transpose %arg40, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3220 = stablehlo.dot %3218, %3219, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3221 = stablehlo.reshape %3220 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3222 = stablehlo.add %3194, %3221 : tensor<2x2048x4096xf32>
    %3223 = stablehlo.power %3222, %1 : tensor<2x2048x4096xf32>
    %3224 = stablehlo.reduce(%3223 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3225 = stablehlo.multiply %3224, %0 : tensor<2x2048xf32>
    %3226 = stablehlo.reshape %3225 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3227 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3228 = stablehlo.add %3226, %3227 : tensor<2x2048x1xf32>
    %3229 = stablehlo.rsqrt %3228 : tensor<2x2048x1xf32>
    %3230 = stablehlo.reshape %3229 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3231 = stablehlo.broadcast_in_dim %3230, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3232 = stablehlo.multiply %3222, %3231 : tensor<2x2048x4096xf32>
    %3233 = stablehlo.broadcast_in_dim %arg39, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3234 = stablehlo.multiply %3232, %3233 : tensor<2x2048x4096xf32>
    %3235 = stablehlo.reshape %3234 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3236 = stablehlo.transpose %arg337, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3237 = stablehlo.dot %3235, %3236, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3238 = stablehlo.reshape %3237 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3239 = stablehlo.slice %3238 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3240 = stablehlo.reshape %3239 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3241 = stablehlo.slice %3238 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3242 = stablehlo.reshape %3241 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3243 = stablehlo.complex %3240, %3242 : tensor<2x2048x32x64xcomplex<f32>>
    %3244 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3245 = stablehlo.multiply %3243, %3244 : tensor<2x2048x32x64xcomplex<f32>>
    %3246 = stablehlo.real %3245 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3247 = stablehlo.reshape %3246 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3248 = stablehlo.imag %3245 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3249 = stablehlo.reshape %3248 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3250 = stablehlo.concatenate %3247, %3249, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3251 = stablehlo.reshape %3250 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3252 = stablehlo.transpose %3251, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3253 = stablehlo.reshape %3252 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3254 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3255 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3256 = stablehlo.add %arg199, %3255 : tensor<2048xi64>
    %3257 = stablehlo.select %3254, %3256, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3258 = stablehlo.reshape %3257 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3259 = stablehlo.reshape %3234 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3260 = stablehlo.transpose %arg335, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3261 = stablehlo.dot %3259, %3260, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3262 = stablehlo.reshape %3261 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3263 = stablehlo.slice %3262 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3264 = stablehlo.reshape %3263 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3265 = stablehlo.slice %3262 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3266 = stablehlo.reshape %3265 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3267 = stablehlo.complex %3264, %3266 : tensor<2x2048x32x64xcomplex<f32>>
    %3268 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3269 = stablehlo.multiply %3267, %3268 : tensor<2x2048x32x64xcomplex<f32>>
    %3270 = stablehlo.real %3269 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3271 = stablehlo.reshape %3270 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3272 = stablehlo.imag %3269 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3273 = stablehlo.reshape %3272 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3274 = stablehlo.concatenate %3271, %3273, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3275 = stablehlo.reshape %3274 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3276 = "stablehlo.scatter"(%arg336, %3258, %3275) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3277 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3278 = "stablehlo.gather"(%3276, %3277) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3279 = stablehlo.transpose %3278, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3280 = stablehlo.reshape %3279 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3281 = stablehlo.dot_general %3253, %3280, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3282 = stablehlo.reshape %3281 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3283 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3284 = stablehlo.divide %3282, %3283 : tensor<2x32x2048x2048xf32>
    %3285 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3286 = stablehlo.broadcast_in_dim %3285, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3287 = stablehlo.add %3284, %3286 : tensor<2x32x2048x2048xf32>
    %3288 = stablehlo.reduce(%3287 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3289 = stablehlo.broadcast_in_dim %3288, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3290 = stablehlo.subtract %3287, %3289 : tensor<2x32x2048x2048xf32>
    %3291 = stablehlo.exponential %3290 : tensor<2x32x2048x2048xf32>
    %3292 = stablehlo.reduce(%3291 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3293 = stablehlo.broadcast_in_dim %3292, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3294 = stablehlo.divide %3291, %3293 : tensor<2x32x2048x2048xf32>
    %3295 = stablehlo.reshape %3294 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3296 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3297 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3298 = stablehlo.add %arg199, %3297 : tensor<2048xi64>
    %3299 = stablehlo.select %3296, %3298, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3300 = stablehlo.reshape %3299 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3301 = stablehlo.reshape %3234 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3302 = stablehlo.transpose %arg38, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3303 = stablehlo.dot %3301, %3302, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3304 = stablehlo.reshape %3303 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3305 = "stablehlo.scatter"(%arg334, %3300, %3304) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3306 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3307 = "stablehlo.gather"(%3305, %3306) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3308 = stablehlo.transpose %3307, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3309 = stablehlo.reshape %3308 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3310 = stablehlo.dot_general %3295, %3309, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3311 = stablehlo.reshape %3310 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3312 = stablehlo.transpose %3311, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3313 = stablehlo.reshape %3312 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3314 = stablehlo.transpose %arg37, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3315 = stablehlo.dot %3313, %3314, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3316 = stablehlo.reshape %3315 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3317 = stablehlo.add %3222, %3316 : tensor<2x2048x4096xf32>
    %3318 = stablehlo.power %3317, %1 : tensor<2x2048x4096xf32>
    %3319 = stablehlo.reduce(%3318 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3320 = stablehlo.multiply %3319, %0 : tensor<2x2048xf32>
    %3321 = stablehlo.reshape %3320 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3322 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3323 = stablehlo.add %3321, %3322 : tensor<2x2048x1xf32>
    %3324 = stablehlo.rsqrt %3323 : tensor<2x2048x1xf32>
    %3325 = stablehlo.reshape %3324 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3326 = stablehlo.broadcast_in_dim %3325, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3327 = stablehlo.multiply %3317, %3326 : tensor<2x2048x4096xf32>
    %3328 = stablehlo.broadcast_in_dim %arg36, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3329 = stablehlo.multiply %3327, %3328 : tensor<2x2048x4096xf32>
    %3330 = stablehlo.reshape %3329 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3331 = stablehlo.transpose %arg338, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3332 = stablehlo.dot %3330, %3331, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3333 = stablehlo.reshape %3332 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3334 = stablehlo.logistic %3333 : tensor<2x2048x11008xf32>
    %3335 = stablehlo.multiply %3333, %3334 : tensor<2x2048x11008xf32>
    %3336 = stablehlo.reshape %3329 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3337 = stablehlo.transpose %arg35, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3338 = stablehlo.dot %3336, %3337, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3339 = stablehlo.reshape %3338 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3340 = stablehlo.multiply %3335, %3339 : tensor<2x2048x11008xf32>
    %3341 = stablehlo.reshape %3340 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3342 = stablehlo.transpose %arg34, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3343 = stablehlo.dot %3341, %3342, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3344 = stablehlo.reshape %3343 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3345 = stablehlo.add %3317, %3344 : tensor<2x2048x4096xf32>
    %3346 = stablehlo.power %3345, %1 : tensor<2x2048x4096xf32>
    %3347 = stablehlo.reduce(%3346 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3348 = stablehlo.multiply %3347, %0 : tensor<2x2048xf32>
    %3349 = stablehlo.reshape %3348 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3350 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3351 = stablehlo.add %3349, %3350 : tensor<2x2048x1xf32>
    %3352 = stablehlo.rsqrt %3351 : tensor<2x2048x1xf32>
    %3353 = stablehlo.reshape %3352 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3354 = stablehlo.broadcast_in_dim %3353, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3355 = stablehlo.multiply %3345, %3354 : tensor<2x2048x4096xf32>
    %3356 = stablehlo.broadcast_in_dim %arg33, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3357 = stablehlo.multiply %3355, %3356 : tensor<2x2048x4096xf32>
    %3358 = stablehlo.reshape %3357 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3359 = stablehlo.transpose %arg342, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3360 = stablehlo.dot %3358, %3359, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3361 = stablehlo.reshape %3360 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3362 = stablehlo.slice %3361 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3363 = stablehlo.reshape %3362 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3364 = stablehlo.slice %3361 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3365 = stablehlo.reshape %3364 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3366 = stablehlo.complex %3363, %3365 : tensor<2x2048x32x64xcomplex<f32>>
    %3367 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3368 = stablehlo.multiply %3366, %3367 : tensor<2x2048x32x64xcomplex<f32>>
    %3369 = stablehlo.real %3368 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3370 = stablehlo.reshape %3369 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3371 = stablehlo.imag %3368 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3372 = stablehlo.reshape %3371 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3373 = stablehlo.concatenate %3370, %3372, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3374 = stablehlo.reshape %3373 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3375 = stablehlo.transpose %3374, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3376 = stablehlo.reshape %3375 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3377 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3378 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3379 = stablehlo.add %arg199, %3378 : tensor<2048xi64>
    %3380 = stablehlo.select %3377, %3379, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3381 = stablehlo.reshape %3380 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3382 = stablehlo.reshape %3357 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3383 = stablehlo.transpose %arg340, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3384 = stablehlo.dot %3382, %3383, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3385 = stablehlo.reshape %3384 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3386 = stablehlo.slice %3385 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3387 = stablehlo.reshape %3386 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3388 = stablehlo.slice %3385 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3389 = stablehlo.reshape %3388 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3390 = stablehlo.complex %3387, %3389 : tensor<2x2048x32x64xcomplex<f32>>
    %3391 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3392 = stablehlo.multiply %3390, %3391 : tensor<2x2048x32x64xcomplex<f32>>
    %3393 = stablehlo.real %3392 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3394 = stablehlo.reshape %3393 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3395 = stablehlo.imag %3392 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3396 = stablehlo.reshape %3395 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3397 = stablehlo.concatenate %3394, %3396, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3398 = stablehlo.reshape %3397 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3399 = "stablehlo.scatter"(%arg341, %3381, %3398) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3400 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3401 = "stablehlo.gather"(%3399, %3400) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3402 = stablehlo.transpose %3401, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3403 = stablehlo.reshape %3402 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3404 = stablehlo.dot_general %3376, %3403, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3405 = stablehlo.reshape %3404 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3406 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3407 = stablehlo.divide %3405, %3406 : tensor<2x32x2048x2048xf32>
    %3408 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3409 = stablehlo.broadcast_in_dim %3408, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3410 = stablehlo.add %3407, %3409 : tensor<2x32x2048x2048xf32>
    %3411 = stablehlo.reduce(%3410 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3412 = stablehlo.broadcast_in_dim %3411, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3413 = stablehlo.subtract %3410, %3412 : tensor<2x32x2048x2048xf32>
    %3414 = stablehlo.exponential %3413 : tensor<2x32x2048x2048xf32>
    %3415 = stablehlo.reduce(%3414 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3416 = stablehlo.broadcast_in_dim %3415, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3417 = stablehlo.divide %3414, %3416 : tensor<2x32x2048x2048xf32>
    %3418 = stablehlo.reshape %3417 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3419 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3420 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3421 = stablehlo.add %arg199, %3420 : tensor<2048xi64>
    %3422 = stablehlo.select %3419, %3421, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3423 = stablehlo.reshape %3422 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3424 = stablehlo.reshape %3357 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3425 = stablehlo.transpose %arg32, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3426 = stablehlo.dot %3424, %3425, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3427 = stablehlo.reshape %3426 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3428 = "stablehlo.scatter"(%arg339, %3423, %3427) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3429 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3430 = "stablehlo.gather"(%3428, %3429) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3431 = stablehlo.transpose %3430, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3432 = stablehlo.reshape %3431 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3433 = stablehlo.dot_general %3418, %3432, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3434 = stablehlo.reshape %3433 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3435 = stablehlo.transpose %3434, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3436 = stablehlo.reshape %3435 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3437 = stablehlo.transpose %arg31, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3438 = stablehlo.dot %3436, %3437, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3439 = stablehlo.reshape %3438 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3440 = stablehlo.add %3345, %3439 : tensor<2x2048x4096xf32>
    %3441 = stablehlo.power %3440, %1 : tensor<2x2048x4096xf32>
    %3442 = stablehlo.reduce(%3441 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3443 = stablehlo.multiply %3442, %0 : tensor<2x2048xf32>
    %3444 = stablehlo.reshape %3443 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3445 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3446 = stablehlo.add %3444, %3445 : tensor<2x2048x1xf32>
    %3447 = stablehlo.rsqrt %3446 : tensor<2x2048x1xf32>
    %3448 = stablehlo.reshape %3447 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3449 = stablehlo.broadcast_in_dim %3448, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3450 = stablehlo.multiply %3440, %3449 : tensor<2x2048x4096xf32>
    %3451 = stablehlo.broadcast_in_dim %arg30, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3452 = stablehlo.multiply %3450, %3451 : tensor<2x2048x4096xf32>
    %3453 = stablehlo.reshape %3452 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3454 = stablehlo.transpose %arg343, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3455 = stablehlo.dot %3453, %3454, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3456 = stablehlo.reshape %3455 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3457 = stablehlo.logistic %3456 : tensor<2x2048x11008xf32>
    %3458 = stablehlo.multiply %3456, %3457 : tensor<2x2048x11008xf32>
    %3459 = stablehlo.reshape %3452 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3460 = stablehlo.transpose %arg29, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3461 = stablehlo.dot %3459, %3460, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3462 = stablehlo.reshape %3461 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3463 = stablehlo.multiply %3458, %3462 : tensor<2x2048x11008xf32>
    %3464 = stablehlo.reshape %3463 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3465 = stablehlo.transpose %arg28, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3466 = stablehlo.dot %3464, %3465, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3467 = stablehlo.reshape %3466 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3468 = stablehlo.add %3440, %3467 : tensor<2x2048x4096xf32>
    %3469 = stablehlo.power %3468, %1 : tensor<2x2048x4096xf32>
    %3470 = stablehlo.reduce(%3469 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3471 = stablehlo.multiply %3470, %0 : tensor<2x2048xf32>
    %3472 = stablehlo.reshape %3471 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3473 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3474 = stablehlo.add %3472, %3473 : tensor<2x2048x1xf32>
    %3475 = stablehlo.rsqrt %3474 : tensor<2x2048x1xf32>
    %3476 = stablehlo.reshape %3475 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3477 = stablehlo.broadcast_in_dim %3476, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3478 = stablehlo.multiply %3468, %3477 : tensor<2x2048x4096xf32>
    %3479 = stablehlo.broadcast_in_dim %arg27, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3480 = stablehlo.multiply %3478, %3479 : tensor<2x2048x4096xf32>
    %3481 = stablehlo.reshape %3480 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3482 = stablehlo.transpose %arg347, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3483 = stablehlo.dot %3481, %3482, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3484 = stablehlo.reshape %3483 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3485 = stablehlo.slice %3484 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3486 = stablehlo.reshape %3485 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3487 = stablehlo.slice %3484 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3488 = stablehlo.reshape %3487 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3489 = stablehlo.complex %3486, %3488 : tensor<2x2048x32x64xcomplex<f32>>
    %3490 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3491 = stablehlo.multiply %3489, %3490 : tensor<2x2048x32x64xcomplex<f32>>
    %3492 = stablehlo.real %3491 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3493 = stablehlo.reshape %3492 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3494 = stablehlo.imag %3491 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3495 = stablehlo.reshape %3494 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3496 = stablehlo.concatenate %3493, %3495, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3497 = stablehlo.reshape %3496 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3498 = stablehlo.transpose %3497, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3499 = stablehlo.reshape %3498 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3500 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3501 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3502 = stablehlo.add %arg199, %3501 : tensor<2048xi64>
    %3503 = stablehlo.select %3500, %3502, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3504 = stablehlo.reshape %3503 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3505 = stablehlo.reshape %3480 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3506 = stablehlo.transpose %arg345, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3507 = stablehlo.dot %3505, %3506, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3508 = stablehlo.reshape %3507 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3509 = stablehlo.slice %3508 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3510 = stablehlo.reshape %3509 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3511 = stablehlo.slice %3508 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3512 = stablehlo.reshape %3511 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3513 = stablehlo.complex %3510, %3512 : tensor<2x2048x32x64xcomplex<f32>>
    %3514 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3515 = stablehlo.multiply %3513, %3514 : tensor<2x2048x32x64xcomplex<f32>>
    %3516 = stablehlo.real %3515 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3517 = stablehlo.reshape %3516 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3518 = stablehlo.imag %3515 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3519 = stablehlo.reshape %3518 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3520 = stablehlo.concatenate %3517, %3519, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3521 = stablehlo.reshape %3520 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3522 = "stablehlo.scatter"(%arg346, %3504, %3521) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3523 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3524 = "stablehlo.gather"(%3522, %3523) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3525 = stablehlo.transpose %3524, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3526 = stablehlo.reshape %3525 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3527 = stablehlo.dot_general %3499, %3526, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3528 = stablehlo.reshape %3527 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3529 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3530 = stablehlo.divide %3528, %3529 : tensor<2x32x2048x2048xf32>
    %3531 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3532 = stablehlo.broadcast_in_dim %3531, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3533 = stablehlo.add %3530, %3532 : tensor<2x32x2048x2048xf32>
    %3534 = stablehlo.reduce(%3533 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3535 = stablehlo.broadcast_in_dim %3534, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3536 = stablehlo.subtract %3533, %3535 : tensor<2x32x2048x2048xf32>
    %3537 = stablehlo.exponential %3536 : tensor<2x32x2048x2048xf32>
    %3538 = stablehlo.reduce(%3537 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3539 = stablehlo.broadcast_in_dim %3538, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3540 = stablehlo.divide %3537, %3539 : tensor<2x32x2048x2048xf32>
    %3541 = stablehlo.reshape %3540 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3542 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3543 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3544 = stablehlo.add %arg199, %3543 : tensor<2048xi64>
    %3545 = stablehlo.select %3542, %3544, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3546 = stablehlo.reshape %3545 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3547 = stablehlo.reshape %3480 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3548 = stablehlo.transpose %arg26, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3549 = stablehlo.dot %3547, %3548, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3550 = stablehlo.reshape %3549 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3551 = "stablehlo.scatter"(%arg344, %3546, %3550) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3552 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3553 = "stablehlo.gather"(%3551, %3552) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3554 = stablehlo.transpose %3553, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3555 = stablehlo.reshape %3554 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3556 = stablehlo.dot_general %3541, %3555, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3557 = stablehlo.reshape %3556 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3558 = stablehlo.transpose %3557, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3559 = stablehlo.reshape %3558 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3560 = stablehlo.transpose %arg25, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3561 = stablehlo.dot %3559, %3560, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3562 = stablehlo.reshape %3561 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3563 = stablehlo.add %3468, %3562 : tensor<2x2048x4096xf32>
    %3564 = stablehlo.power %3563, %1 : tensor<2x2048x4096xf32>
    %3565 = stablehlo.reduce(%3564 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3566 = stablehlo.multiply %3565, %0 : tensor<2x2048xf32>
    %3567 = stablehlo.reshape %3566 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3568 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3569 = stablehlo.add %3567, %3568 : tensor<2x2048x1xf32>
    %3570 = stablehlo.rsqrt %3569 : tensor<2x2048x1xf32>
    %3571 = stablehlo.reshape %3570 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3572 = stablehlo.broadcast_in_dim %3571, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3573 = stablehlo.multiply %3563, %3572 : tensor<2x2048x4096xf32>
    %3574 = stablehlo.broadcast_in_dim %arg24, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3575 = stablehlo.multiply %3573, %3574 : tensor<2x2048x4096xf32>
    %3576 = stablehlo.reshape %3575 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3577 = stablehlo.transpose %arg348, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3578 = stablehlo.dot %3576, %3577, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3579 = stablehlo.reshape %3578 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3580 = stablehlo.logistic %3579 : tensor<2x2048x11008xf32>
    %3581 = stablehlo.multiply %3579, %3580 : tensor<2x2048x11008xf32>
    %3582 = stablehlo.reshape %3575 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3583 = stablehlo.transpose %arg23, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3584 = stablehlo.dot %3582, %3583, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3585 = stablehlo.reshape %3584 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3586 = stablehlo.multiply %3581, %3585 : tensor<2x2048x11008xf32>
    %3587 = stablehlo.reshape %3586 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3588 = stablehlo.transpose %arg22, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3589 = stablehlo.dot %3587, %3588, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3590 = stablehlo.reshape %3589 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3591 = stablehlo.add %3563, %3590 : tensor<2x2048x4096xf32>
    %3592 = stablehlo.power %3591, %1 : tensor<2x2048x4096xf32>
    %3593 = stablehlo.reduce(%3592 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3594 = stablehlo.multiply %3593, %0 : tensor<2x2048xf32>
    %3595 = stablehlo.reshape %3594 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3596 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3597 = stablehlo.add %3595, %3596 : tensor<2x2048x1xf32>
    %3598 = stablehlo.rsqrt %3597 : tensor<2x2048x1xf32>
    %3599 = stablehlo.reshape %3598 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3600 = stablehlo.broadcast_in_dim %3599, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3601 = stablehlo.multiply %3591, %3600 : tensor<2x2048x4096xf32>
    %3602 = stablehlo.broadcast_in_dim %arg21, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3603 = stablehlo.multiply %3601, %3602 : tensor<2x2048x4096xf32>
    %3604 = stablehlo.reshape %3603 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3605 = stablehlo.transpose %arg352, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3606 = stablehlo.dot %3604, %3605, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3607 = stablehlo.reshape %3606 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3608 = stablehlo.slice %3607 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3609 = stablehlo.reshape %3608 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3610 = stablehlo.slice %3607 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3611 = stablehlo.reshape %3610 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3612 = stablehlo.complex %3609, %3611 : tensor<2x2048x32x64xcomplex<f32>>
    %3613 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3614 = stablehlo.multiply %3612, %3613 : tensor<2x2048x32x64xcomplex<f32>>
    %3615 = stablehlo.real %3614 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3616 = stablehlo.reshape %3615 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3617 = stablehlo.imag %3614 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3618 = stablehlo.reshape %3617 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3619 = stablehlo.concatenate %3616, %3618, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3620 = stablehlo.reshape %3619 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3621 = stablehlo.transpose %3620, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3622 = stablehlo.reshape %3621 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3623 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3624 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3625 = stablehlo.add %arg199, %3624 : tensor<2048xi64>
    %3626 = stablehlo.select %3623, %3625, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3627 = stablehlo.reshape %3626 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3628 = stablehlo.reshape %3603 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3629 = stablehlo.transpose %arg350, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3630 = stablehlo.dot %3628, %3629, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3631 = stablehlo.reshape %3630 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3632 = stablehlo.slice %3631 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3633 = stablehlo.reshape %3632 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3634 = stablehlo.slice %3631 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3635 = stablehlo.reshape %3634 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3636 = stablehlo.complex %3633, %3635 : tensor<2x2048x32x64xcomplex<f32>>
    %3637 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3638 = stablehlo.multiply %3636, %3637 : tensor<2x2048x32x64xcomplex<f32>>
    %3639 = stablehlo.real %3638 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3640 = stablehlo.reshape %3639 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3641 = stablehlo.imag %3638 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3642 = stablehlo.reshape %3641 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3643 = stablehlo.concatenate %3640, %3642, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3644 = stablehlo.reshape %3643 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3645 = "stablehlo.scatter"(%arg351, %3627, %3644) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3646 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3647 = "stablehlo.gather"(%3645, %3646) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3648 = stablehlo.transpose %3647, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3649 = stablehlo.reshape %3648 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3650 = stablehlo.dot_general %3622, %3649, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3651 = stablehlo.reshape %3650 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3652 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3653 = stablehlo.divide %3651, %3652 : tensor<2x32x2048x2048xf32>
    %3654 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3655 = stablehlo.broadcast_in_dim %3654, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3656 = stablehlo.add %3653, %3655 : tensor<2x32x2048x2048xf32>
    %3657 = stablehlo.reduce(%3656 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3658 = stablehlo.broadcast_in_dim %3657, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3659 = stablehlo.subtract %3656, %3658 : tensor<2x32x2048x2048xf32>
    %3660 = stablehlo.exponential %3659 : tensor<2x32x2048x2048xf32>
    %3661 = stablehlo.reduce(%3660 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3662 = stablehlo.broadcast_in_dim %3661, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3663 = stablehlo.divide %3660, %3662 : tensor<2x32x2048x2048xf32>
    %3664 = stablehlo.reshape %3663 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3665 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3666 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3667 = stablehlo.add %arg199, %3666 : tensor<2048xi64>
    %3668 = stablehlo.select %3665, %3667, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3669 = stablehlo.reshape %3668 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3670 = stablehlo.reshape %3603 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3671 = stablehlo.transpose %arg20, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3672 = stablehlo.dot %3670, %3671, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3673 = stablehlo.reshape %3672 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3674 = "stablehlo.scatter"(%arg349, %3669, %3673) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3675 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3676 = "stablehlo.gather"(%3674, %3675) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3677 = stablehlo.transpose %3676, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3678 = stablehlo.reshape %3677 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3679 = stablehlo.dot_general %3664, %3678, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3680 = stablehlo.reshape %3679 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3681 = stablehlo.transpose %3680, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3682 = stablehlo.reshape %3681 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3683 = stablehlo.transpose %arg19, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3684 = stablehlo.dot %3682, %3683, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3685 = stablehlo.reshape %3684 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3686 = stablehlo.add %3591, %3685 : tensor<2x2048x4096xf32>
    %3687 = stablehlo.power %3686, %1 : tensor<2x2048x4096xf32>
    %3688 = stablehlo.reduce(%3687 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3689 = stablehlo.multiply %3688, %0 : tensor<2x2048xf32>
    %3690 = stablehlo.reshape %3689 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3691 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3692 = stablehlo.add %3690, %3691 : tensor<2x2048x1xf32>
    %3693 = stablehlo.rsqrt %3692 : tensor<2x2048x1xf32>
    %3694 = stablehlo.reshape %3693 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3695 = stablehlo.broadcast_in_dim %3694, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3696 = stablehlo.multiply %3686, %3695 : tensor<2x2048x4096xf32>
    %3697 = stablehlo.broadcast_in_dim %arg18, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3698 = stablehlo.multiply %3696, %3697 : tensor<2x2048x4096xf32>
    %3699 = stablehlo.reshape %3698 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3700 = stablehlo.transpose %arg353, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3701 = stablehlo.dot %3699, %3700, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3702 = stablehlo.reshape %3701 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3703 = stablehlo.logistic %3702 : tensor<2x2048x11008xf32>
    %3704 = stablehlo.multiply %3702, %3703 : tensor<2x2048x11008xf32>
    %3705 = stablehlo.reshape %3698 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3706 = stablehlo.transpose %arg17, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3707 = stablehlo.dot %3705, %3706, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3708 = stablehlo.reshape %3707 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3709 = stablehlo.multiply %3704, %3708 : tensor<2x2048x11008xf32>
    %3710 = stablehlo.reshape %3709 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3711 = stablehlo.transpose %arg16, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3712 = stablehlo.dot %3710, %3711, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3713 = stablehlo.reshape %3712 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3714 = stablehlo.add %3686, %3713 : tensor<2x2048x4096xf32>
    %3715 = stablehlo.power %3714, %1 : tensor<2x2048x4096xf32>
    %3716 = stablehlo.reduce(%3715 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3717 = stablehlo.multiply %3716, %0 : tensor<2x2048xf32>
    %3718 = stablehlo.reshape %3717 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3719 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3720 = stablehlo.add %3718, %3719 : tensor<2x2048x1xf32>
    %3721 = stablehlo.rsqrt %3720 : tensor<2x2048x1xf32>
    %3722 = stablehlo.reshape %3721 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3723 = stablehlo.broadcast_in_dim %3722, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3724 = stablehlo.multiply %3714, %3723 : tensor<2x2048x4096xf32>
    %3725 = stablehlo.broadcast_in_dim %arg15, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3726 = stablehlo.multiply %3724, %3725 : tensor<2x2048x4096xf32>
    %3727 = stablehlo.reshape %3726 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3728 = stablehlo.transpose %arg357, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3729 = stablehlo.dot %3727, %3728, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3730 = stablehlo.reshape %3729 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3731 = stablehlo.slice %3730 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3732 = stablehlo.reshape %3731 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3733 = stablehlo.slice %3730 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3734 = stablehlo.reshape %3733 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3735 = stablehlo.complex %3732, %3734 : tensor<2x2048x32x64xcomplex<f32>>
    %3736 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3737 = stablehlo.multiply %3735, %3736 : tensor<2x2048x32x64xcomplex<f32>>
    %3738 = stablehlo.real %3737 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3739 = stablehlo.reshape %3738 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3740 = stablehlo.imag %3737 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3741 = stablehlo.reshape %3740 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3742 = stablehlo.concatenate %3739, %3741, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3743 = stablehlo.reshape %3742 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3744 = stablehlo.transpose %3743, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3745 = stablehlo.reshape %3744 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3746 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3747 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3748 = stablehlo.add %arg199, %3747 : tensor<2048xi64>
    %3749 = stablehlo.select %3746, %3748, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3750 = stablehlo.reshape %3749 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3751 = stablehlo.reshape %3726 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3752 = stablehlo.transpose %arg355, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3753 = stablehlo.dot %3751, %3752, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3754 = stablehlo.reshape %3753 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3755 = stablehlo.slice %3754 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3756 = stablehlo.reshape %3755 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3757 = stablehlo.slice %3754 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3758 = stablehlo.reshape %3757 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3759 = stablehlo.complex %3756, %3758 : tensor<2x2048x32x64xcomplex<f32>>
    %3760 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3761 = stablehlo.multiply %3759, %3760 : tensor<2x2048x32x64xcomplex<f32>>
    %3762 = stablehlo.real %3761 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3763 = stablehlo.reshape %3762 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3764 = stablehlo.imag %3761 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3765 = stablehlo.reshape %3764 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3766 = stablehlo.concatenate %3763, %3765, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3767 = stablehlo.reshape %3766 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3768 = "stablehlo.scatter"(%arg356, %3750, %3767) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3769 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3770 = "stablehlo.gather"(%3768, %3769) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3771 = stablehlo.transpose %3770, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3772 = stablehlo.reshape %3771 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3773 = stablehlo.dot_general %3745, %3772, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3774 = stablehlo.reshape %3773 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3775 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3776 = stablehlo.divide %3774, %3775 : tensor<2x32x2048x2048xf32>
    %3777 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3778 = stablehlo.broadcast_in_dim %3777, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3779 = stablehlo.add %3776, %3778 : tensor<2x32x2048x2048xf32>
    %3780 = stablehlo.reduce(%3779 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3781 = stablehlo.broadcast_in_dim %3780, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3782 = stablehlo.subtract %3779, %3781 : tensor<2x32x2048x2048xf32>
    %3783 = stablehlo.exponential %3782 : tensor<2x32x2048x2048xf32>
    %3784 = stablehlo.reduce(%3783 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3785 = stablehlo.broadcast_in_dim %3784, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3786 = stablehlo.divide %3783, %3785 : tensor<2x32x2048x2048xf32>
    %3787 = stablehlo.reshape %3786 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3788 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3789 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3790 = stablehlo.add %arg199, %3789 : tensor<2048xi64>
    %3791 = stablehlo.select %3788, %3790, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3792 = stablehlo.reshape %3791 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3793 = stablehlo.reshape %3726 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3794 = stablehlo.transpose %arg14, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3795 = stablehlo.dot %3793, %3794, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3796 = stablehlo.reshape %3795 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3797 = "stablehlo.scatter"(%arg354, %3792, %3796) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3798 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3799 = "stablehlo.gather"(%3797, %3798) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3800 = stablehlo.transpose %3799, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3801 = stablehlo.reshape %3800 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3802 = stablehlo.dot_general %3787, %3801, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3803 = stablehlo.reshape %3802 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3804 = stablehlo.transpose %3803, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3805 = stablehlo.reshape %3804 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3806 = stablehlo.transpose %arg13, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3807 = stablehlo.dot %3805, %3806, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3808 = stablehlo.reshape %3807 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3809 = stablehlo.add %3714, %3808 : tensor<2x2048x4096xf32>
    %3810 = stablehlo.power %3809, %1 : tensor<2x2048x4096xf32>
    %3811 = stablehlo.reduce(%3810 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3812 = stablehlo.multiply %3811, %0 : tensor<2x2048xf32>
    %3813 = stablehlo.reshape %3812 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3814 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3815 = stablehlo.add %3813, %3814 : tensor<2x2048x1xf32>
    %3816 = stablehlo.rsqrt %3815 : tensor<2x2048x1xf32>
    %3817 = stablehlo.reshape %3816 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3818 = stablehlo.broadcast_in_dim %3817, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3819 = stablehlo.multiply %3809, %3818 : tensor<2x2048x4096xf32>
    %3820 = stablehlo.broadcast_in_dim %arg12, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3821 = stablehlo.multiply %3819, %3820 : tensor<2x2048x4096xf32>
    %3822 = stablehlo.reshape %3821 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3823 = stablehlo.transpose %arg358, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3824 = stablehlo.dot %3822, %3823, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3825 = stablehlo.reshape %3824 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3826 = stablehlo.logistic %3825 : tensor<2x2048x11008xf32>
    %3827 = stablehlo.multiply %3825, %3826 : tensor<2x2048x11008xf32>
    %3828 = stablehlo.reshape %3821 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3829 = stablehlo.transpose %arg11, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3830 = stablehlo.dot %3828, %3829, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3831 = stablehlo.reshape %3830 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3832 = stablehlo.multiply %3827, %3831 : tensor<2x2048x11008xf32>
    %3833 = stablehlo.reshape %3832 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3834 = stablehlo.transpose %arg10, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3835 = stablehlo.dot %3833, %3834, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3836 = stablehlo.reshape %3835 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3837 = stablehlo.add %3809, %3836 : tensor<2x2048x4096xf32>
    %3838 = stablehlo.power %3837, %1 : tensor<2x2048x4096xf32>
    %3839 = stablehlo.reduce(%3838 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3840 = stablehlo.multiply %3839, %0 : tensor<2x2048xf32>
    %3841 = stablehlo.reshape %3840 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3842 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3843 = stablehlo.add %3841, %3842 : tensor<2x2048x1xf32>
    %3844 = stablehlo.rsqrt %3843 : tensor<2x2048x1xf32>
    %3845 = stablehlo.reshape %3844 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3846 = stablehlo.broadcast_in_dim %3845, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3847 = stablehlo.multiply %3837, %3846 : tensor<2x2048x4096xf32>
    %3848 = stablehlo.broadcast_in_dim %arg9, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3849 = stablehlo.multiply %3847, %3848 : tensor<2x2048x4096xf32>
    %3850 = stablehlo.reshape %3849 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3851 = stablehlo.transpose %arg362, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3852 = stablehlo.dot %3850, %3851, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3853 = stablehlo.reshape %3852 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3854 = stablehlo.slice %3853 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3855 = stablehlo.reshape %3854 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3856 = stablehlo.slice %3853 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3857 = stablehlo.reshape %3856 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3858 = stablehlo.complex %3855, %3857 : tensor<2x2048x32x64xcomplex<f32>>
    %3859 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3860 = stablehlo.multiply %3858, %3859 : tensor<2x2048x32x64xcomplex<f32>>
    %3861 = stablehlo.real %3860 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3862 = stablehlo.reshape %3861 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3863 = stablehlo.imag %3860 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3864 = stablehlo.reshape %3863 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3865 = stablehlo.concatenate %3862, %3864, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3866 = stablehlo.reshape %3865 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3867 = stablehlo.transpose %3866, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3868 = stablehlo.reshape %3867 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3869 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3870 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3871 = stablehlo.add %arg199, %3870 : tensor<2048xi64>
    %3872 = stablehlo.select %3869, %3871, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3873 = stablehlo.reshape %3872 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3874 = stablehlo.reshape %3849 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3875 = stablehlo.transpose %arg360, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3876 = stablehlo.dot %3874, %3875, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3877 = stablehlo.reshape %3876 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x64x2xf32>
    %3878 = stablehlo.slice %3877 [0:2, 0:2048, 0:32, 0:64, 0:1] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3879 = stablehlo.reshape %3878 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3880 = stablehlo.slice %3877 [0:2, 0:2048, 0:32, 0:64, 1:2] : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x64x1xf32>
    %3881 = stablehlo.reshape %3880 : (tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64xf32>
    %3882 = stablehlo.complex %3879, %3881 : tensor<2x2048x32x64xcomplex<f32>>
    %3883 = stablehlo.broadcast_in_dim %37, dims = [1, 3] : (tensor<2048x64xcomplex<f32>>) -> tensor<2x2048x32x64xcomplex<f32>>
    %3884 = stablehlo.multiply %3882, %3883 : tensor<2x2048x32x64xcomplex<f32>>
    %3885 = stablehlo.real %3884 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3886 = stablehlo.reshape %3885 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3887 = stablehlo.imag %3884 : (tensor<2x2048x32x64xcomplex<f32>>) -> tensor<2x2048x32x64xf32>
    %3888 = stablehlo.reshape %3887 : (tensor<2x2048x32x64xf32>) -> tensor<2x2048x32x64x1xf32>
    %3889 = stablehlo.concatenate %3886, %3888, dim = 4 : (tensor<2x2048x32x64x1xf32>, tensor<2x2048x32x64x1xf32>) -> tensor<2x2048x32x64x2xf32>
    %3890 = stablehlo.reshape %3889 : (tensor<2x2048x32x64x2xf32>) -> tensor<2x2048x32x128xf32>
    %3891 = "stablehlo.scatter"(%arg361, %3873, %3890) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3892 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3893 = "stablehlo.gather"(%3891, %3892) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3894 = stablehlo.transpose %3893, dims = [0, 2, 3, 1] : (tensor<2x2048x32x128xf32>) -> tensor<2x32x128x2048xf32>
    %3895 = stablehlo.reshape %3894 : (tensor<2x32x128x2048xf32>) -> tensor<64x128x2048xf32>
    %3896 = stablehlo.dot_general %3868, %3895, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x128xf32>, tensor<64x128x2048xf32>) -> tensor<64x2048x2048xf32>
    %3897 = stablehlo.reshape %3896 : (tensor<64x2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3898 = stablehlo.broadcast_in_dim %arg203, dims = [] : (tensor<f32>) -> tensor<2x32x2048x2048xf32>
    %3899 = stablehlo.divide %3897, %3898 : tensor<2x32x2048x2048xf32>
    %3900 = stablehlo.reshape %86 : (tensor<1x1x2048x2048xf32>) -> tensor<2048x2048xf32>
    %3901 = stablehlo.broadcast_in_dim %3900, dims = [2, 3] : (tensor<2048x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3902 = stablehlo.add %3899, %3901 : tensor<2x32x2048x2048xf32>
    %3903 = stablehlo.reduce(%3902 init: %7) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.maximum %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3904 = stablehlo.broadcast_in_dim %3903, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3905 = stablehlo.subtract %3902, %3904 : tensor<2x32x2048x2048xf32>
    %3906 = stablehlo.exponential %3905 : tensor<2x32x2048x2048xf32>
    %3907 = stablehlo.reduce(%3906 init: %8) across dimensions = [3] : (tensor<2x32x2048x2048xf32>, tensor<f32>) -> tensor<2x32x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3908 = stablehlo.broadcast_in_dim %3907, dims = [0, 1, 2] : (tensor<2x32x2048xf32>) -> tensor<2x32x2048x2048xf32>
    %3909 = stablehlo.divide %3906, %3908 : tensor<2x32x2048x2048xf32>
    %3910 = stablehlo.reshape %3909 : (tensor<2x32x2048x2048xf32>) -> tensor<64x2048x2048xf32>
    %3911 = stablehlo.compare  LT, %arg199, %2 : (tensor<2048xi64>, tensor<2048xi64>) -> tensor<2048xi1>
    %3912 = stablehlo.broadcast_in_dim %arg200, dims = [] : (tensor<i64>) -> tensor<2048xi64>
    %3913 = stablehlo.add %arg199, %3912 : tensor<2048xi64>
    %3914 = stablehlo.select %3911, %3913, %arg199 : tensor<2048xi1>, tensor<2048xi64>
    %3915 = stablehlo.reshape %3914 : (tensor<2048xi64>) -> tensor<2048x1xi64>
    %3916 = stablehlo.reshape %3849 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3917 = stablehlo.transpose %arg8, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3918 = stablehlo.dot %3916, %3917, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3919 = stablehlo.reshape %3918 : (tensor<4096x4096xf32>) -> tensor<2x2048x32x128xf32>
    %3920 = "stablehlo.scatter"(%arg359, %3915, %3919) ({
    ^bb0(%arg364: tensor<f32>, %arg365: tensor<f32>):
      stablehlo.return %arg365 : tensor<f32>
    }) {indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1], index_vector_dim = 1>, unique_indices = false} : (tensor<2x2304x32x128xf32>, tensor<2048x1xi64>, tensor<2x2048x32x128xf32>) -> tensor<2x2304x32x128xf32>
    %3921 = stablehlo.convert %arg7 : (tensor<2048xi64>) -> tensor<2048xui32>
    %3922 = "stablehlo.gather"(%3920, %3921) {dimension_numbers = #stablehlo.gather<offset_dims = [0, 2, 3], collapsed_slice_dims = [1], start_index_map = [1], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = dense<[2, 1, 32, 128]> : tensor<4xi64>} : (tensor<2x2304x32x128xf32>, tensor<2048xui32>) -> tensor<2x2048x32x128xf32>
    %3923 = stablehlo.transpose %3922, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,32,2048,128]{3,1,2,0}"} : (tensor<2x2048x32x128xf32>) -> tensor<2x32x2048x128xf32>
    %3924 = stablehlo.reshape %3923 : (tensor<2x32x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3925 = stablehlo.dot_general %3910, %3924, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<64x2048x2048xf32>, tensor<64x2048x128xf32>) -> tensor<64x2048x128xf32>
    %3926 = stablehlo.reshape %3925 : (tensor<64x2048x128xf32>) -> tensor<2x32x2048x128xf32>
    %3927 = stablehlo.transpose %3926, dims = [0, 2, 1, 3] {result_layout = dense<[3, 1, 2, 0]> : tensor<4xindex>, xla_shape = "f32[2,2048,32,128]{3,1,2,0}"} : (tensor<2x32x2048x128xf32>) -> tensor<2x2048x32x128xf32>
    %3928 = stablehlo.reshape %3927 : (tensor<2x2048x32x128xf32>) -> tensor<4096x4096xf32>
    %3929 = stablehlo.transpose %arg6, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,4096]{0,1}"} : (tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3930 = stablehlo.dot %3928, %3929, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x4096xf32>) -> tensor<4096x4096xf32>
    %3931 = stablehlo.reshape %3930 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3932 = stablehlo.add %3837, %3931 : tensor<2x2048x4096xf32>
    %3933 = stablehlo.power %3932, %1 : tensor<2x2048x4096xf32>
    %3934 = stablehlo.reduce(%3933 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3935 = stablehlo.multiply %3934, %0 : tensor<2x2048xf32>
    %3936 = stablehlo.reshape %3935 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3937 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3938 = stablehlo.add %3936, %3937 : tensor<2x2048x1xf32>
    %3939 = stablehlo.rsqrt %3938 : tensor<2x2048x1xf32>
    %3940 = stablehlo.reshape %3939 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3941 = stablehlo.broadcast_in_dim %3940, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3942 = stablehlo.multiply %3932, %3941 : tensor<2x2048x4096xf32>
    %3943 = stablehlo.broadcast_in_dim %arg5, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3944 = stablehlo.multiply %3942, %3943 : tensor<2x2048x4096xf32>
    %3945 = stablehlo.reshape %3944 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3946 = stablehlo.transpose %arg363, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3947 = stablehlo.dot %3945, %3946, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3948 = stablehlo.reshape %3947 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3949 = stablehlo.logistic %3948 : tensor<2x2048x11008xf32>
    %3950 = stablehlo.multiply %3948, %3949 : tensor<2x2048x11008xf32>
    %3951 = stablehlo.reshape %3944 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3952 = stablehlo.transpose %arg4, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,11008]{0,1}"} : (tensor<11008x4096xf32>) -> tensor<4096x11008xf32>
    %3953 = stablehlo.dot %3951, %3952, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x11008xf32>) -> tensor<4096x11008xf32>
    %3954 = stablehlo.reshape %3953 : (tensor<4096x11008xf32>) -> tensor<2x2048x11008xf32>
    %3955 = stablehlo.multiply %3950, %3954 : tensor<2x2048x11008xf32>
    %3956 = stablehlo.reshape %3955 : (tensor<2x2048x11008xf32>) -> tensor<4096x11008xf32>
    %3957 = stablehlo.transpose %arg3, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[11008,4096]{0,1}"} : (tensor<4096x11008xf32>) -> tensor<11008x4096xf32>
    %3958 = stablehlo.dot %3956, %3957, precision = [DEFAULT, DEFAULT] : (tensor<4096x11008xf32>, tensor<11008x4096xf32>) -> tensor<4096x4096xf32>
    %3959 = stablehlo.reshape %3958 : (tensor<4096x4096xf32>) -> tensor<2x2048x4096xf32>
    %3960 = stablehlo.add %3932, %3959 : tensor<2x2048x4096xf32>
    %3961 = stablehlo.power %3960, %1 : tensor<2x2048x4096xf32>
    %3962 = stablehlo.reduce(%3961 init: %8) across dimensions = [2] : (tensor<2x2048x4096xf32>, tensor<f32>) -> tensor<2x2048xf32>
     reducer(%arg364: tensor<f32>, %arg365: tensor<f32>)  {
      %3977 = stablehlo.add %arg364, %arg365 : tensor<f32>
      stablehlo.return %3977 : tensor<f32>
    }
    %3963 = stablehlo.multiply %3962, %0 : tensor<2x2048xf32>
    %3964 = stablehlo.reshape %3963 : (tensor<2x2048xf32>) -> tensor<2x2048x1xf32>
    %3965 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<2x2048x1xf32>
    %3966 = stablehlo.add %3964, %3965 : tensor<2x2048x1xf32>
    %3967 = stablehlo.rsqrt %3966 : tensor<2x2048x1xf32>
    %3968 = stablehlo.reshape %3967 : (tensor<2x2048x1xf32>) -> tensor<2x2048xf32>
    %3969 = stablehlo.broadcast_in_dim %3968, dims = [0, 1] : (tensor<2x2048xf32>) -> tensor<2x2048x4096xf32>
    %3970 = stablehlo.multiply %3960, %3969 : tensor<2x2048x4096xf32>
    %3971 = stablehlo.broadcast_in_dim %arg1, dims = [2] : (tensor<4096xf32>) -> tensor<2x2048x4096xf32>
    %3972 = stablehlo.multiply %3970, %3971 : tensor<2x2048x4096xf32>
    %3973 = stablehlo.reshape %3972 : (tensor<2x2048x4096xf32>) -> tensor<4096x4096xf32>
    %3974 = stablehlo.transpose %arg0, dims = [1, 0] {result_layout = dense<[0, 1]> : tensor<2xindex>, xla_shape = "f32[4096,32000]{0,1}"} : (tensor<32000x4096xf32>) -> tensor<4096x32000xf32>
    %3975 = stablehlo.dot %3973, %3974, precision = [DEFAULT, DEFAULT] : (tensor<4096x4096xf32>, tensor<4096x32000xf32>) -> tensor<4096x32000xf32>
    %3976 = stablehlo.reshape %3975 : (tensor<4096x32000xf32>) -> tensor<2x2048x32000xf32>
    return %3976, %70, %107, %201, %230, %324, %353, %447, %476, %570, %599, %693, %722, %816, %845, %939, %968, %1062, %1091, %1185, %1214, %1308, %1337, %1431, %1460, %1554, %1583, %1677, %1706, %1800, %1829, %1923, %1952, %2046, %2075, %2169, %2198, %2292, %2321, %2415, %2444, %2538, %2567, %2661, %2690, %2784, %2813, %2907, %2936, %3030, %3059, %3153, %3182, %3276, %3305, %3399, %3428, %3522, %3551, %3645, %3674, %3768, %3797, %3891, %3920 : tensor<2x2048x32000xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>, tensor<2x2304x32x128xf32>
  }
}
